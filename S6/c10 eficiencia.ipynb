{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**8/05/2020 - C9 S6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computación de alto Rendimiento con Python\n",
    "\n",
    "Python es utilizado transversalmente, ya sea en la industria o en la academia. Dentro de sus cualidades se encuentra la portabilidad de código, sintaxis intuitiva, disponibilidad de herramientas y documentación. Sin embargo, al ser un lenguaje interpretado se pierden ciertas características intrínsicas de los lenguajes de bajo nivel como C, C++ y Fortran.\n",
    "\n",
    "Se estudian distintas herramientas para mejorar el rendimiento del interprete CPython, estas se basan en el uso eficiente de objetos base, aplicación de técnicas de paralelismo y compilación utilizando tanto librerías nativas, como desarrolladas por terceros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilamiento y Referenciación\n",
    "\n",
    "El flujo de trabajo en ciencia de datos consta de numerosas rutinas de carga, procesamiento, visualización y optimización. Estas rutinas son abordadas por medio de técnicas de programación y diseño de código. En este apartado, se debe tener en cuenta la importancia de generar rutinas eficientes, pues significan reducciones en los tiempos de respuesta y uso de recursos. Por lo anterior, es natural que desde fases tempranas del desarrollo de proyectos, se busque optimizar el código. Como directriz general, se recomienda llevar el proceso de desarrollo en dos etapas. La primera consiste en generar rutinas **correctas**, **comprensibles** y **mantenibles**, evitando la sobre-optimización prematura de código. Como segunda etapa, se recomienda comenzar con los procesos de optimización de rutinas. Esto pues, las herramientas que permiten mejorar los aspectos computacionales, interfieren en la sencillez del código, entorpeciendo los procesos de depuración y mantención. \n",
    "\n",
    "Una vez que las rutinas están implementadas de manera correcta, la mejor manera de enfocar los esfuerzos, pasa por **perfilar** (*profiling*) las rutinas codificadas. Esto consiste en encontrar las zonas de código criticas en cuanto a carga computacional. La manera más directa de encontrar estas zonas, es por medio del uso de contadores de tiempo o *timers*.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza la librería `time` para medir el tiempo de ejecución de una zona de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_1(a):\n",
    "    \n",
    "    result = 0\n",
    "    for val in a:\n",
    "        result += sin(val) + cos(val)**2\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define un rango de datos a operar y se estudia el tiempo de ejecución por medio de la función `process_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [0.1 * i for i in range(1000)]\n",
    "\n",
    "t0 = time.process_time()\n",
    "for r in range(1000):\n",
    "    func_1(x)\n",
    "t1 = time.process_time()\n",
    "\n",
    "\n",
    "print(\"Tiempo transcurrido\", t1 - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Defina una clase *context manager* llamada `Timer`. Esta debe abstraer la dinámica de medición temporal anterior. *Hint*: Deberá definir los métodos `__enter__` y `__exit__`, en este último se produce el `print` de tiempo transcurrido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas ocasiones se desea medir el tiempo de ejecución para tareas sencillas, la librería estándar de Python provee el módulo `timeit`, este puede ser utilizado directamente en la consola interactiva IPython o en notebooks de Jupyter por medio del comando mágico `%timeit`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se mide el tiempo de ejecución promedio para la función coseno de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se compara con la función del módulo `Math`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cos(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver una gran diferencia en los tiempos de ejecución promedio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Diferencie los comandos `%time`, `%timeit`, `%%timeit`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un **perfilador**  (*profiler*) es un programa que ejecuta una rutina y monitorea las funciones ahí especificadas, obteniendo métricas de rendimiento como el consumo de tiempo y memoria. Por otra parte, la referenciación (*benchmarking*) consiste en extraer zonas de código de interés para probar su rendimiento antes y después de aplicar técnicas de optimización. IPython provee de un perfilador de código dado por la orden `%prun`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "1. Se perfila una función utilizando `%prun`. En primera instancia se define tal función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_sum(n):\n",
    "    '''Funcion de referencia que suma n elementos transformados\n",
    "    '''\n",
    "    ac = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        to_sum = [(i // 2)**n + (i-n)**(n // 3) for i in range(n)]\n",
    "        ac = sum(to_sum)\n",
    "    \n",
    "    return ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se perfila la función con `%prun`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EL resultado corresponde las mediciones temporales de cada función involucrada en la ejecución de `benchmark_sum(500)`. En este caso, la mayoria del tiempo se utiliza en la ejecución de la compresión de listas `<listcomp>`. Esto indica que la mejor manera de optimizar el código de `benchmark_sum`pasa por optimizar tal sección del código."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `%lprun` es posible perfilar por linea de código, para ello es necesario instalar el módulo `line_profiler`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga la extensión `%lprun` y se prueba con `benchmark_sum`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El comando `%lprun` toma como parámetro una orden de Python y su principal argumento. Las funciones que se desean perfilar deben ser especificadas de manera explicita con la orden `-f`. En el caso de `benchmark_sum` esto se haría según el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f benchmark_sum benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una tabla con el tiempo utilizado en cada linea de las funciones perfiladas, mostrando porcentajes del tiempo consumido en cada paso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Los perfiladores `%prun` y `%lprun` tienen en común los argumentos -D, -T y -r utilice el parámetro `?` para investigar estas opciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible perfilar uso de memoria, para ello existen los comandos mágicos `%memit` y `%mprun`. Para utilizarlos es necesario instalar el módulo `memory_profiler` y cargarlo mediante\n",
    "\n",
    "```python\n",
    "%load_ext memory_profiler\n",
    "```\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se carga la extensión y se perfila el uso de memoria para `benchmark_sum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primera instancia perfilamos utilizando la linea mágica `%memit`, la cual es equivalente a `timeit` pero ofrece medidas sobre el uso de memoria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar un uso de memoria en torno a 90 MB.\n",
    "\n",
    "De manera análoga a `%prun` la librería `memory_profiler` permite utilizar `%mprun`, con la cual se pueden obtener descripciones linea a linea del uso de memoria. El uso de este comando es un poco más restrictivo, pues solo permite medir funciones definidas en módulos (no dentro de un notebook). Para ello, se crea el módulo `memory_demo`. La manera sencilla de hacer esto, es mediante el comando mágico `%%file` este permite crear archivos en el directorio de trabajo actual, utilizando el código dentro de una celda de jupyter. \n",
    "\n",
    "Se procede a generar el módulo que contiene el código de `benchmark_sum` utilizando el comando `%%file`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file bench_module.py\n",
    "\n",
    "def benchmark_sum(n):\n",
    "    '''Funcion de referencia que suma n elementos transformados\n",
    "    '''\n",
    "    ac = 0\n",
    "    \n",
    "    for i in range(n):\n",
    "        to_sum = [(i // 2)**n + (i-n)**(n // 3) for i in range(n)]\n",
    "        ac = sum(to_sum)\n",
    "    \n",
    "    return ac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a continuación, se importa el módulo creado y se perfuila su memoria mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bench_module import benchmark_sum\n",
    "%mprun -f benchmark_sum benchmark_sum(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado se muestra en pantalla, obteniendo detalles linea a linea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Agregue la linea `del to_sum` luego de ejecutar `ac = sum(to_sum)` y antes de terminar el ciclo `for` principal. Estudie el efecto en el consumo de memoria en la función."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización con Código Nativo\n",
    "\n",
    "Una de las manera más eficientes de mejorar el rendimiento de aplicaciones es por medio del uso de algoritmos más eficientes en conjunción de estructuras de datos mejor diseñadas. A continuación, se estudian los algoritmos y estructuras de datos presentes de manera nativa en Python que permiten acelerar ciertas rutinas. \n",
    "\n",
    "En términos generales, lso algoritmos pueden ser clasificados según su *complejidad computacional*, esta clasificación se expresa según la notación de O-grande, que corresponde a una cota superior de las operaciones requeridas para ejecutar una tarea.\n",
    "\n",
    "Si la tarea no depende del tamaño del input (acceder a cierta llave de un diccionario por ejemplo) se dice que el algoritmo asociado se efectúa en tiempo constante, denotado por $O(1)$. Esto quiere decir, que sin importar la cantidad de datos disponibles, el tiempo de ejecución de la tarea será siempre el mismo. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se genera un lista, a cada uno de sus elementos se le realiza una operación básica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = list(range(10))\n",
    "\n",
    "for i in range(len(lista)):\n",
    "    lista[i]+=100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este algoritmo, la operación `lista[i]+=100` es repetida tantas veces como elementos hay en `lista`, que corresponde al tamaño de los datos de entrada. Al observar la que las operaciones realizadas por este algoritmo son proporcionales a la cantidad de elementos de `lista`, se puede decir que su tiempo de ejecución es $O(N)$ donde `N = len(lista)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Listas\n",
    "\n",
    "Las listas de Python son colecciones ordenadas de elementos, estás se encuentran clasificadas como *arreglos*, que a la vez corresponden a una estructura de datos caracterizada por contener elementos contiguos en bloques de memoria, cada uno de los cuales contienen una referencia a un objeto de Python. La ventaja de las listas recae en la facilidad que entregan par acceder, modificar y agregar elementos. Dado que acceder y modificar elementos de una lista corresponde a acceder a espacios de memoria que a priori no dependen de la longitud de la lista, se dice que estas operaciones tienen complejidad $O(1)$. Por otra parte, para agregar un elemento a una lista por medio de `.append()`, puede requerirse re-ubicar la memoria del arreglo asociado, operación que toma un tiempo de $O(N)$. Sin embargo, tal operación es muy poco frecuente, pues por lo general se tiene acceso a bloques de memoria contiguos, por tal motivo, se dice que la operación `.append()` tiene un tiempo esperado de ejecución de $O(1)$. \n",
    "\n",
    "Para agregar o eliminar datos al inicio de un arreglo, se requiere hacer una traslación (o *shift*) de los demás elementos por lo que tal operación toma un tiempo de $O(N)$. Para agregar o remover elementos de un arreglo en una posición distinta a la última, se opera de manera análoga. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se definen listas para estudiar la complejidad de ciertos métodos empíricamente. Se definen los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_0, n_1, n_2 = (int(10e5), int(5*10e5), int(10e6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se generan una funciones de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_objs(obj_0,obj_1,obj_2):\n",
    "    '''Abstraccion auxiliar para copiar elementos.'''\n",
    "    return (obj_0.copy(),obj_1.copy(),obj_2.copy())\n",
    "\n",
    "def bench_pop(l_0,l_1,l_2, index = -1):\n",
    "    '''Funcion de referncia para eliminacion de elementos.'''\n",
    "    \n",
    "    l_0.pop(index)\n",
    "    l_1.pop(index)\n",
    "    l_2.pop(index)\n",
    "    \n",
    "\n",
    "def bench_append(l_0,l_1,l_2, index = 1):\n",
    "    '''Funcion de referencia para insertar 1 con append.'''\n",
    "    \n",
    "    l_0.append(index)\n",
    "    l_1.append(index)\n",
    "    l_2.append(index)\n",
    "    \n",
    "\n",
    "def bench_insert(l_0,l_1,l_2, index = (0,1)):\n",
    "    '''Funcion de referncia para insertar 1 con insert.'''\n",
    "    \n",
    "    l_0.insert(*index)\n",
    "    l_1.insert(*index)\n",
    "    l_2.insert(*index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_0, lista_1, lista_2 = (list(range(n_0)), list(range(n_1)),\n",
    "                             list(range(n_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el ultimo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo constante\n",
    "%lprun -f bench_pop bench_pop(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el primer elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina el primer elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo lineal\n",
    "%lprun -f bench_pop bench_pop(l_0,l_1,l_2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inserta 1 en la ultima posicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo constante (casi seguramente)\n",
    "%lprun -f  bench_append bench_append(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inserta 1 en la primera posicion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "\n",
    "# Se observa un tiempo lineal\n",
    "%lprun -f bench_insert bench_insert(l_0,l_1,l_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para efectuar inserciones de manera eficiente (siempre en tiempo constante) Se puede utilizar la estructura de datos `deque` del módulo `collections`. Estas estructuras se comportan como listas, están diseñadas para acelerar la inserción de objetos y añaden los métodos `.popleft` y `.appendleft`. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se compara `.popleft` en *deques* con `.pop(0)` en listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bench_pop_left(d_0,d_1,d_2):\n",
    "    '''Funcion de referncia para eliminacion de elementos.'''\n",
    "    \n",
    "    d_0.popleft()\n",
    "    d_1.popleft()\n",
    "    d_2.popleft()\n",
    "    \n",
    "def bench_append_left(d_0,d_1,d_2, val = 1):\n",
    "    '''Funcion de referncia para insertar 1 con insert.'''\n",
    "\n",
    "    d_0.appendleft(val)\n",
    "    d_1.appendleft(val)\n",
    "    d_2.appendleft(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definen los objetos sobre los que se trabajará"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deque_0, deque_1, deque_2 = tuple(map(deque, [lista_1, lista_1, lista_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)\n",
    "\n",
    "# Se observa un tiempo constante\n",
    "%lprun -f bench_pop_left bench_pop_left(d_0, d_1, d_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copiar objetos de tipo `deque` tiene una carga de aproximadamente 190 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "d_0, d_1, d_2 = copy_objs(deque_0,deque_1,deque_2)\n",
    "bench_pop_left(d_0, d_1, d_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su parte, aplicar el benchmark `bench_pop_left` tarda en promedio 191 - 190 ms = 1 ms.\n",
    "\n",
    "En cuanto a las listas, la operación de copiar lleva unos 112 ms en promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar el benchmark `bench_pop` en listas lleva un tiempo promedio de 120 ms - 112 ms = 8ms. Por lo que se aprecia un aumento en el rendimiento. Cabe señalar que tal aumento se ve sujeto a una carga mayor en el proceso de copia de objetos, por tal motivo, vale la pena evitar la copia de objetos tipo `deque` y utilizarlos para acceder a lista con una gran cantidad de elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "l_0,l_1,l_2 = copy_objs(lista_0, lista_1, lista_2)\n",
    "bench_pop(lista_0,lista_1,lista_2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Repita el proceso de comparación para `.appendleft` en deques  e `.insert()` en listas. \n",
    "\n",
    "2. Cual es la complejidad computacional de acceder a:\n",
    "    1. Primer elemento de un deque / lista\n",
    "    2. Ultimo elemento de un deque / lista\n",
    "    3. Un elemento distinto del último o el primero (ej: el elemento de la mitad de un arreglo).\n",
    "\n",
    "3. El módulo `bisect` permite hacer búsquedas rápidas en arreglos ordenados. la función `bisect.bisect` permite encontrar el índice en cual insertar un elemento, manteniendo el orden del arreglo operado. \n",
    "    1. Genere la lista ordenada 'ordered_list'  de números entre 0 y 10.\n",
    "    2. Elimine el cuarto elemento de la lista, guarde su valor en la variable `dropped`. Se debe hacer en una linea de código. \n",
    "    3. Importe el módulo `bisect` y utilice el comando `bisect.bisect(ordered_list,dropped)`. ¿Qué significa el valor retornado por la función?¿qué operación se efectúa por medio del comando recién aplicado?\n",
    "    4. Haga un código de referencia para comparar las funciones `list.index()` y `bisect.bisect()` por medio de perfilamiento temporal. Para comprobar sus resultados utilice el hecho de que  el tiempo de ejecución para `bisect.bisect` es de $O(\\log(N)$, mientras que el de `list.index()` es de $O(N)$. \n",
    "    5. Estudie la función `bisect.bisect_left`. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Diccionarios\n",
    "\n",
    "La gran flexibilidad de los diccionarios los hacen un objeto central en el uso de Python. Estos son implementaciones de *hash maps*, es decir, son estructuras de datos construidas por medio de asociaciones *llave - valor*, donde a cada llave, se asigna un índice especifico, de tal manera que el valor de tal índice puede ser ordenado en un arreglo. Por tal motivo, los diccionarios son altamente eficientes en procesos de eliminación, acceso e inserción teniendo un tiempo promedio de ejecución de $O(1)$. \n",
    "\n",
    "Para acceder a los índices dados por el *hash map* se puede utilizar la función `hash` de Python, esta opera sobre distintos tipos de datos.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se aplica `hash` a diferentes objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hash string: ',hash('MA6202'))\n",
    "print('hash int:' , hash(1234))\n",
    "print('hash tuple', hash(('a','b','c')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un objeto puede ser operado por `hash` (*hashable object*) si tiene un método `__hash__` y puede ser comparado por medio de `__eq__` por ejemplo. Si un objeto es *hashable* significa que puede ser utilizado como llave de un diccionario, en general, todos los objetos inmutables de Python son *hashables* mientras que las listas y diccionarios, por ser inmutables, no lo son.  \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Es posible usar las ventajas de accesibilidad de diccionarios agrupar listas de manera eficiente. Para esto se utiliza el objeto `defaultdict` de la librería `collections`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye la lista a agrupar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_group = [('a', 1), ('b', 2), ('c', 3), ('b', 4), ('d', 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los objetos `defaultdict` son subclases de `dict`. Reciben como argumentos un valor inicial para su el atributo `.default_factory`, cuyo valor por defecto es `None`. \n",
    "\n",
    "Los objetos `defaultdict` poseen todas las funcionalidades de un diccionario pero añaden el método `.__missing__()` con el cual se proveen valores por defecto, los cuales se asignan a una nueva llave, es decir, permiten inicializar diccionarios entregando solo el valor de la llave (y no su valor asociado), pues a cada llave nueva, se asigna un valor por defecto de manera automática. \n",
    "\n",
    "Según lo enterior, inicializar un objeto `defaultdict` por medio de `defaultdict(list)` genera un diccionario, en el cual, cada llave nueva tendrá asociada una lista vacía (valor por defecto del atributo `.default_factory` para este tipo de dato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez teniendo el diccionario definido, es posible agrupar los elementos de la lista `to_group` y se perfila por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "D = defaultdict(list)\n",
    "\n",
    "for k, v in to_group:\n",
    "    D[k].append(v)\n",
    "\n",
    "sorted(D.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior genera las llaves `k`, que por defecto poseen una lista vacía asociada, a cada lista vacía agregan por medio de `append` (tiempo de ejecución constante) el elemento inspeccionado `v`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la misma funcionalidad usando ciclos `for` y `append` de listas, se perfila utilizando `%%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "L = []\n",
    "for elem in to_group:    \n",
    "    if len(L) == 0:\n",
    "        L.append((elem[0],[elem[1]]))\n",
    "    else:\n",
    "        c = 0\n",
    "        for l in L:\n",
    "            if l[0] == elem[0]:\n",
    "                l[1].append(elem[1])\n",
    "                c = 1\n",
    "        if c == 0:\n",
    "             L.append((elem[0],[elem[1]]))\n",
    "\n",
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior apreciamos una ganancia en eficiencia, que tambien se traduce en simpleza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "Los objetos `defaultdict` permiten además aumentar la eficiencia al momento de contar elementos de un arreglo. Para ver esto, implemente una función que:\n",
    "\n",
    "1. Reciba una *iterable* como argumento.\n",
    "2. Inicalice un objeto `defaultdict` con tipo de dato `int`. ¿Qué valor se asocia por defecto?.\n",
    "3. Recorra cada elemento del iterable, registrando su número de ocurrencias en una llave del objeto `defaultdict` antes inicializado.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El módulo `collections` permite implementar el procedimiento del ejercicio 2 anterior por medio de la clase `Counter`\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se cuentan los elementos de una lista por medio de la clase `Counter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "lista = np.random.randint(0, 10, size=100)\n",
    "counts = Counter(lista)\n",
    "\n",
    "sorted(counts.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: El método de counteo por medio de la clase `Counter` tiene un tiempo de ejecución de $O(N)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra ventaja de los diccionarios es que permiten buscar palabras de manera rápida en una lista de documentos, en este caso, tal lista de documentos viene representada dada por:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [l.rstrip(' \\n') for l in lines]\n",
    "        \n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "supongamos que se busca la palabra 'imaginario' en cada documento, es posible generar una lista de documentos con tal palabra por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_search = 'imaginario'\n",
    "%timeit found = [line for line in lines if to_search in line]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe considerar que el tiempo de ejecución asociado a consultar por una palabra es $O(N)$. Para mejorar esto, se puede construir un diccionario, donde a cada palabra se asocie un índice, donde este último corresponde al la linea (o documento si se prefiere) al que pertenece. Esto se puede hacer mediante el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = defaultdict(list)\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    \n",
    "    for word in line.split():\n",
    "        index[word].append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el diccionario generado, hacer búsquedas es de orden $O(1)$, luego para la misma consulta antes hecha se tiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "res = index[to_search]\n",
    "[lines[i] for i in res]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es decir, un aumento substancial de rendimiento. Cabe mencionar, que este procedimiento solo tiene sentido si se busca hacer una cantidad alta de consultas sobre un arreglo de lineas/documentos, esto pues, el tiempo de preprocesamiento para generar el indexado por diccionario puede ser muy alto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Operaciones con Conjuntos\n",
    "\n",
    "A diferencia de las listas, los conjuntos son colecciones no ordenadas, donde cada elemento debe ser único. La implementación de conjuntos en Python sigue la misma lógica de los diccionarios en cuanto ambos utilizan funciones *hash*. Por tal motivo, en conjuntos se tienen operaciones rápidas para añadir, eliminar y acceder a elementos. (Del orden $O(1)$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Los tiempos de ejecución para los métodos `A.union(B)`, `A.intersection(B)` y `A.difference(B)` son $O(a+b)$, $O(\\min(a,b))$ y $O(a)$, donde $a = |A|$ y $b = |B|$. \n",
    "\n",
    "1. Construya una función de referencia para cada método y utilice un perfilamiento adecuado para comprobar la afirmación anterior de manera empírica. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer uso de conjuntos para efectuar consultas rápidas.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza el objeto `index` creado para hacer búsquedas sobre texto. Se consulta sobre los documentos donde las palabras 'imaginario' y 'vive' ocurren simultáneamente, se obtiene un estimado del tiempo de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_search = ['imaginaria', 'vive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "res_0 = [lines[i] for i in index[to_search[0]]]\n",
    "res_1 = [lines[i] for i in index[to_search[1]] ]\n",
    "\n",
    "[r for r in res_1 if r in res_0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede modificar la función de indexación para que opere sobre conjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_set = defaultdict(set)\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    \n",
    "    for word in line.split():\n",
    "        index_set[word].add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "luego se hace la misma búsqueda por medio de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "index_set[to_search[0]].intersection(index_set[to_search[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado se ve un incremento substancial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con uso de Memoización\n",
    "\n",
    "También se puede mejorar el rendimiento de aplicaciones por medio de un uso eficiente de la memoria, una de las ideas tras esta premisa es la de guardar los resultados de operaciones intensivas en un espacio de memoria llamado *cache*, este espacio puede estar ubicado en memoria (RAM), disco o almacenada de manera remota. El acto de guardar resultados en memoria para luego utilizarlos de manera directa se denomina **memoización**. y es una forma de *chaching* o uso de memorias *cache*.\n",
    "\n",
    "Python ofrece el decorador `@lru_cache` accesible desde la librería base `functools`. Este decorador puede ser utilizado de manera sencilla para guardar resultados en memoria y luego accederlos. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza el decorador `@lru_cache` sobre una función sencilla. En primera instancia se importa el módulo necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función a memoizar y se aplica el decorador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def simple_func(x, y):\n",
    "    '''Funcion de prueba para memoizar.'''\n",
    "\n",
    "    print('Obteniendo el resultado...')\n",
    "\n",
    "    return x**y + y**x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para comprobar el funcionamiento del decorador se llama la función dos veces sobre el mismo argumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (2,5)\n",
    "simple_func(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se repite el procedimiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_func(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este último caso se observa que el resultado es obtenido directamente desde la memoria. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "`@lru_cache` es un decorador que acepta argumentos de entrada, permitiendo el uso del `max_size`. Con este parámetro se especifica el tamaño máximo de memoria para el cache asociado a la función. \n",
    "\n",
    "1. Decore la función anterior indicando como parámetro `max_size = 8`.\n",
    "\n",
    "2. ¿Qué ocurre cuando se llena el tamaño maximo y se realizan más cálculos? *Hint*: lru significa *least recently used*.\n",
    "\n",
    "3. Acceda a la información del *cache* por medio del método `.cache_info()` de la función decorada. ¿Qué significa *hit* y *miss* en este contexto?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo más avanzado es el de memoizar funciones recursivas\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se trabaja con la función `factorial` almacenando sus resultados en *cache*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mide el tiempo de ejecución para `n=1000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "factorial(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se memoiza la función y se repite el experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def factorial(n):\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "factorial(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se comprueba la eficiencia del método. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Programe secuencia de Fibonacci, perfile su consumo de tiempo y luego compare con una versión memoizada.\n",
    "\n",
    "2. Instale el módulo `joblib`. Este módulo permite guardar resultados en disco por medio del objeto `Memory`. Utilice el decorador `@memory.cache` para memoizar as funciones anteriores (factorial y fibonacci). Compare los tiempos de ejecución al guardar los resultados en disco vs ram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: La ventaja de utilizar técnicas de *caching* tienen un costo, este radica en aumentar el consumo de memoria, si esta memoria esta localizada en disco, el acceso puede ser muy lento y el rendimiento puede decaer drásticamente. Antes de usar este tipo de estrategias, se recomienda estudiar la factibilidad, teniendo en cuenta las politicas de almacenamiento y acceso de los resultados y su relación con el rendimiento del programa que se desea implementar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización con uso de Compresiones y Generadores\n",
    "\n",
    "Las compresiones de lista están altamente optimizadas en Python y por tanto puede ser utilizadas para reemplazar ciclos `for` en ciertas circunstancias. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Es posible ganar un mayor rendimiento al utilizar comprensión de listas en vez del ciclo `for` en el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(10e4)\n",
    "\n",
    "def for_loop(n=n):\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        res.append(i*(i+1) - i**2)\n",
    "    \n",
    "    return sum(res)/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mide su consumo de tiempo por medio de `%%timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se implementa la misma función haciendo uso de compresión de listas y de diccionarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_comp(n=n):\n",
    "    return sum([i*(i+1) - i**2 for i in range(n)])/n\n",
    "    \n",
    "def dic_comp(n=n):\n",
    "    return sum({i: i*(i+1) -i**2 for i in range(n)})/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "list_comp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "dic_comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de compresión de listas vemos una mejoría, por su parte, en compresión de diccionarios, podemos esperar que operaciones de reducción sean más lentas pues se hace uso de llaves. \n",
    "\n",
    "En términos de memoria, cada compresión de listas (o diccionarios) ocupa un nuevo espacio, lo cual aumenta el uso de memoria. Para atacar este problema, se puede hacer uso de **generadores**. \n",
    "\n",
    "Un generador es un iterable que guarda que posee memoria solo de su estado actual y una regla de cambio para el estado siguiente. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "La función `map` toma como argumentos una función y un iterator, el resultado de su aplicación es un generador. Para estudiar el comportamiento de este tipo de objetos se construyen dos funciones y se perfilan ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file bench_module.py -a\n",
    "\n",
    "def list_comp_list(n=int(10e6)):\n",
    "    '''Concatena operaciones sobre comprensiones de lista'''\n",
    "\n",
    "    l_1 = [i**2 for i in range(n) if i % 2 == 0]\n",
    "    l_2 = [i * (i - 1) for i in l_1]\n",
    "\n",
    "    l_3 = [i // 3 for i in l_2]\n",
    "\n",
    "    return max(l_3) / n**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se construye la misma función utilizando generadores `map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file bench_module.py -a\n",
    "\n",
    "def list_comp_map(n=int(10e6)):\n",
    "    '''Concatena operaciones sobre comprensiones de lista'''\n",
    "\n",
    "    l_1 = map(lambda i: i**2, [i for i in range(n) if i % 2 == 0])\n",
    "    l_2 = map(lambda i: i * (i - 1), l_1)\n",
    "    \n",
    "    l_3 = map(lambda i: i // 3, l_2)\n",
    "\n",
    "    return max(l_3) / n**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se perfila la memoria utilizada por estas funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit list_comp_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit list_comp_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "Se pueden entender los objetos generadores con las estructuras ya vistas. El objetivo de estos ejercicios es revisar ciertos aspectos de interés al usar generadores.\n",
    "\n",
    "1. Se puede definir un generador por medio de *compresnsión de generadores* este tipo de comprensión sigue la misma sintaxis que una compresión usua (listas o diccionarios) solo que se utilizan paréntesis normales (como una '*compresion de tuplas*'). Defina un generador por medio de *compresión de generadores*.\n",
    "\n",
    "2. Se pueden definir generadores a partir de funciones, en este caso, el comando `return` debe ser sustituido por `yield`. Este comando permite que el generador definido sea un iterable, el cual solo guarda su estado actual de ejecución y posee una *regla de transición* dada por el cuerpo de la función. Implemente un generador de secuencias inifinitas. Para ello:\n",
    "    1. Defina una función `infinite_seq`, que no tiene argumentos de entrada. \n",
    "    2. Defina un acumulador de suma por medio de la variable `sum = 0`.\n",
    "    3. Defina un bloque `while True` dentro de este inserte las ordenes `yield sum` y en la linea siguiente `sum +=1`. \n",
    "    4. Itere sobre su generador utilizando el método `next`. Interprete la función de `yield` en el bloque anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso eficiente de Arreglos con Numpy y Pandas\n",
    "\n",
    "Como ya se ha discutido, NumPy provee una rutinas altamente eficientes para realizar operaciones matemáticas complejas basándose en arreglos de C y FORTRAN. Esto permite tener velocidades optimas aún cuando Python sea interpretado. Otra de las cualidades de NumPy es que almacena resultados intermedios en memoria, es posible mejorar tal aspecto por medio del paquete `numexpr` , el cual permite optimizar y compilar arreglos de manera rápida.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "se definen arreglos de NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(10e7)\n",
    "x, y, z = (np.random.rand(n), np.random.rand(n), np.random.rand(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener las ventajas de `numexpr` es recomendable trabajar con arreglos de gran tamaño. A continiación se utiliza la función `numexpr.evaluate` para procesar una operación entre los arreglos definidos, esta función actúa como `eval` de Python, por lo que recibe un string y lo ejecuta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numexpr import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "evaluate('x + z*y**2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "x + z*y**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Estudie la documentación de `numexpr` y busque las funciones soportadas por `evaluate`.\n",
    "\n",
    "2. Genere una matriz de distancia entre dos arreglos de NumPy. Esta contiene la distancia euclidiana en cada una de sus componentes. Compare los tiempos de ejecución de obtener tal matriz con solamente con expresiones de NumPy y utilizando `numexpr`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como consideraciones generales al trabajar con NumPy se puede tener en cuenta:\n",
    "\n",
    "1. Las operaciones *inplace* son más rápidas que sus contrpartes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se define una operacion *inplace* y se compara con una asignación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(5*10e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.rand(n)\n",
    "a *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.rand(n)\n",
    "b = a * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Aplicar *reshape* no implica generar una copia, por su parte, trasponer si. Por lo anterior, trasponer utiliza más memoria que cambiar la forma de un arreglo. Vale la pen\n",
    "\n",
    "3. `flatten()` y `ravel()` permiten cambiar la forma de un arreglo a dimensión 1, sin embarog, `flatten()` retorna una copia, mientras que `ravel()` solo lo hace si es necesario. Por tal motivo `ravel()` es más rápido con arreglos de gran tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.random(size = [n,n])\n",
    "b = a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "a = np.random.random(size = [n,n])\n",
    "b = a.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Seimrpe mejor utilizar [reglas de broadcasting](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html) para operar con arreglos de distinto tamaño, es decir, se debe prevenir el uso de `reshape` si es que dos arreglos son compatibles según alguna regla de *broadcasting*. A modo de ejemplo, se estudia el producto externo entre dos arreglos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random(size = n)\n",
    "a_1 = a[:,np.newaxis]\n",
    "a_2 = a[np.newaxis, :]\n",
    "\n",
    "'''\n",
    "Obs: np.tile permite copiar un arreglo segun un patron (rep_f,rep_c)\n",
    "de esta forma se repite tantas veces por fila como rep_f y tantas\n",
    "veces por columna como rep_c.\n",
    "'''\n",
    "\n",
    "%timeit np.tile(a_1, (1, n)) * np.tile(a_2, (n, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit a_1 * a_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. En arreglos de gran tamaño, donde la precisión no es un problema, se puede reducir el consumo de memoria al disminuir la presición numérica de los elementos del arreglo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.astype('float16')\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "Perfile el uso de memoria y velocidad de ejecución para arreglos de punto flotante de doble presición  `float64`versus punto flotante de presición singular `float32`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiladores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paralelismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento Distribuido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
