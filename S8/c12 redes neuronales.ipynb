{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**19/06/2020 - C12 S7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales \n",
    "\n",
    "La redes neuronales aparecen bajo el nombre de **perceptron**, propuesta por [Rosenblatt en 1958](http://www.ling.upenn.edu/courses/cogs501/Rosenblatt1958.pdf). Este es un modelo de clasificación consistente en pesos $w$ y una función de output del tipo $f(w^t\\mathbf{x})$ para el input $\\mathbf{x}$. Si bien este modelo es en esencia muy similar a la regresión logística, el percetron implementa $f(\\cdot)$ como una función de salto, que entrega el valor 1 para argumentos mayores que 0 y retorna 0 en otro caso. El problema de este modelo consiste en su poca expresibilidad, pues solo permite hacer separaciones lineales. \n",
    "\n",
    "Sobre el modelo anterior, se construye el perceptron multicapa, el cual consiste en múltiples modelos de perceptron intecomunicadas, cada uno de estos modelos se denota como *unidad* (*unit*) y se organizan en capas secuenciales conocidas como *capa input*, corresponde a un conjunto de perceptrones que operan de manera paralela sobre un vector input. El resultado de sus clasificaciones corresponde a un vector, donde cada componente se asocia un perceptron de la capa input. Las siguientes capas se denotan como *capas ocultas* y se contruyen de manera análoga a la capa input (o inicial), la primera capa oculta consiste en un conjunto de percetrones que operan sobre el output de la capa input. Sobre esta primera capa oculta pueden haber multiples capas ocultas que operan sobre el output de la capa oculta anterior. El proceso de generar una salida sobre la entrada de una capa anterior se denota *propagación hacia adelante* (*feedforward*) la propagación termina en una última capa denominada *capa output* que entrega el resultado final de la clasificación. \n",
    "\n",
    "Bajo el punto de vista del aprendizaje automático, las capas ocultas de un perceptron multicapa (red neuronal) generan abstracciones o características a partir de los datos sobre los cuales operan. \n",
    "\n",
    "Para trabajar con redes neuronales haremos uso de la librería **Pytorch**. Esta librería consiste en un conjunto de herramientas diseñadas para generar modelos basados en redes neuronales utilizando las capacidades de computo distribuido que ofrecen las GPU (unidades de procesamiento gráfico / tarjetas de video). Esto permite operaciones de vectorización aceleradas y distribuidas. Esta librería se importa como `torch`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se implementa una red neuronal simple utilizando Pytorch. Para esto, se importa el módulo y se indica una semilla aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Se asigna un valor de reproductibilidad\n",
    "torch.manual_seed(6202)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el dataset sobre el cual trabajaremos, en este caso será un conjunto de datos de vinos. Este conjunto consta de 13 atributos continuos, cada vino posee un identificador dentro de 3 posibilidades, la idea es poder clasificar cada vino para predecir su identificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "names = [\n",
    "    'class','Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
    "    'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "    'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline'\n",
    "]\n",
    "\n",
    "wine_data = pd.read_csv(\n",
    "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',\n",
    "    names=names)\n",
    "\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a hacer una separación en entrenamiento y test, se hará es una codificación dummy para la variable de respuesta y se estandarizan las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "response = ['class']\n",
    "num_cols = wine_data.loc[:, 'Alcohol':].columns.values\n",
    "\n",
    "data_transform = ColumnTransformer(\n",
    "    transformers=[('normaliza', StandardScaler(),num_cols), \n",
    "                  ('codifica', OrdinalEncoder(), response)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar fuga de información, se hace una separación en train y test para luego transformar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(wine_data, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica el preprocesamiento sobre el conjunto train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_transform.fit_transform(data_train)\n",
    "\n",
    "# Se obtienen las variables numericas y de respuesta\n",
    "\n",
    "X_train = data[:,:-1].copy()\n",
    "y_train = data[:,-1:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El perceptron multicapa a modelar consiste en 10 capas ocultas y su función de activación tiene la forma $f(x) = max(0,x)$, esta es una función conocida y se denota como ReLU (Rectified Linear Unit). Se definen los parámetros, para la función de activación se utiliza el módulo de redes neuronales de Pytorch, se puede acceder a este módulo por medio de `torch.nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim, output_dim = (X_train.shape[1], 3)\n",
    "\n",
    "# Equivalente al output de la capa input\n",
    "input_dim_capas_ocultas = 5\n",
    "\n",
    "f_activation = torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para definir la primera capa, tenemos que tener en cuenta que buscamos una transformación de la forma $x \\mapsto w^t x$ que luego es clasificada por medio de $f(w^t x)$. Esto quiere decir que los parámetros a entrenar serán los vectores de peso $w$ asociados a cada unidad (perceptron) de cada capa (input, ocultas y output). Pytorch ofrece una abstracción para capas formadas por perceptrones de la forma $f(w^t x)$. Esta abstracción es la clase `Linear` (observe que $x \\mapsto w^t x$ es una transformación lineal), se procede a definir la capa input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "capa_input = Linear(in_features  = input_dim,\n",
    "                    out_features = input_dim_capas_ocultas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se definen las capas ocultas, estas también corresponden a transformaciones lineales sobre sus capas predecesoras. En este caso, cada capa oculta tendrá dimensión 5 como input y output. Se define una capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Linear(input_dim_capas_ocultas, input_dim_capas_ocultas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura de esta red es de naturaleza secuencial y corresponde al siguiente algoritmo:\n",
    "\n",
    "1. Input: x de dimensión 13\n",
    "2. Opera x en cada unidad de la capa lineal input, es decir, calcula $w_i^t x$ para $i = 1, \\ldots, 5$ (dimensión de salida de la capa input).\n",
    "3. Opera RelU($w_i^t x$) para $i = 1, \\ldots, 5$, se obtiene un vector de dimensión 5. \n",
    "\n",
    "4. Para cada una de las 2 capas ocultas y de manera secuencial:\n",
    "    1. Genera una transformación lineal sobre los outputs de la capa anterior.\n",
    "    2. Aplica ReLU sobre las transformaciones lineales.\n",
    "    3. En la última capa oculta el vector resultante se pasa a la capa output.\n",
    "\n",
    "5. Se recibe el resultado de la última capa oculta, se transforma de manera lineal sobre 3 perceptrones para finalmente ser transformada por medio de una función softmax (dimensión del output es 3). \n",
    "\n",
    "Esto se reduce a: \n",
    "```\n",
    "X  -> capa input -> ReLU() -> Co_1 -> ReLU() -> Co_2 -> ReLU() -> capa output -> predicción\n",
    "```\n",
    "\n",
    "Para programar el esquema anterior se hace uso de un diccionario ordenado `OrderedDict` de la librería `collections`. Este tipo de objetos opera de manera similar a las Pipelines de Scikit-learn, pues reciben un conjunto de tuplas del tipo `(identificador,objeto)`. Se procede a generar la arquitectura de la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "n_capas_ocultas = 2\n",
    "\n",
    "# capa input\n",
    "input_ = ('capa input', capa_input)\n",
    "relu = ('relu', f_activation)\n",
    "\n",
    "steps = [input_, relu]\n",
    "\n",
    "# capas ocultas\n",
    "for i in range(n_capas_ocultas):\n",
    "    \n",
    "    capa = ('capa oculta_' + str(i),\n",
    "         Linear(input_dim_capas_ocultas, input_dim_capas_ocultas))\n",
    "    \n",
    "    steps.extend([capa,relu])\n",
    "\n",
    "# capa output\n",
    "output = ('capa ouput', Linear(input_dim_capas_ocultas, output_dim))\n",
    "\n",
    "steps.extend([(output),('Softmax',torch.nn.Softmax(dim=1))])\n",
    "\n",
    "# Se utiliza la estructura de diccionario ordenado\n",
    "steps = OrderedDict(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, cuando ya se posee la arquitectura, se inicializa un objeto `Sequential` del módulo `nn`, este objeto permite modelar una red neuronal multicapa recibiendo como input los componentes de la arquitectura de manera ordenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "\n",
    "#MLP -> multi layer perceptron\n",
    "mlp = Sequential(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado entregado por la capa output corresponde a un vector de tres dimensiones, se asigna la clase predicha a aquella componente con el mayor valor. Luego de definir la red, es necesario definir un criterio de optimalidad (función de perdida), en este caso se utiliza la entropía cruzada. Este criterio permite comparar dos distribuciones de probabilidad $q$ (aproximación) y $p$ (real) en términos de la diferencia de información esperada (en bits por ejemplo) al utilizar la distribución $q$ para describir un eventos codificados, optimizados para $p$. Dado que se trabaja en un problema de clasificación (supervisado) se conoce la distribución real $p$ para una etiqueta  (ej: etiqueta (1,0,0), distribución (100%, 0, 0) ), por otra parte, la distribución aproximada viene dada por nuestro modelo. La entropía cruzada entre $p$ y $q$ se expresa según:\n",
    "$$\n",
    "H(p, q)=-\\sum_{x \\in \\mathcal{X}} p(x) \\log q(x)\n",
    "$$\n",
    "\n",
    "Se implementa mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterio = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe seleccionar el optimizador a utilizar, en este caso será **descenso de gradiente estocástico** (SGD, se estudiará con más detenimiento posteriormente). Este optimizador tiene un parámetro asociado a la proporción de aprendizaje (*learning rate*) y momentum. Se inicializa entregando dichos parámetros y los coeficientes sobre los que opera, en este caso, los parámetros de la red `mpl` a los cuales se acceede por medio del método `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizador = torch.optim.SGD(mlp.parameters(), lr=0.05, momentum=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se puede entrenar la red definida, para ello se define una cantidad de *épocas* (*epochs*), esto se refiere a la cantidad de veces que se entrena utilizando el conjunto de entrenamiento. Este proceso tiene el siguiente orden:\n",
    "\n",
    "1. Genera un conjunto de inputs en un formato compatible.\n",
    "2. En cada época:\n",
    "    1. Inicializa los gradientes asociados al optimizador, esto evita que se acumulen gradientes entre épocas.\n",
    "    2. Se opera sobre los inputs para obtener las predicciones.\n",
    "    3. Se calcula el error de predicción.\n",
    "    4. Se propagan los valores de la función de perdida para ajustar los pesos de la red y mejorar predicciones. Este proceso se denomina como *propagación hacia atrás* (*backpropagation*).\n",
    "    5. Se pasa a la siguiente época.\n",
    "    \n",
    "Se implementa el esquema anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paso A\n",
    "datos_input = torch.autograd.Variable(torch.Tensor(X_train))\n",
    "labels = torch.autograd.Variable(torch.Tensor(y_train.reshape([-1,])).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocas = 1000\n",
    "for ep in range(epocas):\n",
    "    #Paso B\n",
    "    optimizador.zero_grad()\n",
    "    for i in range(20):\n",
    "        #Paso C\n",
    "        out = mlp(datos_input)\n",
    "        #out.requires_grad_(True)\n",
    "\n",
    "        #Paso D \n",
    "        loss = criterio(out, labels)\n",
    "        \n",
    "        #Paso E\n",
    "        loss.backward() \n",
    "        optimizador.step()\n",
    "    \n",
    "    if ((ep+1) % 100) == 0 : print('Epoca: ', ep+1, 'Loss: ', loss.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se estudia el rendimiento en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "dt_test = data_transform.transform(data_test)\n",
    "\n",
    "X_test = dt_test[:, :-1]\n",
    "y_test = dt_test[:, -1:]\n",
    "\n",
    "f = lambda x: torch.argmax(mlp(x), dim=1)\n",
    "\n",
    "#Train error\n",
    "datos_input = torch.Tensor(X_train).float()\n",
    "preds_train = f(datos_input)\n",
    "\n",
    "print('Reporte train : \\n',\n",
    "      classification_report(y_train.reshape([-1,]), preds_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Error\n",
    "\n",
    "datos_input = torch.Tensor(X_test).float()\n",
    "preds_test = f(datos_input)\n",
    "\n",
    "print('Reporte test : \\n', \n",
    "      classification_report(y_test.reshape([-1,]), preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se puede decir que el clasificador entrenado fue un éxito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las redes neuronales pueden ser descritas como un modelo matemático de procesamiento de información. En general, una red neuronal puede considerarse como un sistema con las siguientes características:\n",
    "\n",
    "1. El procesamiento de la información ocurre en unidades llamadas neuronas.\n",
    "2. Las neuronas están conectadas e intercambian información (o señales) por medio de sus conexiones.\n",
    "3. Las conexiones entre neuronas pueden ser fuertes o débiles, dependiendo de como se procesa la información.\n",
    "4. Cada neurona tiene un estado interno determinado por todas las conexiones que posee.\n",
    "5. Cada neurina tiene una función de activación que opera sobre su estado, esta función determina la información que se comparte a otras neuronas.\n",
    "\n",
    "En términos operativos, una red neuronal posee una **arquitectura** que describe el conjunto de conexiones entre neurona y un proceso de **aprendizaje** asociado, que describe el proceso entrenamiento.\n",
    "\n",
    "Las **neuronas** por tanto, pueden ser definidas por medio de la siguiente relación:\n",
    "$$\n",
    "y=f\\left(\\sum_{i} x_{i} w_{i}+b\\right)\n",
    "$$\n",
    "\n",
    "Acá se hace el calculó $w^t x + b = \\sum_i x_i w_i + b$ sobre los inputs $x_i$ y los pesos $w_i$. Estos últimos, son valores numéricos que representan las conexiones entre neuronas, el peso $b$ se denomina *bias*. Luego se calcula el resultado de aplicar la función de activación $f(\\cdot)$. Existen distintos tipos de funciones de activación dentro de estas se pueden nombrar:\n",
    "\n",
    "* $f(x)=x$ la función identidad.\n",
    "* $f(x)=\\left\\{\\begin{array}{l}1 \\text { if } x \\geq 0 \\\\ 0 \\text { if } x<0\\end{array}\\right.$ la función de activación de umbral.\n",
    "* $f(x)=\\frac{1}{1+\\exp (-x)}$ la función sigmoide logistica, es una de las más utilizadas.\n",
    "* $f(x) =\\frac{1-\\exp (-x)}{1+\\exp (-x)}$ la función sigmoide bipolar, esta corresponde a una sigmoide escalada a $(-1,1)$.\n",
    "* $f(x) = \\frac{1-\\exp (-2 x)}{1+\\exp (-2 x)}$ la tangente hiperbólica. \n",
    "\n",
    "* $f(x)=\\left\\{\\begin{array}{l}x\\text { if } x \\geq 0 \\\\ 0 \\text { if } x<0\\end{array}\\right.$ La función de activación ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Existen variantes de la función de activación ReLU, investigue al menos 3 y compare sus diferencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por su parte, las **capas de una red** conforman su arquitectura al agrupar conjuntos de neuronas. Acá se puede distinguir la *capa input* que representa las condiciones iniciales del dataset. La *capa output* puede tener una neurona (ej: problemas de regresión) o más (como en el ejemplo anterior). Si hay capas entre el input y el output, estas se denominan *capas ocultas*. En general las capas pueden estar completamente conectadas (como en el ejemplo implementado) o pueden faltar conexiones entre neuronas, esto se puede representar por los valores de los pesos, por ejemplo, el si denotamos $w_{ij}^{(k,k+1)}$ como los pesos entre el output de la neurona $i$ en la capa $k$ con el input de la neurona $j$ de la capa $k+1$, un peso $w_{ij}^{(k,k+1)} = 0$ implica que la neurona $j$ esima de la capa $k+1$ no posee interacción con la neurona $i$ esima de la capa $k$. \n",
    "\n",
    "**Ejercicios**\n",
    "\n",
    "1. El esquema presentado en el ejemplo anterior implica que las capas de una red deben conectarse de manera secuencial. En general esto no tiene porque ser cierto, en efecto, las conexiones entre capas pueden ser modeladas por medio de grafos *acíclicos dirigidos*. ¿Por qué es necesario utilizar grafos de este tipo? \n",
    "\n",
    "2. El teorema de aproximación universal para redes neuronales dice que toda función continua en un compacto de $\\mathbb{R}^n$ puede ser aproximada por una red neuronal con al menos una capa oculta. Para tener una intuición sobre esto, observe que es posible aproximar funciones continuas por medio de sumas ponderadas de *funciones boxcar* o *cajón*, estás, para una altura $A$ y base $(b-a)$ , $b >a$ se puede escribir como $\\operatorname{boxcar}(x)=A(H(x-a)-H(x-b))$, donde:\n",
    "$$\n",
    "H(x)=\\left\\{\\begin{array}{ll}0, & x<0 \\\\ 1, & x\\geq 0\\end{array}\\right.\n",
    "$$ \n",
    "\n",
    "Implemente una función boxcar utilizando una red neuronal con inputs en $x \\in \\mathbb{R}$, una capa oculta de dos neuronas, cada una con función de activación $f(x) = 1 /(1+\\exp (-x))$, la red genera un output $y \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de aprendizaje en redes pasa por definir un **esquema de entrenamiento**. Esto hace referencia a encontrar un conjunto de conexiones óptimas entre las las neuronas de la arquitectura para generar predicciones. Estas conexiones optimas se representan por los pesos de la red en cada capa y se entrenan en función de algún esquema de optimización (Descenso de gradiente por ejemplo).\n",
    "\n",
    "Observemos por ejemplo una regresión lineal, en este caso la red consta de una capa oculta, un output unidimensional y la función de activiación identidad. Es posible entrenar una regresión lineal utilizando descenso de gradiente, para ello se define el función a minimizar $J$ como:\n",
    "$$\n",
    "J = \\frac{1}{n} \\sum_{i=0}^{n}\\left(y_{i}-t_{i}\\right)^{2}=\\frac{1}{n} \\sum_{i=0}^{n}\\left(w^t x_{i} - {i}\\right)^{2}\n",
    "$$\n",
    "\n",
    "En este caso $y_i$ representa el output del modelo lineal. El funcional a minimizar es el error cuadrátrico medio. El esquema de descenso de gradiente para este modelo pasa a ser:\n",
    "$$\n",
    "w \\rightarrow w-\\lambda \\nabla(J(w))\n",
    "$$\n",
    "\n",
    "El cual se detiene al llegar a cierto umbral para $J$ o luego de cierto número de iteraciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Encuentre una expresión exacta para $\\nabla(J(w))$ e implemente un esquema de descenso de gradiente para la regresión lineal. ¿Qué nombre se asocia al parámetro $\\lambda$ en esquema $w \\rightarrow w-\\lambda \\nabla(J(w))$?¿Cuál es su función?\n",
    "\n",
    "2. El esquema de regresión logística corresponde a una red neuronal idéntica a la utilizada para regresión lineal, con la salvedad de que posee una función de activación sigmoide logística. Calcule un esquema de descenso de gradiente para este tipo de red. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe observar que al implementar el esquema anterior, se produce una acumulación de error en todo en conjunto de entrenamiento. En conjunto de datos grandes esto no es práctico. Una solución es implementar *Descenso de Gradiente Estocástico*, este algoritmo consiste en aproximar los pesos del esquema anterior sobre un subconjunto de observaciones del conjunto de entrenamiento, este subconjunto se denota como **mini -batch**.\n",
    "\n",
    "Las redes de una capa oculta (regresión logística y lineal) poseen reglas sencillas de actualización según la función de activación, con esto se pueden actualizar los pesos de cada conexión utilizando el error de predicción como referencia. En redes con múltiples capas sólo se puede aplicar esta técnica a las neuronas de la última capa oculta, esto pues, no se tienen valores reales (*target*) con los cuales comparar los resultados de las capas ocultas intermedias. En este caso, lo que se hace es calcula el error de la ultima capa oculta para luego hacer una **estimación** del error cometido en la capa oculta anterior, este proceso se hace de manera recurrente hasta llegar a la capa inicial. Tal proceso de denota como *propagación hacia atrás* (**backpropagation**). Este algoritmo es la base del aprendizaje con redes neuronales. Para comprenderlo es necesario definir los siguientes conceptos:\n",
    "\n",
    "\n",
    "1. Se define $w_ij$ como el peso entre la neurona $i$ esima de la capa $l$ con la neurona $j$ esima de la capa $l+1$. Es decir, el subindice izquierdo hace referencia a una capa anterior a la que neurona que representa el subindice derecho. Al convención $l$ hace referncia a cualquier capa oculta de la red.\n",
    "\n",
    "2. Se utiliza $y$ para denotar inputs y outputs entre capas.  Es decir, $y_i$ es el input de la capa $l+1$ pero también el output de la capa $l$. \n",
    "\n",
    "3. El funcional de pérdida se denota como $J$, el valor de activación $w^t x$ se denota como $a$.\n",
    "\n",
    "4. Si $a_j$ es una función de activación con pesos $w_j$, $y_j$ es una función de $a_j$ y $J$ es función de $y_j$. Según la regla de la cadena se tiene así:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{i, j}}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} \\frac{\\partial a_{j}}{\\partial w_{i, j}}\n",
    "$$\n",
    "\n",
    "5. Como se sabe que $\\frac{\\partial a_{j}}{\\partial w_{i, j}}=y_{i}$, se tiene:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{i, j}}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} y_{i}\n",
    "$$\n",
    "\n",
    "6. Para las capas anteriores se cumple la misma formula (por notación):$$\n",
    "\\frac{\\partial J}{\\partial w_{i, j}}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} \\frac{\\partial a_{j}}{\\partial w_{i, j}}\n",
    "$$\n",
    "Aunque se tengan muchas capas, siempre es posible concentrarse en pares de capas consecutivas, por que se logra siempre tener una capa input y una capa output. Como se sabe que $\\frac{\\partial a_{j}}{\\partial w_{i, j}}=y_{i}$, es decir, la derivada parcial del valor de  activación de la neurona $j$-ésima en la capa $l+1$ con respecto al peso de la conexión del output $y_j$ entre las capas $l$ y $l+1$ con la neurona $i$-ésima, es justamente el valor del output sin ser ponderado por el peso de la conexión. Más aún, $\\frac{\\partial y_{j}}{\\partial a_{j}}$ es la derivada de la función de activación que se puede calcular. Entonces, en la expresión obtenida por la regla de la cadena, sólo hace falta calcular $\\frac{\\partial J}{\\partial y_{j}}$, la derivada del error con respecto a la función de activación en la segunda capa. Con esto, se pueden calcular todas las derivadas partiendo desde la última capa hacia atrás pues:\n",
    "    * Se puede calcular esta derivada para la última capa\n",
    "    * Se tiene la formula que permite calcula la derivdada de una capa, teniendo calculada la derivada de la capa siguiente. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "En la siguiente ecuación, $y_i$ es el output de la primera capa, $y_j$ el ouput de la segunda capa. Aplicando la regla de la cadena se tiene:\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial y_{i}}=\\sum_{j} \\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial y_{i}}=\\sum_{j} \\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} \\frac{\\partial a_{j}}{\\partial y_{i}}\n",
    "$$\n",
    "\n",
    "Se puede calcular $\\frac{\\partial y_{j}}{\\partial a_{j}}$ y $\\frac{\\partial a_{j}}{\\partial y_{i}}=w_{i, j}$ , si $\\frac{\\partial J}{\\partial y_{j}}$ es conocido (gradiente en la capa segunda), se puede calcular $\\frac{\\partial J}{\\partial y_{i}}$ (gradiente en la capa primera). En resumen, si se tienen 3 capas conectadas de manera secuencia según los inputs (outputs) $y_i \\rightarrow y_j \\rightarrow y_k$ entonces se pueden aplicar las ecuaciones:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{i, j}}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} \\frac{\\partial a_{j}}{\\partial w_{i, j}}\n",
    "$$\n",
    "\n",
    "y \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial y_{j}}=\\sum_{k} \\frac{\\partial J}{\\partial y_{k}} \\frac{\\partial y_{k}}{\\partial y_{j}}\n",
    "$$\n",
    "\n",
    "Para calcular las derivadas del costo en cada capa. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al definir $\\delta_{j}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}}$, se tiene que $\\delta_j$ representa la variación de costo con respecto a cada valor de activación. Con esto se puede reescribir:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial y_{i}}=\\sum_{j} \\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial y_{i}}=\\sum_{j} \\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}} \\frac{\\partial a_{j}}{\\partial y_{i}}=\\sum_{j} \\delta_{j} w_{i, j}\n",
    "$$\n",
    "\n",
    "Con lo que $\\delta_{i}=\\left(\\sum_{j} \\delta_{j} w_{i, j}\\right) \\frac{\\partial y_{i}}{\\partial a_{i}}$. Esto se traduce en poder calcular la variación para la siguiente capa:\n",
    "\n",
    "$$\\delta_{j}=\\frac{\\partial J}{\\partial y_{j}} \\frac{\\partial y_{j}}{\\partial a_{j}}$$\n",
    "\n",
    "$$\\delta_{i}=\\left(\\sum_{j} \\delta_{j} w_{i, j}\\right) \\frac{\\partial y_{i}}{\\partial a_{i}}$$\n",
    "\n",
    "Combinando las ecuaciones:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{i, j}}=\\delta_{j} \\frac{\\partial a_{j}}{\\partial w_{i, j}}=\\delta_{j} y_{i}\n",
    "$$\n",
    "\n",
    "Con lo que la regla de actualizació para los pesos de cada capa pasa a ser: \n",
    "\n",
    "$$\n",
    "w_{i, j} \\rightarrow w_{i, j}-\\eta \\delta_{j} y_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Pytorch es posible implementar reglas de actualización basadas en propagación hacia atrás de manera automática. Para ello, es necesario comprender los tipos de datos asociados a esta librería. \n",
    "\n",
    "En primer lugar, se tienen los **tensores**, estos son arreglos n dimensionales, soportan almacenamiento en GPU. Poseen el atributo booleano `.requires_grad`, si es verdadero, un objeto tipo `Tensor` generará un grafo en cual se registra cada operación aplicada sobre él. Este grafo es utilizado para calcular gradientes de manera automática utilizando y se denota como grafo dinámico de computación DCG.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se define un tensor en Pytorch que hace uso del DCG para registrar operaciones y calcular gradientes. Pytorch se mimetiza con NumPy en cuanto a la definición de sus métodos y compatibilidad cruzada, por ejemplo, para definir un arreglo de 2x2 que requiera del uso de DCG se puede utilizar la función `randn` (análoga a la de NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 2, requires_grad = True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden importar arreglos de numpy de manera bastante sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(2,2)\n",
    "x = torch.from_numpy(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma forma se puede activar el uso de gradientes en objetos importados desde NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como observación, se debe tener en cuenta que sólo es posible calcular gradientes para tensores de punto flotante. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otra parte, la clase `Autograd` es el motor sobre el cual se calculan las derivadas. Esta clase registra todas las operaciones en un grafo acíclico dirigido. . Las hojas de este grafo son los tensores input y las raices son los tensores output. Los gradientes se calculan recorriendo el grafo desde la raiz a la hoja, multiplicando cada gradiente según la regla de la cadena. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se crea un grafo usando tensores que requieren gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(5.0, requires_grad = True)\n",
    "y = torch.tensor(1.0)\n",
    "z = x * y + 1\n",
    "\n",
    "# Componentes del grafo\n",
    "for i, name in zip([x, y, z], \"XYZ\"):\n",
    "    \n",
    "    \n",
    "    print(f\"{name}\\ndata: {i.data}\\nrequires_grad: {i.requires_grad}\\n\\\n",
    "grad: {i.grad}\\ngrad_fn: {i.grad_fn}\\nis_leaf: {i.is_leaf}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer operaciones sin registrar gradientes se utiliza el context manager `torch,no_grad()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(25.0, requires_grad=True)\n",
    "y = x * 2\n",
    "\n",
    "print('Se requiere gradiente en y:', y.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "    print('Se requiere gradiente en y (context manager): ', y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `.backward()` calcula los gradientes al aplicarse sobre un **valor escalar** (tensor unitario) esto se recorriendo el grafo generado por las operaciones que le dan origen a tal valor. Los gradientes calculados se guardan en el atributo `.grad` de cada nodo hoja. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se estudia el gradiente de una función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera el grafo de manera dinamica en cada operacion\n",
    "x = torch.tensor(5.0, requires_grad = True)\n",
    "z = x ** 3\n",
    "\n",
    "# Se calculan los gradientes\n",
    "z.backward() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso anterior, se tiene la función $z = x^3$ cuyo gradiente con respecto a $x$ es $3x^2$ que evaluado en $x=5$ pasa a ser $75$. Se confirma lo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se llama `z.backward()` se pasa como argumento el tensor unitario `torch.tensor(5.0)`, es decir, se calcula `z.backward(torch.tensor(5.0))`, en este caso, dicho argumento es el *gradiente externo* utilizado para terminar las multiplicaciones asociadas a la regla de la cadena. Por ejemplo, si se tienen los tensores :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0, 4.0, 8.0], requires_grad = True)\n",
    "y = torch.tensor([1.0 , 3.0 , 5.0], requires_grad = True)\n",
    "\n",
    "z = x*y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward(torch.tensor([1.0,1.0,1.0]))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, para calcular los gradientes de `z` con respecto a `x` o a `y`, se debe entregar un gradiente externo de dimensión 3. Este tensor actúa como los pesos de un gradiente ponderado. Es decir, corresponde a multiplicar un vector de pesos por la matriz jacobiana. En término generales, la clase Autograd permite calcular productos de la matriz jacobiana con vectores de gradiente de la forma:\n",
    "\n",
    "$$\n",
    "J \\cdot v=\\left(\\begin{array}{ccc}\\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\\end{array}\\right)\\left(\\begin{array}{c}\\frac{\\partial l}{\\partial y_{1}} \\\\ \\vdots \\\\ \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)=\\left(\\begin{array}{c}\\frac{\\partial l}{\\partial x_{1}} \\\\ \\vdots \\\\ \\frac{\\partial l}{\\partial x_{n}}\\end{array}\\right)\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
