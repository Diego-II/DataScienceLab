{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "**Profesor: Nicolás Caro** \n",
    "\n",
    "**22/07/2020 - S15** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puesta en Marcha: Introducción a Flask\n",
    "\n",
    "La puesta en marcha o *despliegue* consiste en el flujo de trabajo necesario para hacer que una aplicación pasa de un estado de desarrollo experimental (prueba de concepto) a ser una versión de *producción* donde el usuario final tendrá acceso. \n",
    "\n",
    "Para poner en marcha nuestros proyectos de ciencia de datos, haremos uso de *aplicaciones web*. Estas consisten programas diseñados para ejecutarse desde un servidor web. Esta aproximación nos permitirá facilitar resultados y visualizaciones a una amplia variedad de sistemas. \n",
    "\n",
    "En Python existen conjuntos de herramientas para desarrollo, dentro de estas se utilizará Flask por su enfoque minimal. Antes de estudiar esta herramienta, estudiamos el manejo de entornos virtuales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambientes Virtuales\n",
    "\n",
    "Cada aplicación de Python posee sus requerimientos en cuanto a las librerías sobre las cuales se basa. Esto hace que en algunas oportunidades se trabaje en aplicaciones que requieran distintas versiones de una misma librería o que trabajen sobre versiones distintas de Python. En este caso, una instalación global de Python no permitiría trabajar de manera fluida, pues se necesitaría reinstalar paquetes de distintas versiones cada vez que se cambie de aplicación.\n",
    "\n",
    "Para solucionar el problema anterior aparecen los **entornos virtuales**, estos consisten en conjuntos de carpetas autocontenidos en cuanto a sus dependencias, para lograr esta independencia, cada entorno irtual presenta su propia instalación de Python, pudiendo elegir incluso que versión del lenguaje se desea instalar. \n",
    "\n",
    "En general se recomienda el uso de entornos virtuales para manejar dependencias de proyectos de software basados en Python, tanto en el desarrollo de estos como como en su puesta en marcha o producción.\n",
    "\n",
    "Python 3 posee un módulo que permite crear entornos virtuales, este es `venv`, cabe destacar que esta librería no es la única forma de manejar entornos virtuales (ej: conda ofrece una herramienta similar) pero si es la estándar en el stack de Python. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Para crear un entorno virtual, nos localizamos en la carpeta raíz de nuestro proyecto, en este caso será `./ProjectLab`, sobre tal carpeta inicializamos un entorno virtual usando `venv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ProjectLab\n",
    "!python -m venv entorno_virtual\n",
    "\n",
    "#En windows la orden es\n",
    "#py -m venv entorno_virtual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "con lo anterior, se ha creado un a carpeta llamada `./ProjectLab/entorno_virtual` la cual contiene el código necesario para generar un entorno virtual independiente de la instalación global de Python. Para acceder a dicho entorno ejecutamos el archivo `activate` dentro de la carpeta `./entorno_virtual/bin` esto se hace por medio de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!. entorno_virtual/bin/activate\n",
    "\n",
    "# En Windows\n",
    "# entorno_virtual\\Scripts\\activate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "una vez activado un entorno virtual, no encontramos localmente dentro una nueva instalción de Python, la cual maneja sus propias dependencias, en este caso, si buscamos importar un paquete de la instalación global (ej: Numpy o cualquier otra librería de terceros), no se podrá acceder, pues mientras el ambiente viertual este activado, se ignora la instalación global. \n",
    "\n",
    "Para trabajar en conjunción con notebooks de Jupyter podemos instalar la librería `ipykernel` en nuestro entorno virtual, esto lo hacemos por medio de las ordenes:\n",
    "\n",
    "```\n",
    "user@ruta/a/proyecto$ . entorno_virtual/bin/activate  \n",
    "user@ruta/a/proyecto$ pip install ipykernel\n",
    "```\n",
    "\n",
    "Donde `user@ruta/a/proyecto$` hace referencia a que se debe ejecutar en la carpeta de nuestro proyecto `ProjectLab` desde una consola, no funcionará usando el comando `!` en una celda. \n",
    "\n",
    "**Obs:** En Windows equivale a activar el ambiente y luego instalar el paquete `ipykernel` usando pip. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez instalada la librería podemos registrar el kernel asociado a nuestro entorno virtual, para ello ejecutamos \n",
    "\n",
    "```\n",
    "(entorno_virtual) user@ruta/a/proyecto$ python -m ipykernel install --user --name entorno_virtual --display-name \"Python (entorno_virtual)\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde la linea `(entorno_virtual) user@ruta/a/proyecto$` indica que se ejecuta dentro de un entorno virtual activado. Esta linea instala un kernel llamado `entorno_virtual` asociado a nuestro entorno de ejecución actual (indicado en la consola) que corresponde en este caso al entorno virtual activado. El nombre con el cual aparece dicho kernel en un notebook de Jupyter será `\"Python (entorno_virtual)\"`. Finalmente, podemos cambiar de kernel usando la opción `kernel -> change kernel -> Python (entorno_virtual)` (puede ser necesario actualizar la página sociada al notebook actual). \n",
    "\n",
    "\n",
    "Con lo anterior, el notebook se reinicia pero se tiene conexión directa con el entorno virtual creado.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se cambia de kernel pasando al creado recientemente, como nos encontramos en una instalación nueva de Python no habrá disponibilidad a paquetes instalados en el entorno global. Intentaremos acceder a NumPy desde este nuevo kernel asociado al entorno virtual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\n",
    "    import numpy\n",
    "    print('Numpy instalado en este entorno virtual')\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    \n",
    "    print('Modulo NumPy no encontrado en este entorno virtual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que confirmamos que nos encontramos accediendo al nuevo entorno virtual. Lamentablemente, el comando `!` está asociado al entorno en el cual se ejecuta Jupyter al iniciar y no al kernel con el que estamos trabajando, por tal motivo, si ejecutamos `!pip install numpy` desde una celda, no se instalará en el entorno virtual. Para instalar librerías, necesitamos por tanto instalarlas directamente desde la consola habiendo activado el entorno virtual previamente. \n",
    "\n",
    "Para salir de un entorno virtual basta con *desactivarlo*, esto se hace ejecutando la orden `deactivate` desde la consola en un entorno virtual previamente activado. Este comando se agrega a la consola / terminal cada vez que activamos un entorno virtual por lo que podemos ejecutarla desde cualquier carpeta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción a Flask\n",
    "\n",
    "`Flask` es un *micro web framework* escrito en Python. Es decir, corresponde a un conjunto de herramientas para desarrollo web (web framework) minimal (micro). En este sentido, el prefijo *micro* hacer referencia a que una aplicación debe ser sencilla en sus componentes, esto no afecta a la funcionalidad, pues se tiene acceso a multiples extensiones, así la minimalidad del framework hace referencia a mantener un núcleo simple pero a la vez extensible, logrando así que el programador tenga total control sobre que componentes integrar, evitando redundancia en el código y complejidades extra.\n",
    "\n",
    "Para instalar Flask hacemos uso de la sintaxis usual. Esta vez se recomienda hacerlo dentro de un entorno virtual, de manera que se pueda desarrollar una aplicación web autocontenida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Instale flask `pip install flask` dentro del entorno virtual `entorno_virtual` creado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask permite crear aplicación que hace uso de la convención WSGI (**W**eb  **S**erver **G**ateway **I**nterface - *whiskey*), esta consiste en un protocolo de servidores web para el manejo de consultas por medio de aplicaciones o frameworks de Python. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Creamos una aplicación minimal usando Flask, para ello importamos la clase `Flask`, la cual corresponde a una aplicación WSGI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se crea un objeto como instancia de dicha clase. El primer argumento de este objeto en su constructor, será el nombre del módulo al cual dicha aplicación pertenece. Al usar solamente un módulo, se recomienda utilizar la variable de sistema `__name__`. Esta variable entrega el nombre del módulo sobre el cual se ejecuta. Observemos su comportamiento :\n",
    "\n",
    "1. Se crea un módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file modulo_1.py\n",
    "\n",
    "def func1():\n",
    "    print('Valor de __name__ : ' + __name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Se importa dicho módulo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modulo_1\n",
    "\n",
    "modulo_1.func1() \n",
    "print('Valor de __name__ fuera del modulo:' + __name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que dentro del módulo creado, la variable `__name__` cambia, esto permite asociar una aplicación de Flask al módulo sobre el cual se desea operar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se iniciado una aplicación de Flask, la cual buscará dependendcias en el módulo `__name__` (`__main__` en este caso).\n",
    "\n",
    "El siguiente paso es usar un *decorador de ruta*  `route(url)`, el cual le dice a Flask que acción tomar (que función ejecutar) cuando se accede a la dirección `url`. De esta manera, se define una función de bienvenida, la cual se activa cuando accedemos a la dirección raíz de la aplicación `/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el nombre de la función decorada se utiliza para generar urls de manera automática, la orden `return` de la función será el mensaje mostrado en el navegador.\n",
    "\n",
    "Procedemos a crear un módulo con la aplicación generada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ejecutar la aplicación generada se puede utilizar el comando `flask` desde la terminal (análogo a pip), sin embargo, antes de ejecutarla, es necesario indicarle a la terminal que aplicación se ejecutará con el comando `flask`. Esto corresponde a una variable del sistema llamada `FLASK_APP`, darle el valor que necesitamos utilizamos el comando `export`(linux - mac):\n",
    "\n",
    "```\n",
    "(entorno_virtual) user@ruta/a/ProjecLab$ export FLASK_APP=app_minimal.py\n",
    "```\n",
    "\n",
    "En windows se utiliza `C:\\ruta\\a\\ProjecLab>set FLASK_APP=app_minimal.py`. Luego de exportar la aplicación desde la terminal, se procede a lanzar la aplcación usando el comando:\n",
    "\n",
    "```\n",
    "(entorno_virtual) user@ruta/a/ProjecLab$ flask run\n",
    "```\n",
    "\n",
    "El ejecutar dicha orden se indica una url con la cual se accede a la aplicación, por lo general es del tipo `http://127.0.0.1:5000/`. Con esto, hemos utilizado el servidor interno de flask en nuestro computador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aplicación anterior se mantiene funcionando como servidor de desarrollo pero requiere de un reinicio cada vez que se se haga un cambio al código. Para solucionar dicho problema existe el modo de depuración *debug mode*. Al activar este modo el servidor se recarga a si mismo al generar cambios en los módulos que lo componen. \n",
    "\n",
    "La activación del modo de depuración se hace por medio de la variable de sistema `FLASK_ENV` que se debe exportar como `development`.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se exporta el ambiente de depuración y se corre nuevamente la aplicación usando `flask run` todo desde la terminal.\n",
    "\n",
    "```\n",
    "(entorno_virtual) user@ruta/a/ProjecLab$ export FLASK_ENV=development\n",
    "(entorno_virtual) user@ruta/a/ProjecLab$ flask run\n",
    "```\n",
    "\n",
    "Con lo anterior, se activa el depurador, la carga automática y activa el modo de depuración en la aplicación creada. \n",
    "\n",
    "Aunque el depurardor permite la ejecución de código arbitrario, lo que se traduce en riesgos de seguridad, por tal motivo no debe ser utilizado en entornos de producción. \n",
    "\n",
    "Se cambia el texto de la aplicación y se recarga en el navegador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal! con depuracion'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Introduzca un error en la función anterior e identifiquelo a partir del depurador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ruteo de urls**\n",
    "\n",
    "Una aplicación web utiliza urls para acceder a sus funcionalidades y contenidos, esto además ayuda a los usuarios a comprender la estructura del sitio que se les presenta. Para manejar el acceso a urls dentro de la aplicación hacemos uso del decorador `@app.route()`.\n",
    "\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se construye una página de bienvenida una de saludo dentro de la aplicación `aplicación minimal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'\n",
    "\n",
    "@app.route('/hola') \n",
    "def funcion_saludo():\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accedemos a la nueva función usando la url `127.0.0.1:5000/hola`.\n",
    "\n",
    "Como es posible observar, el decorador recibe un string indicando la url a la cual se asocia el procedimiento de una función. Este tipo de dato permite generar urls dinámicas utilizando **reglas variables**. \n",
    "\n",
    "Una regla variable permite aplicar funciones sobre urls dinámicas, para ello se utiliza la sintaxis `<variable>` entro de la url a la cual está asociada la función que deseamos operar. De tal manera, si creamos una función `func ` que recibe como argumento una la variable `id`  entonces se puede generar una regla variable con la url `/ruta/a/la/url/<id>` luego decoramos la función `func` con la url anterior.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se implementa el caso recientemente explorado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'\n",
    "\n",
    "@app.route('/hola/<user>') \n",
    "def funcion_saludo(user):\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...' + user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al acceder a la aplicación anterior, si entramos a la url `127.0.0.1:5000/hola/estudiante` recibimos la ejecución de `funcion_saludo('estudiante')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Se pueden indicar tipos de dato `string`,`int`,`float`,`path`,`uuid` mediante la notación `<dtype:varname>` donde `dtype` es el tipo de dato escogido para operar. Implemente una función que reciba un valor de punto flotante como input. ¿Qué diferencia hay entre `string` y `path`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask opera sobre las urls entregadas de manera especial. Por ejemplo, al agregar las funciones `proyectos` y `acerca` estamos asociando las urls `'/proyectos/'` y `'/acerca'`. \n",
    "\n",
    "En el caso de`'/proyectos/'`, si accedemos a la url `127.0.0.1:5000/proyectos`, seremos redirigidos a `127.0.0.1:5000/proyectos/` es decir agregará el simbolo `/` al final de la url. \n",
    "\n",
    "Por el contrario, si accedemos a `127.0.0.1:5000/acerca/` no habrá redirección a la versión sin `/`. Es decir acceder a `127.0.0.1:5000/acerca/` lanza un error pero `127.0.0.1:5000/proyectos` no. Para entender este comportamiento, pensemos en las urls como rutas de acceso a carpetas (terminan con `/`) y archivos (terminan si `/`). Si intentamos a acceder a una carpeta con notación de archivo, seremos redirigidos a la carpeta, por otra parte, si intentamos acceder a un archivo con notación de carpeta habrá un error pues no existe una ruta con el nombre que buscamos. \n",
    "\n",
    "Se comprueba lo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask \n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'\n",
    "\n",
    "@app.route('/hola/<user>') \n",
    "def funcion_saludo(user):\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...' + user\n",
    "\n",
    "@app.route('/proyectos/')\n",
    "def proyectos():\n",
    "    return 'Pagina de proyectos.'\n",
    "\n",
    "@app.route('/acerca')\n",
    "def acerca():\n",
    "    return 'Pagina de informacion sobre el autor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir urls a una función en especifico se puede utilizar la función `url_for()`, esta función toma como argumento el nombre de una función y un diccionario de argumentos pcional `**kwargs` asociado a la función. La utilidad de `url_for()` es permitir la construcción de urls dinámicas, en el sentido de que modificar múltiples rutas se hace más sencillo que cambiarlas manualmente una por una. \n",
    "\n",
    "La construcción de urls por medio de ese método hace un manejo automático de caracteres especiales, además las rutas generadas se construyen de manera absoluta, evitando comportamientos inesperados usuales con rutas relativas en navegadores. \n",
    "\n",
    "Si se tiene una aplicación ubicada fuera de la raiz de la url (ej: aplicación ubicada en `/aplicación` en vez de `/`),  `url_for` permite su manejo sencillo. \n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se utiliza el context manager `text_request_context()` del módulo `app`. Este permite navegar por una aplicación de Flask desde Python, emulando accesos a funciones.  Se procede a obtener las urls para las funciones anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask, url_for\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def bienvenida():\n",
    "    return 'Bienvenida/o a la app minimal!'\n",
    "\n",
    "@app.route('/hola/Fulano')\n",
    "def funcion_saludo_0():\n",
    "    return 'SI ...'\n",
    "\n",
    "@app.route('/hola/<user>')\n",
    "def funcion_saludo(user,va):\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...' + user + va\n",
    "\n",
    "@app.route('/proyectos/')\n",
    "def proyectos():\n",
    "    return 'Pagina de proyectos.'\n",
    "\n",
    "\n",
    "@app.route('/acerca')\n",
    "def acerca():\n",
    "    return 'Pagina de informacion sobre el autor'\n",
    "\n",
    "\n",
    "with app.test_request_context():\n",
    "    print('URL: Funcion bienvendia ->', url_for('bienvenida'))\n",
    "    print('URL: Funcion funcion_saludo ->',url_for('funcion_saludo_0'))\n",
    "    print('URL: Funcion funcion_saludo ->',url_for('funcion_saludo', user='Fulano'))\n",
    "    print('URL: Funcion acerca ->',url_for('acerca'))\n",
    "    print('URL: Funcion proyectos ->',url_for('proyectos'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las aplicaciones web utilizan distintos métodos HTTP (Hypertext Transfer Protocol) al momento de acceder a urls, estose se conocen tambien como verbos, dentro de los cuales se pueden reconocer `GET` consultar sobre un recurso especifico (solo reciben datos), `HEAD`, de la misma manera que `GET` solo recibe información pero acá se busca acceder al identificador de la información y no a su contenido total (cuerpo), `POST`, este método se utiliza para enviar recursos causando por lo genear un cambio de estado en el servidor y `PUT` que remplaza recursos objetivo.\n",
    "\n",
    "**Ejercicio**\n",
    "\n",
    "1. Investigue sobre los verbos HTTP existentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, una ruta de Flask soo responde a consultas `GET`, sin embargo, el ecorador `app.route()` puede recibir el argumento `methods` con el cual se pueden especificar los tipos de métodos HTTP soportados por la función que decora.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Para utilizar el parámetro `methods` en el enrutamiento, importamos el objeto `requests` con el cual se puede identificar que tipo de consulta. \n",
    "\n",
    "Generaremos una página de `login` desde la cual un usuario podrá registrarse, haremos uso de la función `url_for()` y de la capacidad de Flask para manejar ordenes HTML. \n",
    "\n",
    "En primer lugar, creamos la página en la cual se hará el registro, esta consiste en un archivo HTML con la siguiente estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()\n",
    "\n",
    "try:\n",
    "    os.mkdir('templates')\n",
    "\n",
    "except FileExistsError:\n",
    "    print('Directorio ya existe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un template de login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file templates/login.html \n",
    "<html>\n",
    "   <body>\n",
    "    \n",
    "      <form action = \"http://localhost:5000/login\" method = \"post\">\n",
    "         <p>Buenas, ingresa tu nombre:</p>\n",
    "         <p><input type = \"text\" name = \"nm\" /></p>\n",
    "         <p><input type = \"submit\" value = \"submit\" /></p>\n",
    "      </form>\n",
    "    \n",
    "   </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior genera una página que consulta por la variable `name` generando una consulta `POST`. El texto ingresado en la página se almacena con el campo `nm` dentro de un diccionario asociado a la consulta `POST`. \n",
    "\n",
    "Añadiremos la función `exito` que recibe un nombre y le da la bienvenida, tambén implementamos la función de login, esta utiliza el objeto `request` para diferenciar que tipo de consulta se está realizando. Se decora dicha función utilizando el parámetro `methods`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return render_template('login.html')\n",
    "\n",
    "@app.route('/hola/<user>') \n",
    "def funcion_saludo(user):\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...' + user\n",
    "\n",
    "@app.route('/proyectos/')\n",
    "def proyectos():\n",
    "    return 'Pagina de proyectos.'\n",
    "\n",
    "@app.route('/acerca')\n",
    "def acerca():\n",
    "    return 'Pagina de informacion sobre el autor'\n",
    "\n",
    "#Exito\n",
    "@app.route('/exito/<name>') \n",
    "def exito(name):\n",
    "    return f'Bienvenido {name}'  \n",
    "\n",
    "#Login\n",
    "@app.route('/login', methods = ['POST', 'GET'])\n",
    "def login():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['nm'] \n",
    "        return  redirect(url_for('exito',name = user))\n",
    "    else:\n",
    "        user = request.args.get('nm')\n",
    "        return 'Login fallido'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior utilizamos la función `render_template`. Con esta función es posible renderizar plantillas HTML directamente desde Flask. Para usar dicha funcionalidad  se requiere ubicar las plantillas a utilizar en una carpeta llamada `templates`, en este caso, si trabajamos con estructura de módulo, las carpetas deberían seguir el patrón:\n",
    "\n",
    "```\n",
    "|- /modulo.py\n",
    "|- /templates\n",
    "|-----/template_html_a_utilizar.html\n",
    "```\n",
    "\n",
    "En el caso de trabajar con librerías:\n",
    "\n",
    "```\n",
    "|- /libreria\n",
    "|----/__init__.py\n",
    "|----/templates\n",
    "|---------/template_html_a_utilizar.html\n",
    "```\n",
    "\n",
    "Para generar plantillas (*templates*) se puede utilizr [Jinga2](jinja.pocoo.org/docs/templates/). Esta librería consiste en un lenguaje de diseño diámico sencillo y rápido. Veamos un ejemplo de template Jinga2 y observemos como interactua con el entorno de Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '--Test--'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "name": {}
    }
   },
   "source": [
    "```html\n",
    "<!doctype html>\n",
    "<title> En Flask esto se vería así: </title>\n",
    "\n",
    "{% if name %}\n",
    "    <h1> Variable inicializada {{name}} </h1>\n",
    "\n",
    "{% else %}\n",
    "    <h1> No hay variable inicializada!</h1>\n",
    "\n",
    "{% endif %}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que se tiene acceso a funcionalidades de Python mediante la sintaxis `{% %}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general, podemos utilizar una estructura de herencia de plantillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file templates/layout.html \n",
    "\n",
    "<!doctype html>\n",
    "<html>\n",
    "  <head>\n",
    "    {% block head %}\n",
    "    <link rel=\"stylesheet\" href=\"{{ url_for('static', filename='style.css')}}\">\n",
    "    <title>{% block title %} {% endblock %} - App Minimal - </title>\n",
    "    {% endblock %}\n",
    "    \n",
    "  </head>\n",
    "\n",
    "  <body>\n",
    "    \n",
    "    <div id=\"content\">\n",
    "    {% block content %}\n",
    "    \n",
    "    {% endblock %}\n",
    "    </div>\n",
    "    \n",
    "    <div id=\"footer\">\n",
    "      {% block footer %}\n",
    "        Copyright 2020 by <a href=\"https://github.com/NicoCaro/DataScienceLab\"> DaScLab </a>.\n",
    "      {% endblock %}\n",
    "    </div>\n",
    "    \n",
    "  </body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior genera una plantilla HTML utilizando Jinga2. Esta se constituye por bloques, los bloques tienen un nombre asociado y se comportan como atributos de un objeto. En este caso el template se denomina `layout.html` y se ubica en la carpeta `template`. Los bloques definidos son `head`, `content` y `footer`. \n",
    "\n",
    "Finalmente, dentro del template utilizamos la función de Python (Flask) `url_for('static', filename='style.css')` la cual accede a la url del componente `static`. Este componente viene por defecto en las aplicaciones de flask (no fue definido en `app_minimal.py`) y permite acceder a archivos ubicados en la carpeta `\\static`. Esta debe seguir la lógica de carpetas presentada en `templates`. En la carpeta `\\static` ubicamos un código de estilo `CSS` llamada `style.css`. Esta  cambia el color de los párrafos (`<p>`), headers (`<h1>`) y del cuerpo (`body`).\n",
    "\n",
    "Podemos pensar que `layout.html` se comporta como una clase, sobre la cual se puede hacer herencia simple. Para ello crearemos una reestructuración del template de `login` para que herede los atributos de `layout.html`. Observe que se puede hacer *overriding* de manera natural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file templates/login.html\n",
    "{% extends \"layout.html\" %}\n",
    "\n",
    "{% block title %} Login {% endblock %}\n",
    "\n",
    "{% block head %}\n",
    "{{ super() }}\n",
    "Buenas, ingresa tu nombre:\n",
    "{% endblock %} \n",
    "                \n",
    "{% block content %}   \n",
    "{{ super() }}\n",
    " <form action = \"{{ url_for('login', filename='style.css')}}\", method = \"post\">\n",
    "         <p><input type = \"text\" name = \"nm\" /></p>\n",
    "         <p><input type = \"submit\" value = \"submit\" /></p>\n",
    "      </form>             \n",
    "{% endblock %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La orden `super()` actua de la misma forma que en un esquema de herencia de objetos. \n",
    "\n",
    "Se construye un template para la página de redirección `extio.html`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file templates/exito.html\n",
    "{% extends \"layout.html\" %}\n",
    "\n",
    "{% block title %} Exito! {% endblock %}\n",
    "\n",
    "{% block head %}\n",
    "{{ super() }}\n",
    "\n",
    "Login Exitoso\n",
    "\n",
    "{% endblock %} \n",
    "                \n",
    "{% block content %}  \n",
    "    {{ super() }}\n",
    "    Bienvenido {{name}}!\n",
    "{% endblock %}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente cambiamos los parámetros que permiten ejecutar nuestra aplicación sobre los templates creados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file app_minimal.py\n",
    "from flask import Flask, redirect, url_for, request, render_template\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/') \n",
    "def bienvenida():\n",
    "    return render_template('login.html') \n",
    "\n",
    "@app.route('/hola/<user>') \n",
    "def funcion_saludo(user):\n",
    "    return 'Has accedido a la pagina de saludo. Hola ...' + user\n",
    "\n",
    "@app.route('/proyectos/')\n",
    "def proyectos():\n",
    "    return 'Pagina de proyectos.'\n",
    "\n",
    "@app.route('/acerca')\n",
    "def acerca():\n",
    "    return 'Pagina de informacion sobre el autor'\n",
    "\n",
    "#Exito\n",
    "@app.route('/exito/<name>') \n",
    "def exito(name):\n",
    "    return render_template('exito.html', name = name)   \n",
    "\n",
    "#Login\n",
    "@app.route('/login',methods = ['POST', 'GET'])\n",
    "def login():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['nm'] \n",
    "        return  redirect(url_for('exito',name = user))\n",
    "    else:\n",
    "        user = request.args.get('nm')\n",
    "        return redirect(url_for('exito',name = user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interludio: Flujo de trabajo \n",
    "\n",
    "El flujo de trabajo de un proyecto de ciencia de datos puede dividirse según ciertos entornos que caracterizan las etapas de desarrollo. \n",
    "\n",
    "El primer paso es comenzar un *entorno de investigación* donde se hace el prototipado del proyecto de ciencia de datos. En este entorno se producen los bloques iniciales de carga de datos, analisis exploratorio y limpieza, ingenieria de características, entrenamiento, validación y finalmente evaluación del modelo final. \n",
    "\n",
    "Al entorno anterior le sigue una etapa de *desarrollo* o *entorno de desarrollo* en el cual se generan los modulos y librerías necesarias para poner en marcha el proyecto. \n",
    "\n",
    "Finalmente, se pasa al *entorno de producción* donde se tiene un proyecto accesible, robusto, controlable y reproducible al que tendrá acceso el usuario final. Sobre esta última etapa se busca construir actualizaciones que mejoren el funcionamiento, ya sea en cuanto a las dependiencias de software como tambien en relación a las dependencias con las fuentes de datos. \n",
    "\n",
    "**Ejemplo - Entorno de Investigación**\n",
    "\n",
    "Se simula un entorno sencillo de investigación, haremos un seguimiento desde su formulación hasta su puesta en producción. \n",
    "\n",
    "El conjunto de datos a trabajar consiste en la base de datos del Titanic, esta base entrega información sobre los pasajeros a bordo del barco homónimo, indicando si estos sobrevivieron al accidente en el que se vieron envueltos. \n",
    "\n",
    "Procedemos a cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(6202)\n",
    "\n",
    "train = pd.read_csv('ProjectLab/data/train.csv') \n",
    "test = pd.read_csv('ProjectLab/data/test.csv')\n",
    "\n",
    "data = pd.concat((train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es hacer una exploración inicial del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver una variedad de tipos de datos, además de valores faltantes, las variables disponibles consisten en:\n",
    "\n",
    "- PassengerId: Identificador por pasajero.\n",
    "- Survived: Variable de respuesta booleana\n",
    "- Pclass: Clase asociada al boleto.\n",
    "- Name: Nombre del pasajero.\n",
    "- Sex: Sexo de pasajero.\n",
    "- Age: Edad.\n",
    "- Sibsp: Número de hermanos o parejas viajando en compañia.\n",
    "- Parch: Numero de padres o hijos viajando en compañia.\n",
    "- Ticket: Identificador del boleto.\n",
    "- Fare: Costo del boleto.\n",
    "- Cabin: Numero de cabina asociada al pasajero.\n",
    "- Embarked: Lugar de embarcación del pasajero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver que en promedio el $38\\%$ de los pasajeros sobrevivieron el accidente. \n",
    "\n",
    "En cuanto a los valores faltantes se tiene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es una exploración visual del conjunto de datos, para ello, se comienza por estudiar las correlaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "corr = corr = train.corr()\n",
    "sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien es una exploración inicial, se aprecia una correlación entre `Pclass`, `Fare` y la variable de respuesta. Se estudia la distribución de la variable de respuesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "\n",
    "sns.countplot(x='Survived', data = train)\n",
    "print(train['Survived'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudiamos la la variable de respuesta según `Pclass`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "ax1 = plt.subplot(2,1,1)\n",
    "ax1 = sns.countplot(x = 'Pclass', hue = 'Survived', data = train)\n",
    "ax1.set_title('Supervivencia según Clase', fontsize = 20)\n",
    "ax1.set_xticklabels(['1 Alta','2 Media','3 Baja'], fontsize = 15)\n",
    "ax1.set_ylim(0,400)\n",
    "ax1.set_xlabel('Clase',fontsize = 15) \n",
    "ax1.set_ylabel('Conteo',fontsize = 15)\n",
    "ax1.legend(['No','Si'])\n",
    "\n",
    "# Pointplot Pclass type\n",
    "ax2 = plt.subplot(2,1,2)\n",
    "sns.pointplot(x='Pclass', y='Survived', data=train)\n",
    "ax2.set_xlabel('Clase',fontsize = 15)\n",
    "ax2.set_ylabel('% Sobrevive',fontsize = 15)\n",
    "ax2.set_title('Porcentaje de supervivencia por Clase', fontsize = 20);\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior confirma la correlación observada, mientras mayor la clase del boleto, más probable es sobrevivir. \n",
    "\n",
    "En cuanto a la edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = 'Sobrevive'\n",
    "not_survived = 'No sobrevive'\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(12, 6))\n",
    "\n",
    "women = train[train['Sex']=='female']\n",
    "men = train[train['Sex']=='male']\n",
    "\n",
    "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=20, label = survived, ax = axes[0], kde =False)\n",
    "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=20, label = not_survived, ax = axes[0], kde =False)\n",
    "\n",
    "ax.legend(fontsize=12) \n",
    "\n",
    "ax.set_title('Mujer', fontsize=20)\n",
    "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=20, label = survived, ax = axes[1], kde = False)\n",
    "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=20, label = not_survived, ax = axes[1], kde = False)\n",
    "\n",
    "ax.legend(fontsize=12)\n",
    "ax.set_title('Hombre', fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se tiende que en general las mujeres tuvieron un más alto porcentaje de supervivencia sin importar la edad. En ambos sexos, las probabilidaddes de sobrevivir tienden a acumularse en la juventud. \n",
    "\n",
    "Aunque es posible continuar analizando relaciones visuales en el conjunto de datos, pasaremos a la *ingeniería de características*. \n",
    "\n",
    "Se crea la variable **family survival** que busca encapsular relaciones de supervivencia de familias. De esta forma, se genera una relación de similitud basándose en la información contenida en el boleto de cada pasajero. Así, grupos similares tendrán una probabilidad similar de supervivencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se llena el valor Fare con la media total\n",
    "\n",
    "def na_mean_fill(df, col='Fare'):\n",
    "    '''Cambia los datos faltantes de la columna col por la media en df.'''\n",
    "\n",
    "    data = df.copy()\n",
    "    data[col].fillna(data[col].mean(), inplace = True)\n",
    "    return data \n",
    "\n",
    "data = na_mean_fill(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a trabajar con la variable `Family_Survival`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se extrae el apellido\n",
    "def last_name_gen(df):\n",
    "    '''Genera la columna Last_name a partir de Name en el DataFrame df.\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    data: Pandas.DataFrame\n",
    "        Un conjunto de datos con la variable Last_Name agregada.\n",
    "    '''\n",
    "    \n",
    "    data = df.copy()\n",
    "    data['Last_Name'] = data['Name'].apply(lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "    return data\n",
    "\n",
    "data = last_name_gen(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se genera una rutina para crear la variable`Family_Survival`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_dict_gen(df, default_survival_chance=0.5):\n",
    "    '''Genera un DataFrame con probabilidades de supervivencia por familia.\n",
    "    \n",
    "    El conjunto de datos debe tener las columnas: Survived, Name, Last_Name, \n",
    "    Fare, Ticket, PassengerId, SibSp, Parch, Age y Cabin. Se genera un  \n",
    "    DataFrame con la relación familia -> fecuencia de supervivenca.\n",
    "\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "\n",
    "    data: Pandas.DataFrame\n",
    "        Un conjunto con la relacion familia - frecuencia de supervivencia\n",
    "    '''\n",
    "\n",
    "    data = df.copy()\n",
    "\n",
    "    # Utiliza un valor prior para la probabilidad de sobrevivir\n",
    "    data['Family_Survival'] = default_survival_chance\n",
    "\n",
    "    # Se agrupa el conjunto de datos por apellido y fare\n",
    "    for grp, grp_df in data[['Survived', 'Name', 'Last_Name', 'Fare', 'Ticket', 'PassengerId',\n",
    "                             'SibSp', 'Parch', 'Age', 'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "\n",
    "        # Si no es igual a 1, se encuentra una familia\n",
    "        # en tal caso se calcula una probabilidad de supervivencia\n",
    "        if (len(grp_df) != 1):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                smax = grp_df.drop(ind)['Survived'].max()\n",
    "                smin = grp_df.drop(ind)['Survived'].min()\n",
    "                passID = row['PassengerId']\n",
    "                if (smax == 1.0):\n",
    "                    data.loc[data['PassengerId'] ==\n",
    "                             passID, 'Family_Survival'] = 1\n",
    "                elif (smin == 0.0):\n",
    "                    data.loc[data['PassengerId'] ==\n",
    "                             passID, 'Family_Survival'] = 0\n",
    "\n",
    "    # Luego se agrupa la informacion por tickets y se procede\n",
    "    for _, grp_df in data.groupby('Ticket'):\n",
    "        if (len(grp_df) != 1):\n",
    "            for ind, row in grp_df.iterrows():\n",
    "                if (row['Family_Survival'] == 0) | (row['Family_Survival'] == 0.5):\n",
    "                    smax = grp_df.drop(ind)['Survived'].max()\n",
    "                    smin = grp_df.drop(ind)['Survived'].min()\n",
    "                    passID = row['PassengerId']\n",
    "                    if (smax == 1.0):\n",
    "                        data.loc[data['PassengerId'] ==\n",
    "                                 passID, 'Family_Survival'] = 1\n",
    "                    elif (smin == 0.0):\n",
    "                        data.loc[data['PassengerId'] ==\n",
    "                                 passID, 'Family_Survival'] = 0\n",
    "\n",
    "    return data.groupby('Last_Name').mean()['Family_Survival']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dict = family_dict_gen(data) \n",
    "family_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finalmente se crea la variable `Family_Survival`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_survival_gen(df, family_dict=family_dict, default_prob=0.5):\n",
    "    '''Recibe observaciones y asigna probabilidad de supervivencia por familia.\n",
    "\n",
    "    Permite generar una variable donde se asigna una proporcion de sobrevivencia\n",
    "    por familia. Para ello toma un DataFrame con las relaciones por familia si \n",
    "    el apellido asociado a la observacion x en df esta en el conjunto  de \n",
    "    familias, le asigna el valor indicado en family_dict. En caso contrario \n",
    "    le asigna la probabilidad default_prob. \n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    data : Pandas.DataFrame \n",
    "        Conjunto de datos con la variable family_survival generada. \n",
    "    '''\n",
    "    \n",
    "    data = df.copy()\n",
    "    data['Family_Survival'] = default_prob\n",
    "\n",
    "    for x in data.itertuples():\n",
    "        if x.Last_Name in family_dict:\n",
    "            prob = family_dict.loc[x.Last_Name]\n",
    "            data.loc[data['PassengerId'] == x.PassengerId,'Family_Survival'] = prob\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = family_survival_gen(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pasajeros con informacion de familia:\",\n",
    "      data.loc[data['Family_Survival'] != 0.5].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se reinicia el conjunto de índices para continuar trabajando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data = data.drop('Survived', axis=1)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se trabaja la variable `Fare`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.plot(figsize = [12,12])  \n",
    "plt.hist(data['Fare'], bins=40)\n",
    "\n",
    "plt.xlabel('Fare', fontdict={'fontsize':15})\n",
    "plt.ylabel('Conteo', fontdict={'fontsize':15})\n",
    "\n",
    "plt.title('Distribucion de Precio',  fontdict={'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La distribución presenta asimetria estadística, dentro de las opciones que se tienen para trabajar con este tipo de dato, se encuentran las transformaciones de potencia, o la categorización. En este caso, se procede a categorizar la variable en 4 niveles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_to_cat(df,col = 'Fare' , cuts = 4):\n",
    "    '''Toma un conjunto de datos df y transfroma la columna col en categorica.\n",
    "    \n",
    "    La cantidad de bins viene dada por el parametro cuts.\n",
    "    \n",
    "    Retorna:\n",
    "    -------- \n",
    "    \n",
    "    data: Pandas.DataFrame\n",
    "        Un conjunto de datos con la variable col recategorizada. \n",
    "    '''\n",
    "    lbl = LabelEncoder() \n",
    "    data = df.copy()\n",
    "    \n",
    "    data[col] = pd.qcut(data[col], cuts) \n",
    "    data[col] = lbl.fit_transform(data[col]) \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = col_to_cat(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a observar el resultado de la categorización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig  = plt.plot(figsize = [12,12])  \n",
    "\n",
    "sns.countplot(data['Fare'])\n",
    "plt.xlabel('Fare Bin',fontdict={'fontsize':15})\n",
    "plt.ylabel('Conteo',fontdict={'fontsize':15})\n",
    "plt.title('Fare Bins',fontdict={'fontsize':20});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede trabajar la variable `Name`. En este caso, los nombres no como identificadores no entregan información, sin embargo, los nombres de esta base continen expresiones del tipo `Mr.` o `Mrs.` que pueden ayudar a categorizar entre hombres y mujeres. \n",
    "\n",
    "Se procede a extraer dicha información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(name):\n",
    "    '''Obtiene le titulo asociado a una persona.'''\n",
    "    \n",
    "    if '.' in name:\n",
    "        return name.split(',')[1].split('.')[0].strip()\n",
    "    else:\n",
    "        return 'desconocido' \n",
    "\n",
    "def get_title_list(df): \n",
    "    '''Dado un conjunto de datos obtiene titulos a partir de la columna Name.\n",
    "    \n",
    "    Retorna:\n",
    "    -------- \n",
    "    \n",
    "    title_data: list \n",
    "        Lista con los titulos encontrados en df.\n",
    "        \n",
    "    '''\n",
    "    data = df.copy() \n",
    "    titles_data = sorted(set([x for x in data['Name'].map(lambda x: get_title(x))]))\n",
    "    \n",
    "    return titles_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan los titulos obtenidos del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_data = get_title_list(data)\n",
    "titles_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se observan 18 valores únicos, se procede a reducir la dimensionalidad de la categoría reduciendo solo a `Mr`,`Mrs`, `Miss` y `Master`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_title(x):\n",
    "    '''Reduce el titulo a Mr,Mrs o Miss segun corresponda.'''\n",
    "    \n",
    "    title = x['Title']\n",
    "    if title in ['Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n",
    "        return 'Mr'\n",
    "    elif title in ['the Countess', 'Mme', 'Lady','Dona']:\n",
    "        return 'Mrs'\n",
    "    elif title in ['Mlle', 'Ms']:\n",
    "        return 'Miss'\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='male':\n",
    "            return 'Mr'\n",
    "        else:\n",
    "            return 'Mrs'\n",
    "    else:\n",
    "        return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la transformación anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_gen(df):\n",
    "    ''' Genera la columna Title a partir de Name en el DataFrame df.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    data: Pandas.DataFrame\n",
    "        Un conjunto de datos con la variable Title agregada.\n",
    "    ''' \n",
    "    \n",
    "    data = df.copy() \n",
    "    data['Title'] = data['Name'].map(lambda x: get_title(x))\n",
    "    data['Title'] = data.apply(set_title, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa la distribución según nueva categoría, la categría `Master` no es transformada por la función anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = title_gen(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la variable `Age` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Informacion faltante: ', pd.isnull(data['Age']).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se utiliza imputación de datos por grupo, el grupo corresponde al titulo asociado anteriormente "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_imputer(df): \n",
    "    ''' Llena la información faltante de la columna Age en df. \n",
    "    \n",
    "    Utiliza una agrupacion por titulo y aplica un llenado por mediana de grupo.\n",
    "    \n",
    "    Retorna:\n",
    "    -------- \n",
    "    \n",
    "    data: Pandas.DataFrame \n",
    "        Conjunto de datos con la variable Age completada.\n",
    "    '''\n",
    "    data = df.copy()\n",
    "    data['Age'] = data.groupby('Title')['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = age_imputer(data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se llenan los datos faltantes por grupo utilizando la mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [7,7])\n",
    "\n",
    "plt.hist(data['Age'], bins=40)\n",
    "plt.xlabel('Age',fontdict={'fontsize':15})\n",
    "plt.ylabel('Conteo',fontdict={'fontsize':15})\n",
    "plt.title('Distribucion de Edades',fontdict={'fontsize':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiendo la idea utilizada en `Fare` se usan 4 categorias para representar las edades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = col_to_cat(data, col='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo que se obtiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[7,7])\n",
    "plt.xticks(rotation='90')\n",
    "sns.countplot(data['Age'])\n",
    "\n",
    "plt.xlabel('Bins de Edad',fontdict={'fontsize':15})\n",
    "plt.ylabel('Conteo',fontdict={'fontsize':15})\n",
    "plt.title('Age Bins',fontdict={'fontsize':20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a transformar los titulos a valores ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odc = OrdinalEncoder() \n",
    "data['Title'] = odc.fit_transform(data['Title'].values.reshape([-1,1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cuanto a la variable `Sex`, simplemente se hace una codificación *one-hot*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "data['Sex'] = ohe.fit_transform(data['Sex'].values.reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de `Embarked` se imputan usando la moda y se codifican de manera ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_fill(df, col): \n",
    "    '''Llena los valores faltantes de col en df usando la moda global.\n",
    "    \n",
    "    Retorna: \n",
    "    -------- \n",
    "    \n",
    "    data: Pandas.DataFrame \n",
    "        Conjunto de datos con la informacion de col completada. \n",
    "    ''' \n",
    "    \n",
    "    data = df.copy() \n",
    "    data[col] = data[col].fillna(data[col].mode()[0])  \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mode_fill(data,col = 'Embarked' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ode_embarked =  OrdinalEncoder() \n",
    "data['Embarked'] = ode_embarked.fit_transform(data['Embarked'].values.reshape([-1,1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `Cabin` está formateada según letras numeros que indican el piso del barco (letra) y número de cabina en tal piso (número). Es posible que exista alguna relación entre el piso de la cabina y la posibilidad de sobrevivir. Se trabajan los valores de esta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, se cambian los valores perdidos por `desconocido`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_desconocido(df, col):\n",
    "    ''' Toma un conjunto de datos df y llena la columna col con el valor\n",
    "    'desconocido'.\n",
    "    \n",
    "    Retorna:\n",
    "    -------- \n",
    "    \n",
    "    data : Pandas.DataFrame\n",
    "        Conjunto de datos con la variable col completada. \n",
    "\n",
    "    '''\n",
    "    data = df.copy()\n",
    "    data[col].fillna('desconocido', inplace = True) \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fill_desconocido(data, 'Cabin') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se extrae la letra de cada cabina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Cabin'].map(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las cabinas con letra `d` asociada poseen información faltante y sobrepasan a las demás categorías, basándose en esto, se construyen 2 nuevos grupos, aquellos con información en su cabina y aquellos sin información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unknown_cabin(cabin):\n",
    "    if cabin != 'd':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabin_cat(df):\n",
    "    '''Genera dos categorias en df basandose en la columna Cabin.\n",
    "    \n",
    "    Retorna:\n",
    "    -------\n",
    "    \n",
    "    data : Pandas.DataFrame \n",
    "        Conjunto de datos con la categorizacion creada. \n",
    "    '''\n",
    "    \n",
    "    data = df.copy() \n",
    "    data['Cabin'] = data['Cabin'].map(lambda x: x[0])\n",
    "    data['Cabin'] = data['Cabin'].apply(lambda x: unknown_cabin(x))\n",
    "\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cabin_cat(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables `SibSp` y `Parch` se combinan en `Family Size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def family_size_gen(df): \n",
    "    '''Genera la columna Family_Size a partir de SibSp y Parch en df. \n",
    "    \n",
    "    Retorna:\n",
    "    ------- \n",
    "    data : Pandas.DataFrame \n",
    "        Conjunto de datos con la columna creada. \n",
    "    \n",
    "    '''\n",
    "    data = df.copy()\n",
    "    data['Family_Size'] = data['SibSp'] + data['Parch']\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = family_size_gen(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las variables que no serán utilizadas son eliminadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['Name', 'Parch', 'SibSp', 'Ticket', 'Last_Name', 'PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(to_drop, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez explorado el conjunto de datos, haciendo la ingeniería de características necesaria, se procede a implementar un conjunto de algoritmos de aprendizaje de máquinas. En este contexto, se procede a empaquetar los métodos de preprocesamiento para incluirlos en una pipeline de entrenamiento. \n",
    "\n",
    "A los métodos anteriores añadimos un preprocesador por estandarización, además se empaquetan los preprocesadores de codificación ordinal y one hot. Para finalizar se crea una función que encapsula la eliminación de columnas no deseadas y otra que permite estandarizar un DataFrame manteniendo la estructura de columnas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh_encoder_col(df, col='Sex'):\n",
    "    '''Genera codificacion One hot en df basandose en la columna col.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "\n",
    "    data : Pandas.DataFrame\n",
    "        Conjunto de datos con el encoding creado.\n",
    "    '''\n",
    "    data = df.copy()\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "    data[col] = ohe.fit_transform(data[col].values.reshape([-1, 1]))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def ord_encoder_col(df, col='Title'):\n",
    "    '''Genera codificacion Ordinal df basandose en la columna col.\n",
    "\n",
    "    Retorna:\n",
    "    -------\n",
    "\n",
    "    data : Pandas.DataFrame \n",
    "        Conjunto de datos con el encoding creado. \n",
    "    '''\n",
    "\n",
    "    data = df.copy()\n",
    "    ode = OrdinalEncoder()\n",
    "    data[col] = ode.fit_transform(data[col].values.reshape([-1, 1]))\n",
    "\n",
    "    return data\n",
    "\n",
    "to_drop = ['Name', 'Parch', 'SibSp', 'Ticket', 'Last_Name', 'PassengerId']\n",
    "def drop_cols(df, cols = to_drop):\n",
    "    '''Elimina las columans cols del DataFrame df.\n",
    "    \n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    data : Pandas.DataFrame \n",
    "        Conjunto de datos con las columnas borradas. \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    data = df.copy() \n",
    "    data.drop(cols, axis = 1, inplace=True)\n",
    "    \n",
    "    return data \n",
    "\n",
    "def std_scaler(df):\n",
    "    '''Toma un DataFrame y lo estandariza, retorna un DataFrame.'''\n",
    "    \n",
    "    std_scaler = StandardScaler()\n",
    "    \n",
    "    data = df.copy()\n",
    "    cols = data.columns\n",
    "    \n",
    "    return pd.DataFrame(std_scaler.fit_transform(data),columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea la Pipeline asociada al proceso de exploración y se preprocesa el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer as F\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "data = pd.read_csv('ProjectLab/data/train.csv')\n",
    "test_data = data.sample(frac=0.1, random_state = 5)\n",
    "\n",
    "train_idx = data.index.difference(test_data.index) \n",
    "family_dict = family_dict_gen(last_name_gen(data.loc[train_idx]))\n",
    "\n",
    "y_train = data.loc[train_idx,'Survived'] \n",
    "x_train = data.drop('Survived', axis=1).loc[train_idx]\n",
    "\n",
    "steps = [('Fare mean fill', F(na_mean_fill)),\n",
    "         ('Last_Name gen', F(last_name_gen)),\n",
    "         ('Family_Survival gen', F(lambda df: family_survival_gen(df,family_dict=family_dict))), \n",
    "         ('Fare to cat', F(col_to_cat)),\n",
    "         ('Title var gen', F(title_gen)),\n",
    "         ('Age imputer', F(age_imputer)),\n",
    "         ('Age to cat', F(lambda df: col_to_cat(df, col='Age'))),\n",
    "         ('Title to ordinal', F(ord_encoder_col)),\n",
    "         ('Sex to One Hot Enc', F(oh_encoder_col)),\n",
    "         ('Fill with the mean Embarked', F(lambda df: mode_fill(df, col='Embarked'))),\n",
    "         ('Embarked to Ordinal', F(lambda df: ord_encoder_col(df, col='Embarked'))),\n",
    "         ('Fill desconocido Cabin', F(lambda df: fill_desconocido(df, col='Cabin'))),\n",
    "         ('Cabin to Cat', F(cabin_cat)),\n",
    "         ('Family size gen', F(family_size_gen)),\n",
    "         ('drop cols', F(drop_cols)),\n",
    "         ('Scaler', F(std_scaler))\n",
    "         ]\n",
    "\n",
    "\n",
    "data_prep = Pipeline(steps=steps)\n",
    "x_train = data_prep.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se procede a entrenar modelos de Aprendizaje automático sobre el conjunto de datos, los modelos seleccionados corresponden a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ran = RandomForestClassifier(random_state=1)\n",
    "knn = KNeighborsClassifier()\n",
    "log = LogisticRegression()\n",
    "xgb = XGBClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "svc = SVC(probability=True)\n",
    "ext = ExtraTreesClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "gnb = GaussianNB()\n",
    "gpc = GaussianProcessClassifier()\n",
    "bag = BaggingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos modelos son evaluados usando un esquema de validación cruzada, se procede a almacenar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import model_selection\n",
    "\n",
    "models = [ran, knn, log, xgb, gbc, svc, ext, ada, gnb, gpc, bag]         \n",
    "scores = []\n",
    "\n",
    "for mod in models:\n",
    "    mod.fit(x_train, y_train)\n",
    "    acc = cross_val_score(mod, x_train, y_train, scoring = \"accuracy\", cv = 10)\n",
    "    scores.append(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos corresponden a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'K Nearest Neighbour', 'Logistic Regression', 'XGBoost', 'Gradient Boosting', 'SVC', 'Extra Trees', 'AdaBoost', 'Gaussian Naive Bayes', 'Gaussian Process', 'Bagging Classifier'],\n",
    "    'Score': scores})\n",
    "\n",
    "result_df = results.sort_values(by='Score', ascending=False).reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = [9,7])   \n",
    "\n",
    "sns.barplot(x='Score', y = 'Model', data = result_df, color = 'c')\n",
    "\n",
    "plt.title('Accuracy por modelo  \\n', fontsize = 20)  \n",
    "plt.xlabel('Accuracy  (%)', fontsize = 15)\n",
    "plt.ylabel('Algoritmo', fontsize = 15)\n",
    "plt.xlim(0.80, 0.87);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que el algoritmo con mejor rendimiento es el clasificador `SVC`. El modelo XGBoost permite obtener un indicador de las caracteristicas más importantes dentro del proceso de predicción, podemos acceder a estos puntajes por medio de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_plotting(data, x, y, palette, title):\n",
    "    \n",
    "    sns.set(style=\"whitegrid\")\n",
    "    ft = sns.PairGrid(data, y_vars=y, x_vars=x, height=5, aspect=1.5) \n",
    "    ft.map(sns.stripplot, orient='h', palette=palette,\n",
    "           edgecolor=\"black\", size=10)\n",
    "\n",
    "    for ax, title in zip(ft.axes.flat, titles):\n",
    "        ax.set_title(title, fontsize = 18)\n",
    "        ax.xaxis.grid(False) \n",
    "        ax.yaxis.grid(True)\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "fi = {'Features': x_train.columns.tolist(), 'Importance': xgb.feature_importances_}\n",
    "importance = pd.DataFrame(fi, index=None).sort_values(\n",
    "    'Importance', ascending=False)\n",
    "\n",
    "titles = ['Importancia de Caracterísitcas en Prediccion según XGBoost'] \n",
    "importance_plotting(importance, 'Importance', 'Features', 'Reds_r', titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar, el sexo del pasajero es la característica más influyente bajo este modelo, de la misma forma, se encuentra una relación entre el parentezco dentro de los pasajeros por medio de `Family_Survival` y la cabina en la cual se viaja. \n",
    "\n",
    "En cuanto a las relaciones lineales se pueden observar los coeficientes de la regresión logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = {'Features':x_train.columns.tolist(), 'Importance':np.transpose(log.coef_[0])}\n",
    "importance = pd.DataFrame(fi, index=None).sort_values('Importance', ascending=False)\n",
    "\n",
    "titles = ['Importancia de Caracterísitcas en Prediccion según LogReg']\n",
    "importance_plotting(importance, 'Importance', 'Features', 'Reds_r', titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa cierta concordancia con las importancias anteriores, en este caso aparece `Cabin` y `Fare` Como indicadores lineales de supervivencia sumados a `Family_Survival` y a `Sex`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en lo anterior se efectua un proceso de **selección de características**, para ello se construye una tabla con la información por modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting feature importances for the 5 models where we can\n",
    "gbc_imp = pd.DataFrame({'Feature': x_train.columns,\n",
    "                        'gbc importance': gbc.feature_importances_})\n",
    "xgb_imp = pd.DataFrame(\n",
    "    {'Feature': x_train.columns, 'xgb importance': xgb.feature_importances_})\n",
    "ran_imp = pd.DataFrame(\n",
    "    {'Feature': x_train.columns, 'ran importance': ran.feature_importances_})\n",
    "ext_imp = pd.DataFrame(\n",
    "    {'Feature': x_train.columns, 'ext importance': ext.feature_importances_})\n",
    "ada_imp = pd.DataFrame(\n",
    "    {'Feature': x_train.columns, 'ada importance': ada.feature_importances_})\n",
    "\n",
    "# Merging results into a single dataframe\n",
    "importances = gbc_imp.merge(xgb_imp, on='Feature').merge(\n",
    "    ran_imp, on='Feature').merge(ext_imp, on='Feature').merge(ada_imp, on='Feature')\n",
    "\n",
    "importances['Average'] = importances.mean(axis=1)\n",
    "\n",
    "\n",
    "importances = importances.sort_values(\n",
    "    by='Average', ascending=False).reset_index(drop=True)\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando esta información podemos tener una idea de como las carácteristicas influyen en el promedio de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = {'Features':importances['Feature'], 'Importance':importances['Average']}\n",
    "\n",
    "importance = pd.DataFrame(fi, index=None).sort_values('Importance', ascending=False)\n",
    "titles = ['Importancia de Features Promedio']\n",
    "\n",
    "# Plotting graph\n",
    "importance_plotting(importance, 'Importance', 'Features', 'Reds_r', titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas asociadas a `Embarked` y `Cabin` no aportan mucho en general por lo que se seleccionan como variables a eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop.extend(['Embarked', 'Cabin'])\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = drop_cols(x_train, cols=['Embarked', 'Cabin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizada la selección de características, se reentrenan los modelos, se actualiza la Pipeline para generar datos sin las características que deseamos exlcuir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ProjectLab/data/train.csv')\n",
    "test_data = data.sample(frac=0.1, random_state = 5)\n",
    "\n",
    "train_idx = data.index.difference(test_data.index) \n",
    "family_dict = family_dict_gen(last_name_gen(data.loc[train_idx]))\n",
    "\n",
    "y_train = data.loc[train_idx,'Survived'] \n",
    "x_train = data.drop('Survived', axis=1).loc[train_idx]\n",
    "\n",
    "# Actualiza la pipeline eliminando las nuevas caracteristicas\n",
    "steps = [('Fare mean fill', F(na_mean_fill)),\n",
    "         ('Last_Name gen', F(last_name_gen)),\n",
    "         ('Family_Survival gen', F(lambda df: family_survival_gen(df,family_dict=family_dict))), \n",
    "         ('Fare to cat', F(col_to_cat)),\n",
    "         ('Title var gen', F(title_gen)),\n",
    "         ('Age imputer', F(age_imputer)),\n",
    "         ('Age to cat', F(lambda df: col_to_cat(df, col='Age'))),\n",
    "         ('Title to ordinal', F(ord_encoder_col)),\n",
    "         ('Sex to One Hot Enc', F(oh_encoder_col)),\n",
    "         ('Fill with the mean Embarked', F(lambda df: mode_fill(df, col='Embarked'))),\n",
    "         ('Embarked to Ordinal', F(lambda df: ord_encoder_col(df, col='Embarked'))),\n",
    "         ('Fill desconocido Cabin', F(lambda df: fill_desconocido(df, col='Cabin'))),\n",
    "         ('Cabin to Cat', F(cabin_cat)),\n",
    "         ('Family size gen', F(family_size_gen)),\n",
    "         ('drop cols', F(lambda df: drop_cols(df, cols=to_drop))),\n",
    "         ('Scaler', F(std_scaler))\n",
    "         ]\n",
    "\n",
    "data_prep = Pipeline(steps=steps)\n",
    "\n",
    "def make_mod_pipe(mod): return Pipeline(\n",
    "    steps=[('preprocess', data_prep), ('clf', mod)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a reentrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ran, knn, log, xgb, gbc, svc, ext, ada, gnb, gpc, bag]         \n",
    "scores_v2 = []\n",
    "\n",
    "for mod in models:\n",
    "    mod_pipe = make_mod_pipe(mod) \n",
    "    \n",
    "    mod_pipe.fit(x_train, y_train)\n",
    "    \n",
    "    acc = cross_val_score(mod_pipe, x_train, y_train, scoring = \"accuracy\", cv = 10, n_jobs = -1)\n",
    "    scores_v2.append(acc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'K Nearest Neighbour', 'Logistic Regression', 'XGBoost', 'Gradient Boosting', 'SVC', 'Extra Trees', 'AdaBoost', 'Gaussian Naive Bayes', 'Gaussian Process', 'Bagging Classifier'],\n",
    "    'Score original': scores,\n",
    "    'Score seleccion': scores_v2})\n",
    "\n",
    "result_df = results.sort_values(\n",
    "    by='Score seleccion', ascending=False).reset_index(drop=True)\n",
    "result_df['Diferencia'] = result_df['Score seleccion'] - \\\n",
    "    result_df['Score original']\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9, 7])\n",
    "\n",
    "sns.barplot(x='Score seleccion', y='Model',\n",
    "            data=result_df, color='c', label='seleccion')\n",
    "sns.barplot(x='Score original', y='Model',\n",
    "            data=result_df, color='r', label='original')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Accuracy por Modelo \\n', fontsize=20)\n",
    "plt.xlabel('Accuracy (%)')\n",
    "plt.ylabel('Algoritmo')\n",
    "plt.xlim(0.80, 0.87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar un aumento global al aplicar selección de características en los modelos. El siguiente paso es la **obtención de hiperparámetros**. \n",
    "\n",
    "En este caso generamos un conjunto de hipeparámetros sobre los cuales se hará una búsqueda por grilla según validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualiza la pipeline eliminando fuga en family gen\n",
    "def step_gen(model):\n",
    "    '''Genera pasos para predicir usando model.'''\n",
    "\n",
    "    steps = [('Fare mean fill', F(na_mean_fill)),\n",
    "             ('Last_Name gen', F(last_name_gen)),\n",
    "             ('Family_Survival gen', F(family_survival_gen)),\n",
    "             ('Fare to cat', F(col_to_cat)),\n",
    "             ('Title var gen', F(title_gen)),\n",
    "             ('Age imputer', F(age_imputer)),\n",
    "             ('Age to cat', F(lambda df: col_to_cat(df, col='Age'))),\n",
    "             ('Title to ordinal', F(ord_encoder_col)),\n",
    "             ('Sex to One Hot Enc', F(oh_encoder_col)),\n",
    "             ('Fill with the mean Embarked', F(\n",
    "                 lambda df: mode_fill(df, col='Embarked'))),\n",
    "             ('Embarked to Ordinal', F(lambda df: ord_encoder_col(df, col='Embarked'))),\n",
    "             ('Fill desconocido Cabin', F(\n",
    "                 lambda df: fill_desconocido(df, col='Cabin'))),\n",
    "             ('Cabin to Cat', F(cabin_cat)),\n",
    "             ('Family size gen', F(family_size_gen)),\n",
    "             ('drop cols', F(lambda df: drop_cols(df, cols=to_drop))),\n",
    "             ('Scaler', F(std_scaler)),\n",
    "             ('clf', model)\n",
    "             ]\n",
    "\n",
    "    return steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se preparan los datos para este paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ProjectLab/data/train.csv')\n",
    "test_data = data.sample(frac=0.1, random_state = 5)\n",
    "\n",
    "train_idx = data.index.difference(test_data.index) \n",
    "\n",
    "y_train = data.loc[train_idx,'Survived'] \n",
    "x_train = data.drop('Survived', axis=1).loc[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca un esquema de Grid search, para implementarlo se empaquetan las funciones usuales. En este caso se debe tener en cuenta la **reproducibilidad** por lo que se asignará un valor de estado a la semilla aleatoria cuando sea posible. Por último se debe tener en cuanta la **persistencia** de los modelos, es decir, la capacidad de utilizarlos en entornos distintos al actual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_train(model, hyperparams, x_train=x_train, folds = 3):\n",
    "    '''Recibe un modelo base y lo entrena usando GridSearchCV.\n",
    "    \n",
    "    Recibe un modelo y un conjunto de hiperparametros para realizar busqueda \n",
    "    por grilla. \n",
    "    \n",
    "    Parametros:\n",
    "    ---------- \n",
    "    \n",
    "    model: sklearn.estimator\n",
    "        Clasificador de sklearn.\n",
    "    \n",
    "    hyperams: dict \n",
    "        Diccionario de hiperparametros compatibles con model.\n",
    "    \n",
    "    x_train: pandas.DataFrame\n",
    "        Conjunto de datos sobre el cual entrenar. \n",
    "    \n",
    "    folds: int \n",
    "        numero de folds asociados al esquema de grilla por validacion cruzada.\n",
    "        \n",
    "    Retorna: \n",
    "    -------- \n",
    "    \n",
    "    res: dict \n",
    "        Entrega un diccionaro con el mejor estimador encontrado (best_estimator)\n",
    "        y el objeto grilla asociado (gs_object).\n",
    "    '''\n",
    "\n",
    "    h_pars = {'clf__'+k: val for k, val in hyperparams.items()}\n",
    "    tuning_pipe = Pipeline(steps=step_gen(model))\n",
    "\n",
    "    gs = GridSearchCV(estimator=tuning_pipe, param_grid=h_pars,\n",
    "                      verbose=1, cv=folds, scoring=\"accuracy\", n_jobs=-1)\n",
    "    \n",
    "    print('Entrenando ...')\n",
    "    gs.fit(x_train, y_train)\n",
    "\n",
    "    return {'best_model': gs.best_estimator_['clf'], 'gs_object': gs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurar persistencia de los modelos utilizamos la librería `joblib`. Se procede a entrenar un modelo de clasificación basado en vectores de soporte SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os \n",
    "\n",
    "try:\n",
    "    os.mkdir('ProjectLab/tuned_models')\n",
    "    print('Se crea la carpeta exitosamente')\n",
    "    \n",
    "except FileExistsError as error:\n",
    "    print('La carpeta ya existe:', error)\n",
    "    \n",
    "path = 'ProjectLab/tuned_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 5, 10, 15, 20, 50, 100]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "hyperparams = dict()  # {'C': Cs, 'gamma': gammas}\n",
    "\n",
    "try:\n",
    "    svc = joblib.load(path + 'svc')\n",
    "\n",
    "except FileNotFoundError:\n",
    "\n",
    "    res = grid_train(model=SVC(probability = True, random_state = 0),\n",
    "                     hyperparams=hyperparams)\n",
    "\n",
    "    svc = res['best_model']\n",
    "    joblib.dump(svc, path + 'svc')\n",
    "\n",
    "    print('Mejor puntaje:', res['gs_object'].best_score_)\n",
    "\n",
    "print('Mejor modelo:', svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de persistencia anterior se encapsula en la siguiente función\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(base_model=None, hyperparams=None, model_name=None, path=path):\n",
    "    ''' Busca un modelo en path + model_name o entrena uno nuevo.\n",
    "\n",
    "    Busca un modelo usando path + model_name. Si tal modelo no se encuentra, \n",
    "    entrena un esquema de grilla con validacion cruzada sobre el modelo \n",
    "    base_model usando los hiperparametros hyperparams\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        model = joblib.load(path+model_name)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "\n",
    "        res = grid_train(model=base_model,\n",
    "                         hyperparams=hyperparams)\n",
    "\n",
    "        model = res['best_model']\n",
    "        joblib.dump(model, path + model_name)\n",
    "\n",
    "        print('Mejor puntaje:', res['gs_object'].best_score_)\n",
    "        \n",
    "    \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "    \n",
    "    print('Mejor modelo:', model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridearch para Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.0005, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "n_estimators = [100, 500, 750, 1000, 1250, 1400]\n",
    "\n",
    "hyperparams = {'learning_rate': learning_rate,\n",
    "               'n_estimators': n_estimators}\n",
    "\n",
    "gbc = get_model(base_model=GradientBoostingClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='gbc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede con Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "hyperparams = {'penalty': penalty, 'C': C}\n",
    "\n",
    "log = get_model(base_model=LogisticRegression(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de XGBoost se hace un búsqueda dividida en múltiples pasos debido a la gran cantidad de hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.0001, 0.0005, 0.001, 0.005, 0.01]\n",
    "n_estimators = [10, 25, 50, 75, 100, 250]\n",
    "\n",
    "\n",
    "hyperparams = {'learning_rate': learning_rate, 'n_estimators': n_estimators}\n",
    "\n",
    "xgb = get_model(base_model=XGBClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='xgb_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [3, 4, 5, 6, 7]\n",
    "min_child_weight = [1, 2, 3, 4]\n",
    "\n",
    "hyperparams = {'max_depth': max_depth, 'min_child_weight': min_child_weight}\n",
    "\n",
    "xgb = get_model(base_model=xgb, hyperparams=hyperparams, model_name='xgb_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = [0.02,0.1,0.2]\n",
    "\n",
    "hyperparams = {'gamma': gamma}\n",
    "\n",
    "xgb = get_model(base_model=xgb, hyperparams=hyperparams, model_name='xgb_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = [0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "colsample_bytree = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 1]\n",
    "    \n",
    "hyperparams = {'subsample': subsample, 'colsample_bytree': colsample_bytree}\n",
    "\n",
    "xgb = get_model(base_model=xgb, hyperparams=hyperparams, model_name='xgb_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_alpha = [1e-5, 1e-2, 0.1, 1, 100]\n",
    "    \n",
    "hyperparams = {'reg_alpha': reg_alpha}\n",
    "\n",
    "xgb = get_model(base_model=xgb, hyperparams=hyperparams, model_name='xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado el modelo xgb se procede con el clasificador basado en procesos gaussianos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_restarts_optimizer = [0, 1, 2, 3]\n",
    "max_iter_predict = [1, 2, 5, 10, 20, 35, 50, 100]\n",
    "warm_start = [True, False]\n",
    "\n",
    "\n",
    "hyperparams = {'n_restarts_optimizer': n_restarts_optimizer,\n",
    "               'max_iter_predict': max_iter_predict, 'warm_start': warm_start}\n",
    "\n",
    "gpc = get_model(base_model=GaussianProcessClassifier(\n",
    "    random_state=0), hyperparams=hyperparams, model_name='gpc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se continua con AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 25, 50, 75]\n",
    "learning_rate = [0.001, 0.01, 0.1, 0.5, 1]\n",
    "\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'learning_rate': learning_rate}\n",
    "\n",
    "ada = get_model(base_model=AdaBoostClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='ada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede con knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20]\n",
    "algorithm = ['auto']\n",
    "weights = ['uniform', 'distance']\n",
    "leaf_size = [1, 2, 3, 4, 5, 10, 15, 20, 25, 30]\n",
    "\n",
    "hyperparams = {'algorithm': algorithm, 'weights': weights, 'leaf_size': leaf_size,\n",
    "               'n_neighbors': n_neighbors}\n",
    "\n",
    "knn = get_model(base_model=KNeighborsClassifier(),\n",
    "                hyperparams=hyperparams, model_name='knn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena el clasificador Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 25, 50]\n",
    "max_depth = [3, None]\n",
    "max_features = [1, 3, 5]\n",
    "min_samples_split =[4, 6, 8]\n",
    "min_samples_leaf = [4, 6, 8, 10]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features': max_features,\n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "ran = get_model(base_model=RandomForestClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='ran')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pasa a Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 25, 50]\n",
    "max_depth = [3, None]\n",
    "max_features = [1, 3, 5]\n",
    "min_samples_split = [4, 6, 8, 10]\n",
    "min_samples_leaf = [2, 4, 6]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_depth': max_depth, 'max_features': max_features,\n",
    "               'min_samples_split': min_samples_split, 'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "ext = get_model(base_model=ExtraTreesClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='ext')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente entrenamos el clasificador basado en bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 15, 20, 50, 75, 100]\n",
    "max_samples = [5, 10, 15, 20, 30, 50]\n",
    "max_features = [5, 7]\n",
    "\n",
    "hyperparams = {'n_estimators': n_estimators, 'max_samples': max_samples, 'max_features': max_features}\n",
    "\n",
    "bag = get_model(base_model=BaggingClassifier(random_state=0),\n",
    "                hyperparams=hyperparams, model_name='bag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes no posee hiperparámetros por lo que no se entrena usando este esquema. \n",
    "\n",
    "Se procede a estudiar el efecto global de los modelos entrenados sobre los hiperparámetros encontrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars = ['Pclass','Sex','Age', 'Fare',\n",
    "              'Family_Survival', 'Title', 'Family_Size']\n",
    "\n",
    "X = data_prep.transform(test_data.drop('Survived', axis=1))\n",
    "X = X.reindex(columns=final_vars)\n",
    "y = test_data['Survived']\n",
    "\n",
    "train = data_prep.transform(x_train).reindex(columns = final_vars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists\n",
    "models = [ran, knn, log, xgb, gbc, svc, ext, ada, gnb, gpc, bag]         \n",
    "scores_v3 = []\n",
    "\n",
    "train = data_prep.transform(x_train)\n",
    "\n",
    "# Fit & cross-validate\n",
    "for mod in models:\n",
    "    mod.fit(train, y_train)\n",
    "    acc = cross_val_score(mod, train, y_train, scoring = \"accuracy\", cv = 10)\n",
    "    scores_v3.append(acc.mean())\n",
    "\n",
    "# Creating a table of results, ranked highest to lowest\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'K Nearest Neighbour', 'Logistic Regression', 'XGBoost', 'Gradient Boosting', 'SVC', 'Extra Trees', 'AdaBoost', 'Gaussian Naive Bayes', 'Gaussian Process', 'Bagging Classifier'],\n",
    "    'original': scores,\n",
    "    'feature selection': scores_v2,\n",
    "    'tuned': scores_v3})\n",
    "\n",
    "result_df = results.sort_values(by='tuned', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo anterior se visualiza de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[9, 7])\n",
    "\n",
    "sns.barplot(x='tuned', y='Model', data=result_df, color='r', label='Tuned',edgecolor = 'k')\n",
    "\n",
    "sns.barplot(x='feature selection', y='Model', data=result_df,\n",
    "            color='b', label='Selection', alpha=0.5, edgecolor = 'k') \n",
    "\n",
    "sns.barplot(x='original', y='Model', data=result_df,\n",
    "            color='w', label='Original', alpha=.9, edgecolor = 'c')    \n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Accuracy por modelo', fontsize=20)\n",
    "plt.xlabel('Accuracy (%)')\n",
    "plt.ylabel('Algoritmo')\n",
    "plt.xlim(0.82, 0.88);  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que salvo para la regresión logística, gaussian naive bayes y gradient boosting, los modelos con hiper parámetros ajustados superan tanto a las versiones originales como a la aplicación de selección simple de características. En general se ve un buen aumento en presición al comparar con los resultados iniciales. \n",
    "\n",
    "El paso final es combinar estos modelos por medio de un clasificador de voto por mayoria. Comenzamos entrenando un modelo con esquema de votación duro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_hard_clf = VotingClassifier(estimators=[('Random Forest', ran),\n",
    "                                             ('Logistic Regression', log),\n",
    "                                             ('XGBoost', xgb),\n",
    "                                             ('Gradient Boosting', gbc),\n",
    "                                             ('Extra Trees', ext),\n",
    "                                             ('AdaBoost', ada),\n",
    "                                             ('Gaussian Process', gpc),\n",
    "                                             ('SVC', svc),\n",
    "                                             ('K Nearest Neighbour', knn),\n",
    "                                             ('Bagging Classifier', bag)], voting='hard')\n",
    "\n",
    "vote_hard = get_model(base_model=vote_hard_clf, hyperparams=dict(), model_name='vote_hard');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vars = ['Pclass','Sex','Age', 'Fare',\n",
    "              'Family_Survival', 'Title', 'Family_Size']\n",
    "\n",
    "X = data_prep.transform(test_data.drop('Survived', axis=1))\n",
    "X = X.reindex(columns=final_vars)\n",
    "y = test_data['Survived']\n",
    "\n",
    "train = data_prep.transform(x_train).reindex(columns = final_vars);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Hard voting en train: {vote_hard.score(train,y_train)*100}\") \n",
    "print(f\"Hard voting en test : {vote_hard.score(X,y)*100}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último se compara con un esquema de votación suave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_soft_clf = VotingClassifier(estimators=[('Random Forest', ran),\n",
    "                                         ('Logistic Regression', log),\n",
    "                                         ('XGBoost', xgb),\n",
    "                                         ('Gradient Boosting', gbc),\n",
    "                                         ('Extra Trees', ext),\n",
    "                                         ('AdaBoost', ada),\n",
    "                                         ('Gaussian Process', gpc),\n",
    "                                         ('SVC', svc),\n",
    "                                         ('K Nearest Neighbour', knn),\n",
    "                                         ('Bagging Classifier', bag)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_soft = get_model(base_model=vote_soft_clf, hyperparams=dict(), model_name='vote_soft');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Soft voting en train: {vote_soft.score(train,y_train)*100}\") \n",
    "print(f\"Soft voting en test : {vote_soft.score(X,y)*100}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos concuerdan en sus resultados, se selecciona el sistema de votación suave como modelo final.\n",
    "\n",
    "**Obs:** El flujo de trabajo implementado se basa en la siguiente [fuente](https://www.kaggle.com/josh24990/simple-end-to-end-ml-workflow-top-5-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuación -- Entorno de desarrollo** \n",
    "\n",
    "Ya seleccionado el modelo a trabajar, se procede a traspasar el código a un entorno de desarrollo. La idea es generar una estructura de módulos que permita ejecutar los procesos de preprocesamiento, entrenamiento y predicción desde otras aplicaciones. En este caso la aplicación que hará uso de esta estructura modular será la  API que se desarrollará. \n",
    "\n",
    "Procedemos a modularizar el código generado en el entorno de investigación. Para esto se genera la siguiente estructura de módulos: \n",
    "\n",
    "```\n",
    "config.py\n",
    "preprocessors.py \n",
    "train.py \n",
    "predict.py\n",
    "pipeline.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**config.py**\n",
    "\n",
    "Posee las configuraciones generales a utilizar en los procesos de nuestro módulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/config.py\n",
    "TARGET = 'Survived'\n",
    "MODELS_PATH  = 'tuned_models/'\n",
    "LAST_MODEL_PATH = 'last_models/'\n",
    "LAST_MODEL_NAME = 'last_model'\n",
    "\n",
    "\n",
    "DATA_PATH_TRAIN = 'data/train.csv'\n",
    "\n",
    "FAMILY_DICT ='meta_data/family_dict'\n",
    "TO_DROP_PIPE = ['Name', 'Parch', 'SibSp', 'Ticket', 'Last_Name', 'PassengerId', 'Embarked', 'Cabin']\n",
    "\n",
    "\n",
    "FINAL_VARS = ['Pclass','Sex','Age', 'Fare',\n",
    "              'Family_Survival', 'Title', 'Family_Size']\n",
    "\n",
    "FINAL_MODEL = 'vote_soft'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preprocessors.py**\n",
    "\n",
    "En este módulo procedemos a encapsular los preprocesadores utilizados en el entorno de investigación. Para ello, se hace uso de herencia múltiple según `BaseEstimator` y `TransformerMixin`. Se importan las librerías necesarias para que estos preprocesdores funcionen. Se traspasan las funciones utilizadas a objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9,
     33,
     50,
     179,
     223,
     257,
     289,
     315,
     346,
     365,
     397,
     432,
     459
    ]
   },
   "outputs": [],
   "source": [
    "%%file ProjectLab/preprocesssors.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import config\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "\n",
    "class NaMeanFiller(BaseEstimator, TransformerMixin):\n",
    "    '''Cambia los datos faltantes de la columna col por la media en df.'''\n",
    "\n",
    "    def __init__(self, col='Fare', mean=None):\n",
    "        self.col = col\n",
    "        self.mean = mean\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.mean is None:\n",
    "            data = X.copy()\n",
    "            self.mean = data[self.col].mean()\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col].fillna(self.mean, inplace=True)\n",
    "        else:\n",
    "            data[self.col] = self.mean\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class LastNameGen(BaseEstimator, TransformerMixin):\n",
    "    '''Genera la columna Last_name a partir de Name en el DataFrame df.'''\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data['Name']) is not pd.core.series.Series:\n",
    "            data['Last_Name'] = data['Name'].split(\",\")[0]\n",
    "        else:\n",
    "            data['Last_Name'] = data['Name'].apply(\n",
    "                lambda x: str.split(x, \",\")[0])\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class FamilySurvivalGen(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    '''Recibe observaciones y asigna probabilidad de supervivencia por familia.\n",
    "\n",
    "    Permite generar una variable donde se asigna una proporcion de sobrevivencia\n",
    "    por familia. Para ello toma un DataFrame con las relaciones por familia si\n",
    "    el apellido asociado a la observacion x en df esta en el conjunto  de\n",
    "    familias, le asigna el valor indicado en family_dict. En caso contrario\n",
    "    le asigna la probabilidad default_prob.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, default_prob=.5, family_dict=None):\n",
    "\n",
    "        self.default_prob = default_prob\n",
    "        self.family_dict = family_dict\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        '''Genera un DataFrame con probabilidades de supervivencia por familia.\n",
    "\n",
    "        El conjunto de datos debe tener las columnas: Survived, Name, Last_Name, \n",
    "        Fare, Ticket, PassengerId, SibSp, Parch, Age y Cabin. Se genera un  \n",
    "        DataFrame con la relación familia -> fecuencia de supervivenca.\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "\n",
    "        data: Pandas.DataFrame\n",
    "            Un conjunto con la relacion familia - frecuencia de supervivencia\n",
    "        '''\n",
    "\n",
    "        if self.family_dict is None:\n",
    "\n",
    "            data = X.copy()\n",
    "\n",
    "            # Utiliza un valor prior para la probabilidad de sobrevivir\n",
    "            data['Family_Survival'] = self.default_prob\n",
    "\n",
    "            # Se agrupa el conjunto de datos por apellido y fare\n",
    "            for grp, grp_df in data[['Survived', 'Name', 'Last_Name', 'Fare',\n",
    "                                     'Ticket', 'PassengerId',\n",
    "                                     'SibSp', 'Parch', 'Age',\n",
    "                                     'Cabin']].groupby(['Last_Name', 'Fare']):\n",
    "\n",
    "                # Si no es igual a 1, se encuentra una familia\n",
    "                # en tal caso se calcula una probabilidad de supervivencia\n",
    "                if (len(grp_df) != 1):\n",
    "                    for ind, row in grp_df.iterrows():\n",
    "                        smax = grp_df.drop(ind)['Survived'].max()\n",
    "                        smin = grp_df.drop(ind)['Survived'].min()\n",
    "                        passID = row['PassengerId']\n",
    "                        if (smax == 1.0):\n",
    "                            data.loc[data['PassengerId'] ==\n",
    "                                     passID, 'Family_Survival'] = 1\n",
    "                        elif (smin == 0.0):\n",
    "                            data.loc[data['PassengerId'] ==\n",
    "                                     passID, 'Family_Survival'] = 0\n",
    "\n",
    "            # Luego se agrupa la informacion por tickets y se procede\n",
    "            for _, grp_df in data.groupby('Ticket'):\n",
    "                if (len(grp_df) != 1):\n",
    "                    for ind, row in grp_df.iterrows():\n",
    "                        if (row['Family_Survival'] == 0) | (row['Family_Survival'] == 0.5):\n",
    "                            smax = grp_df.drop(ind)['Survived'].max()\n",
    "                            smin = grp_df.drop(ind)['Survived'].min()\n",
    "                            passID = row['PassengerId']\n",
    "                            if (smax == 1.0):\n",
    "                                data.loc[data['PassengerId'] ==\n",
    "                                         passID, 'Family_Survival'] = 1\n",
    "                            elif (smin == 0.0):\n",
    "                                data.loc[data['PassengerId'] ==\n",
    "                                         passID, 'Family_Survival'] = 0\n",
    "\n",
    "            self.family_dict = data.groupby('Last_Name').mean()[\n",
    "                'Family_Survival']\n",
    "        else:\n",
    "            return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        data = X.copy()\n",
    "        data['Family_Survival'] = self.default_prob\n",
    "\n",
    "        if self.family_dict is not None:\n",
    "            if type(data) is not pd.core.series.Series:\n",
    "\n",
    "                for x in data.itertuples():\n",
    "                    if x.Last_Name in self.family_dict:\n",
    "                        prob = self.family_dict.loc[x.Last_Name]\n",
    "                        data.loc[data['PassengerId'] ==\n",
    "                                 x.PassengerId, 'Family_Survival'] = prob\n",
    "                return data\n",
    "\n",
    "            else:\n",
    "\n",
    "                if data['Last_Name'] in self.family_dict:\n",
    "                    prob = self.family_dict.loc[data['Last_Name']]\n",
    "                    data['Family_Survival'] = prob\n",
    "\n",
    "                return data\n",
    "\n",
    "        else:\n",
    "            print('Inicializar diccionario de familias antes de transformar!')\n",
    "\n",
    "\n",
    "class ColToCat(BaseEstimator, TransformerMixin):\n",
    "    '''Toma un conjunto de datos df y transfroma la columna col en categorica.\n",
    "\n",
    "    La cantidad de bins viene dada por el parametro cuts.'''\n",
    "\n",
    "    def __init__(self, col='Fare', cuts=4):\n",
    "        self.col = col\n",
    "        self.cutter = KBinsDiscretizer(\n",
    "            n_bins=cuts, encode='ordinal', strategy='quantile')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        data = X.copy()\n",
    "        self.cutter.fit(data[self.col].values.reshape([-1, 1]))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col] = self.cutter.transform(\n",
    "                data[self.col].values.reshape([-1, 1]))\n",
    "        else:\n",
    "            data[self.col] = self.cutter.transform(\n",
    "                np.array(data[self.col]).reshape([-1, 1]))[0][0]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class TitleGen(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def get_title(self, name):\n",
    "        '''Obtiene le titulo asociado a una persona.'''\n",
    "\n",
    "        if '.' in name:\n",
    "            return name.split(',')[1].split('.')[0].strip()\n",
    "        else:\n",
    "            return 'desconocido'\n",
    "\n",
    "    def set_title(self, x):\n",
    "        '''Reduce el titulo a Mr,Mrs o Miss segun corresponda.'''\n",
    "\n",
    "        title = x['Title']\n",
    "        if title in ['Capt', 'Col', 'Don', 'Jonkheer', 'Major', 'Rev', 'Sir']:\n",
    "            return 'Mr'\n",
    "        elif title in ['the Countess', 'Mme', 'Lady', 'Dona']:\n",
    "            return 'Mrs'\n",
    "        elif title in ['Mlle', 'Ms']:\n",
    "            return 'Miss'\n",
    "        elif title == 'Dr':\n",
    "            if x['Sex'] == 'male':\n",
    "                return 'Mr'\n",
    "            else:\n",
    "                return 'Mrs'\n",
    "        else:\n",
    "            return title\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data['Name']) is not pd.core.series.Series:\n",
    "            data['Title'] = self.get_title(data['Name'])\n",
    "            data['Title'] = self.set_title(data)\n",
    "        else:\n",
    "            data['Title'] = data['Name'].map(lambda x: self.get_title(str(x)))\n",
    "            data['Title'] = data.apply(self.set_title, axis=1)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class AgeImputer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, title_map=None):\n",
    "        self.title_map = title_map\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.title_map is None:\n",
    "            data = X.copy()\n",
    "            self.title_map = data.groupby(\n",
    "                'Title')['Age'].apply(lambda x: x.median())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ''' Llena la información faltante de la columna Age en df. \n",
    "\n",
    "        Utiliza una agrupacion por titulo y aplica un llenado por mediana de grupo.\n",
    "\n",
    "        Retorna:\n",
    "        -------- \n",
    "\n",
    "        data: Pandas.DataFrame \n",
    "            Conjunto de datos con la variable Age completada.\n",
    "        '''\n",
    "        data = X.copy()\n",
    "        if type(data['Age']) is not pd.core.series.Series:\n",
    "            if data.isnull()['Age'].any():\n",
    "                data['Age'] = self.title_map.loc[data['Title']]\n",
    "\n",
    "        else:\n",
    "            data.loc[data['Age'].isnull(), 'Age'] = data['Title'].map(\n",
    "                self.title_map)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class ModeFill(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, col, mode=None):\n",
    "\n",
    "        self.col = col\n",
    "        self.mode = mode\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.mode is None:\n",
    "            data = X.copy()\n",
    "            self.mode = data[self.col].mode()[0]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Llena los valores faltantes de col en df usando la moda global.\n",
    "\n",
    "        Retorna: \n",
    "        -------- \n",
    "\n",
    "        data: Pandas.DataFrame \n",
    "            Conjunto de datos con la informacion de col completada. \n",
    "        '''\n",
    "\n",
    "        data = X.copy()\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col] = data[self.col].fillna(self.mode)\n",
    "        else:\n",
    "            if data.isnull()[self.col].any():\n",
    "                data[self.col] = self.mode\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class FillDesconocido(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, col):\n",
    "        self.col = col\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        ''' Toma un conjunto de datos df y llena la columna col con el valor\n",
    "        'desconocido'.\n",
    "\n",
    "        Retorna:\n",
    "        -------- \n",
    "\n",
    "        data : Pandas.DataFrame\n",
    "            Conjunto de datos con la variable col completada. \n",
    "\n",
    "        '''\n",
    "        data = X.copy()\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col].fillna('desconocido', inplace=True)\n",
    "        else:\n",
    "            if data.isnull()[self.col].any():\n",
    "                data[self.col] = 'desconocido'\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class CabinCat(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def unknown_cabin(self, cabin):\n",
    "        if cabin != 'd':\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Genera dos categorias en df basandose en la columna Cabin.\n",
    "\n",
    "        Retorna:\n",
    "        -------\n",
    "\n",
    "        data : Pandas.DataFrame \n",
    "            Conjunto de datos con la categorizacion creada. \n",
    "        '''\n",
    "\n",
    "        data = X.copy()\n",
    "        if type(data['Cabin']) is pd.core.series.Series:\n",
    "            data['Cabin'] = data['Cabin'].map(lambda x: x[0])\n",
    "            data['Cabin'] = data['Cabin'].apply(\n",
    "                lambda x: self.unknown_cabin(x))\n",
    "        else:\n",
    "            data['Cabin'] = data['Cabin'][0]\n",
    "            data['Cabin'] = self.unknown_cabin(data['Cabin'])\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class FamilySizeGen(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Genera la columna Family_Size a partir de SibSp y Parch en df. \n",
    "\n",
    "        Retorna:\n",
    "        ------- \n",
    "        data : Pandas.DataFrame \n",
    "            Conjunto de datos con la columna creada. \n",
    "\n",
    "        '''\n",
    "        data = X.copy()\n",
    "        data['Family_Size'] = data['SibSp'] + data['Parch']\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class OneHotEncoderCol(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, col='Sex'):\n",
    "        self.col = col\n",
    "        self.ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        data = X.copy()\n",
    "        self.ohe.fit(data[self.col].values.reshape([-1, 1]))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Genera codificacion One hot en df basandose en la columna col.\n",
    "\n",
    "        Retorna:\n",
    "        -------\n",
    "\n",
    "        data : Pandas.DataFrame\n",
    "            Conjunto de datos con el encoding creado.\n",
    "        '''\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col] = self.ohe.transform(\n",
    "                data[self.col].values.reshape([-1, 1]))\n",
    "\n",
    "        else:\n",
    "            val = np.array(data[self.col]).reshape([-1, 1])\n",
    "            data[self.col] = self.ohe.transform(val)[0][0]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class OrdinaltEncoderCol(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, col='Title'):\n",
    "        self.col = col\n",
    "        self.ode = OrdinalEncoder()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        data = X.copy()\n",
    "        self.ode.fit(data[self.col].values.reshape([-1, 1]))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Genera codificacion Ordinal df basandose en la columna col.\n",
    "\n",
    "        Retorna:\n",
    "        -------\n",
    "\n",
    "        data : Pandas.DataFrame \n",
    "            Conjunto de datos con el encoding creado. \n",
    "        '''\n",
    "\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data[self.col]) is pd.core.series.Series:\n",
    "            data[self.col] = self.ode.transform(\n",
    "                data[self.col].values.reshape([-1, 1]))\n",
    "\n",
    "        else:\n",
    "            val = np.array(data[self.col]).reshape([-1, 1])\n",
    "            data[self.col] = self.ode.transform(val)[0][0]\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class DropCols(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, cols=config.TO_DROP_PIPE):\n",
    "        self.cols = cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Elimina las columans cols del DataFrame df.\n",
    "\n",
    "\n",
    "        Retorna:\n",
    "        --------\n",
    "        data : Pandas.DataFrame \n",
    "            Conjunto de datos con las columnas borradas. \n",
    "\n",
    "        '''\n",
    "\n",
    "        data = X.copy()\n",
    "        if type(data) is pd.core.frame.DataFrame:\n",
    "            data.drop(self.cols, axis=1, inplace=True)\n",
    "        else:\n",
    "            data.drop(self.cols, inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "class StdScaler(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.std_scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        data = X.copy()\n",
    "        self.std_scaler.fit(data)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''Toma un DataFrame y lo estandariza, retorna un DataFrame.'''\n",
    "\n",
    "        data = X.copy()\n",
    "\n",
    "        if type(data) is pd.core.frame.DataFrame:\n",
    "            cols = data.columns\n",
    "            res = self.std_scaler.transform(data)\n",
    "            return pd.DataFrame(res, columns=cols)\n",
    "\n",
    "        else:\n",
    "            cols = data.index\n",
    "            res = self.std_scaler.transform(data.values.reshape([1, -1]))\n",
    "            return pd.Series(data=res[0], index=cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**pipeline.py** \n",
    "\n",
    "En este módulo generamos la pipeline de entrenamiento utilizando los preprocedadores construidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/pipeline.py \n",
    "import joblib\n",
    "\n",
    "import config\n",
    "import preprocesssors as pp \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "family_dict = joblib.load(config.FAMILY_DICT)\n",
    "model = joblib.load(config.MODELS_PATH + config.FINAL_MODEL)\n",
    "\n",
    "train_pipe = Pipeline([\n",
    "    ('Fare mean fill',pp.NaMeanFiller()),\n",
    "    ('Last_Name gen',pp.LastNameGen()),\n",
    "    ('Family_Survival gen', pp.FamilySurvivalGen(family_dict=family_dict)),\n",
    "    ('Fare to cat', pp.ColToCat()),\n",
    "    ('Title var gen', pp.TitleGen()),\n",
    "    ('Age imputer', pp.AgeImputer()),\n",
    "    ('Age to cat', pp.ColToCat(col='Age')),\n",
    "    ('Title to ordinal', pp.OrdinaltEncoderCol()),\n",
    "    ('Sex to One Hot Enc', pp.OneHotEncoderCol()),\n",
    "    ('Fill with the mode Embarked', pp.ModeFill(col='Embarked')),\n",
    "    ('Embarked to Ordinal', pp.OrdinaltEncoderCol(col='Embarked')),\n",
    "    ('Fill desconocido Cabin',pp.FillDesconocido(col='Cabin')),\n",
    "    ('Cabin to Cat', pp.CabinCat()),\n",
    "    ('Family size gen', pp.FamilySizeGen()),\n",
    "    ('drop cols',pp.DropCols(cols = config.TO_DROP_PIPE)),\n",
    "    ('Scaler', pp.StdScaler()),\n",
    "    ('clf', model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**train.py** \n",
    "\n",
    "Acá se genera un rutina de entrenamiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/train.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "import pipeline\n",
    "import config\n",
    "\n",
    "\n",
    "def train(model_name = 'last_model'):\n",
    "    # Lee los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    #Entrena el modelo\n",
    "    pipeline.train_pipe.fit(x_train, y_train)\n",
    "    \n",
    "    #Guarda el modelo \n",
    "    joblib.dump(pipeline.train_pipe, config.LAST_MODEL_PATH + model_name)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notación anterior nos permite ejecutar el proceso de entrenamiento por medio de la terminal:\n",
    "\n",
    "```\n",
    "(entorno_virtual) user@ruta/a/ProjectLab$ python train.py\n",
    "```\n",
    "\n",
    "Con esto se entrena un modelo de nombre `last_model` en la carpeta `last_models`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**predict.py** \n",
    "\n",
    "Se genera un script que produce predicciones basadas en un modelo a elección"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/predict.py \n",
    "import pandas as pd \n",
    "\n",
    "import joblib\n",
    "import config\n",
    "\n",
    "def predict(X):\n",
    "    \n",
    "    model = joblib.load(config.LAST_MODEL_PATH + config.LAST_MODEL_NAME)\n",
    "    \n",
    "    return model.predict(X)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    # Se obtienen los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "        \n",
    "    # Datos de entrenamiento\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    # Datos test\n",
    "    X = test_data.drop(config.TARGET, axis=1)\n",
    "    y = test_data[config.TARGET]\n",
    "    \n",
    "    # Resultados\n",
    "    c_train = classification_report(predict(x_train),y_train)\n",
    "    c_test = classification_report(predict(X),y)\n",
    "    \n",
    "    print('Score en Train:', c_train) \n",
    "    print('Score en Test:', c_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de una Aplicación a partir de un Flujo de Aprendizaje Automático\n",
    "\n",
    "Luego de generados los módulos es necesarios pasamos a crear una estructura de librería para ello generamos la carpeta `packages` dentro la carpeta de nuestro proyecto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ProjectLab/packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea consiste en estructurar nuestros módulos de manera tal que se tenga una estructura de librería, con la cual se generen resultados reproducibles y mantenibles. \n",
    "\n",
    "En este punto del desarrollo se recomienda crear un repositorio de control de versiones propio para el proyecto (asociado a la carpeta ProjectLab en este caso) de manera que tal repositorio se convierta en la herramienta de mantenibilidad del proyecto en producción.\n",
    "\n",
    "La restructuración que haremos permite generar resultados reproducibiles, reducir el riesgo de errores, mejorar la capacidad de depurar el código, manejando de manera elegante los errores. Por último, la estructura modular nos permite extender y actualizar componentes de modelo de manera sencilla y robusta.\n",
    "\n",
    "Comenzamos con la siguiente estructura de carpetas:\n",
    "\n",
    "```\n",
    "|ProjectLab/\n",
    "\n",
    "--| packages/\n",
    "\n",
    "----| clf_model/\n",
    "------| requirements.txt\n",
    "\n",
    "------| clf_model/\n",
    "\n",
    "--------| config/\n",
    "----------| __init__.py\n",
    "----------| config.py\n",
    "\n",
    "--------| data/\n",
    "----------| __init__.py\n",
    "----------| train.csv\n",
    "----------| test.csv\n",
    "\n",
    "--------| meta_data\n",
    "----------| __init__.py\n",
    "----------| family_dict\n",
    "\n",
    "--------| processing/\n",
    "----------| __init__.py\n",
    "----------| preprocessors.py\n",
    "\n",
    "--------| trained_models/\n",
    "----------| __init__.py\n",
    "\n",
    "--------| last_model/\n",
    "----------| __init__.py\n",
    "```\n",
    "\n",
    "Observamos que la carpeta `clf_model` se encuentra dos veces en la estructura debido a la convención de creación de librerías de Python. Los archivos `__init__.py` están vacios por la misma convención. En `~/trained_models/` se encuentran los modelos entrenados en la fase de investigación. Por su parte `/last_model/` se deja vacía para reproducir los resultados obtenidos anteriormente.\n",
    "\n",
    "Los siguientes comandos generan la estructura de carpetas y archivos `__init__.py` usando comandos de la terminal (linux - mac) desde una celda de Jupyter, el proceso puede hacerse de manera manual en windows y en general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ProjectLab/packages/clf_model\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model\n",
    "!touch ProjectLab/packages/clf_model/clf_model/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/config\n",
    "!touch ProjectLab/packages/clf_model/clf_model/config/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/data\n",
    "!touch ProjectLab/packages/clf_model/clf_model/data/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/meta_data\n",
    "!touch ProjectLab/packages/clf_model/clf_model/meta_data/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/processing\n",
    "!touch ProjectLab/packages/clf_model/clf_model/processing/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/trained_models\n",
    "!touch ProjectLab/packages/clf_model/clf_model/trained_models/__init__.py\n",
    "\n",
    "!mkdir ProjectLab/packages/clf_model/clf_model/last_model\n",
    "!touch ProjectLab/packages/clf_model/clf_model/last_model/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los demás archivos se mueven de manera manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario crear un archivo de texto llamado `requirements.txt` donde se especifican las dependencias asociadas a nuestra librerías. Para generar tal archivo accedemos a nuestro entorno virtual y ejecutamos:\n",
    "\n",
    "```\n",
    "(entorno_virtual) user@/ruta/a/ProjectLab$ pip freeze > requirements.txt\n",
    "``` \n",
    "\n",
    "De esta manera almacenamos todas las librerías que utilizamos en la creación del código de desarrollo. En este caso se observa que los primeros 7 requerimientos utilizados corresponden a:\n",
    "```\n",
    "autopep8==1.5.3\n",
    "backcall==0.2.0\n",
    "click==7.1.2\n",
    "cycler==0.10.0\n",
    "decorator==4.4.2\n",
    "Flask==1.1.2\n",
    "ipykernel==5\n",
    "```\n",
    "Observe que los resultados pueden variar en función de los paquetes que haya instalado en su entorno virtual. Podemos cambiar los signos `==` por `>=` o `<=` si deseamos cambiar las versiones que nuestra librería requiere. También se puede usar la notación:\n",
    "\n",
    "```\n",
    "libr >= ver_0, < ver_1\n",
    "```\n",
    "\n",
    "donde lo que se hace es asegurar compatibilidad con la librería `libr` entre las versiones `ver_0` (incluida) y `ver_1` (excluida). Tambíen se pueden eliminar módulos no utilizados por nuestra librería como por ejemplo `autopep8` y `ipykernel` ambas instaladas en el entorno de Jupyter en la fase de investigación. En este caso se mantendrán las librerías capturadas por `pip freeze`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ProjectLab/requirements.txt', 'r') as req_txt:\n",
    "    print(req_txt.read()[:102])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Cabmie los itnervalos de requerimientos para la aplicación, de manera tal que acepte versiones mayores o iguales a las obtenidas por `pip freeze` pero estrictamente menores a la siguiente versión. A modo de ejemplo, observe que para la librería `flask` se requiere como mínimo la versión `1.1.2`, se considerará como *siguiente versión* a `2.0.0`. \n",
    "\n",
    "2. Disminuya la cantidad de módulos requeridos al mínimo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movemos el archivo `ProjectLab/requirements.txt` a la carpeta `ProjectLab/packages/clf_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ProjectLab/requirements.txt ProjectLab/packages/clf_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es hacer un manejo de las dependencias utilizando entornos virtuales automatizados, para ello, se hará uso de la aplicación `Tox`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de dependencias con Tox\n",
    "\n",
    "`tox` es un proyecto de automatizción con Python, su principal función es facilitar el uso de *tests* y de entornos virtuales. Para comprender su funcionamiento comenzaremos con el manejo de dependencias sobre nuestro paquete.\n",
    "\n",
    "El primer paso es instalar tox de la manera usual, luego se genera un archivo llamado `tox.ini`, este corresponde a un archivo de configuración que debe ubicarse en la carpeta del módulo que se desea testear, en este caso `ProjectLab/packages/clf_model/`.\n",
    "\n",
    "La idea de esta librería es la de generar entornos virtuales de manera automática. En estos entornos se instalan las dependencias indicadas por el usuario (en este caso dadas por requirements.txt), posteriormente se ejecutan scripts de módulo que se desea controlar. \n",
    "\n",
    "Los scripts que queremos ejecutar con tox son rutinas de *prueba* o *test*, es decir, corresponden a códigos con los cuales queremos asegurar que nuestra librería sea reproducible en cualquier máquina que cumpla con los requerimientos que solicitamos.\n",
    "\n",
    "En este caso tenemos que el archivo `train.py` debe ser capaz de entrenar un modelo y guardarlo con el nombre `last_model`. Podemos indicar a `tox` que comando ejecutar por medio del campo `comands` este sigue la sintaxis:\n",
    "\n",
    "```\n",
    "commands =\n",
    "    python codigo_a_ejecutar.py\n",
    "```\n",
    "\n",
    "Por otra parte, podemos indicar las dependencias por medio de `deps`. Para automatizar este proceso entregamos el documento `requierements.txt` que necesita nuestra implementación. En este caso, se sigue la sintaxis:\n",
    "```\n",
    "deps =\n",
    "\t-rrequirements.txt\n",
    "```\n",
    "Observe que se utiliza `-r` sin espacio y antes del nombre del archivo. Para indicar que se instalen las librerías necesarias usando `requirements.txt` se debe indicar el comando `install_command` con la orden `pip install {opts} {packages}`. Por último, fijamos la carpeta a la cual se asociará la ejecución de todo script de python, esta se configura con la opción `PYTHONPATH` dentro del comando `setenv`, para ello se utiliza la sintaxis\n",
    "```\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "```\n",
    "\n",
    "Con esto se le indica a `tox` que la carpeta relativa a la cual se ubica el archivo `tox.ini` tendrá la información librerías y módulos que se debe utilizar. El conjunto de opciones detalladas recientemente corresponden al ambiente de *prueba* o *testing*, esto se indica utilizando la notación `[testenv]`. \n",
    "\n",
    "Por último, se entrega un ambiente de ejecución de `tox` utilizando la sintaxis `[tox]`. Al igual que con el ambiente de pruebas, este ambiente tiene opciones especificas, dentro de las cuales se utilizará `envlist` que corresponde al ambiente virtual donde se ejecutarán los comandos indicados en `[testenv]`. Acá se pueden proporcionar múltiples entornos virtuales, ĺos cuales serán creados por tox de manera automática.  Asociado a esto se encuentra la opción `[skipsdist]`con la cual se indica si tox debe empaquetar el conjunto de código sobre el cual se hacen pruebas (ej: se trabaja en una librería), en tox se recomienda indicar esta opción como `True` si se trabaja con una aplicación. \n",
    "\n",
    "A continuación crearemos un archivo de configuración de `tox` con el cual se creará un entorno virtual automático `clf_model`, instalará los requerimientos necesarios y ejecutará un script indicando si todo el proceso salió como se esperaba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/test.py \n",
    "\n",
    "print('Prueba de Tox finalizada con Exito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/tox.ini \n",
    "[tox]\n",
    "envlist = clf_model\n",
    "skipsdist = True\n",
    "\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "deps =\n",
    "    -rrequirements.txt\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/test.py  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de generar el test a ejecutar y construir el archivo de configuración de `tox`, se pasa a ejecutar dicho test en un entorno de python independiente y generado de manera automática con `tox`. Para ello nos debemos ubicar en la carpeta `ProjectLab/packages/clf_model/` que es donde deberían estar los archivos `requirements.txt` y `tox.ini`, además de la carpeta `./clf_model/`.\n",
    "\n",
    "En dicha carpeta ejecutamos:\n",
    "\n",
    "```\n",
    "user@ruta/a/packages/clf_model$ tox\n",
    "```\n",
    "\n",
    "cuyo resultado debería ser\n",
    "\n",
    "```\n",
    "clf_model: commands succeeded\n",
    "  congratulations :)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a utilizar `tox` para probar la rutina de entrenamiento del modelo generado, para ello, se requiere modificar la estructura de los módulos generados para que sean compatibles con la estructura de librería que se utiliza actualmente. \n",
    "\n",
    "Primero se observa que en el archivo `config.py` es necesario cambiar algunas las rutas de acceso, esto pues las rutas proporcionadas se basan en la estructura de carpetas actual, la cual puede no necesariamente coincidir con la obtenida finalmente al empaquetar. Para garantizar flexibles utilizamos `pathlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/config/config.py\n",
    "import pathlib\n",
    "import clf_model\n",
    "\n",
    "PACKAGE_ROOT = pathlib.Path(clf_model.__file__).resolve().parent\n",
    "\n",
    "TARGET = 'Survived'\n",
    "LAST_MODEL_NAME = 'last_model'\n",
    "\n",
    "MODELS_PATH  = PACKAGE_ROOT / 'trained_models/'\n",
    "FINAL_MODEL = MODELS_PATH / 'vote_soft'\n",
    "\n",
    "LAST_MODEL_PATH = PACKAGE_ROOT / 'last_model/'\n",
    "\n",
    "DATA_PATH_TRAIN = PACKAGE_ROOT / 'data/train.csv'\n",
    "DATA_PATH_TEST = PACKAGE_ROOT / 'data/test.csv' \n",
    "FAMILY_DICT =PACKAGE_ROOT / 'meta_data/family_dict'\n",
    "\n",
    "TO_DROP_PIPE = ['Name', 'Parch', 'SibSp', 'Ticket', 'Last_Name', 'PassengerId', 'Embarked', 'Cabin']\n",
    "\n",
    "FINAL_VARS = ['Pclass','Sex','Age', 'Fare',\n",
    "              'Family_Survival', 'Title', 'Family_Size']\n",
    "\n",
    "TEST_VARS = ['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch',\n",
    "            'Ticket', 'Fare', 'Cabin', 'Embarked']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que ahora se utiliza una estructura de librería, es necesario importar nuestras dependencias de otra manera por ejemplo si antes se importaban las configuraciones por medio de:\n",
    "\n",
    "```\n",
    "import config\n",
    "```\n",
    "ahora se importan utilizando\n",
    "\n",
    "```\n",
    "from clf_model.config import config\n",
    "```\n",
    "Es necesario hacer modificaciones de esta naturalelza a los archivos `train.py`, `pipeline.py`, `predict.py` y `processing/preprocessors.py` así por ejemplo, el script de entrenamiento pasa a ser:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from clf_model import pipeline\n",
    "from clf_model.config import config \n",
    "\n",
    "\n",
    "def train(model_name = config.LAST_MODEL_NAME):\n",
    "    '''Entrena el modelo final.'''\n",
    "\n",
    "    # Lee los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    #Entrena el modelo\n",
    "    pipeline.train_pipe.fit(x_train, y_train)\n",
    "\n",
    "    name =  model_name+'_'+str(_version) \n",
    "    file_name = config.LAST_MODEL_PATH / name \n",
    "\n",
    "    #Guarda el modelo \n",
    "    joblib.dump(pipeline.train_pipe, file_name) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se procede a comprobar que el archivo train permite recuperar el modelo antes entrenado, para ello se modifica el archivo de configuraciones `tox.ini` indicando que se ejecute `train.py` y `predict.py`. Se borra además el archivo `test.py` pues ya no es de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ProjectLab/packages/clf_model/clf_model/test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/tox.ini \n",
    "[tox]\n",
    "envlist = clf_model\n",
    "skipsdist = True\n",
    "\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "deps =\n",
    "    -rrequirements.txt\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/train.py  \n",
    "    python clf_model/predict.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de esta operación debe ser un modelo llamado `last_model` en la carpeta `clf_model/last_model` además de una impresión en pantalla con los resultados de predicción. Estos últimos resultados deben ser identicos a los obtenidos anteriormente para asegurar reproducibilidad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testeo\n",
    "\n",
    "Una vez estructurada nuestra aplicación se hace necesario construir *pruebas* o *test* con los cuales podamos asegurar la correctitud del código generado. Para esto se hace uso de la librería `pytest`. \n",
    "\n",
    "Se procede a instalar esta librería y a agregarla a las dependencias del nuestra aplicación, en este caso es necesario ejecutar `tox -r` para que se reconstruya el entorno virtual que añade la nueva dependencia.\n",
    "\n",
    "Pytest es una herramienta que permite escribir pruebas de código de manera sencilla, presenta un manejo simple de excepciones por medio de comandos `assert` detallados. \n",
    "\n",
    "Pytest permite ejecutar todo un conjunto de códigos de prueba dentro de una carpeta a elección. Así, si por ejemplo se almacenan las pruebas de código en la capeta `~/pruebas/` entonces al utilizar la orden `pytest ~/pruebas` se ejecutarán todos los códigos de prueba ahí almacenados. El resultado de la ejecución de dichas pruebas se mostrará en pantalla entregando un mensaje si alguna de estas pruebas falla.\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Se construye la carpeta `~/tests/` en la cual se genera un código de prueba a ejecutar con `pytest` desde `tox`. Para ello se procede a crear tanto la carpeta como código de prueba necesario.\n",
    "\n",
    "La carpeta tests se ubica en la siguiente ruta:\n",
    "```\n",
    "~/ProjectLab/packages/clf_model/tests\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ProjectLab/packages/clf_model/tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se modifica la función de predicción `predict.py`. A partir de este archivo se genera el script `prediction_report.py` que mantiene los contenidos originales de `prediction.py` (respaldo). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp ProjectLab/packages/clf_model/clf_model/predict.py ProjectLab/packages/clf_model/clf_model/prediction_report.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a modificar el contenido original de `predict.py` de manera que este reciba un archivo `json` codificando los datos inputs y entregue un diccionario con las predicciones asociadas a tales inputs. Esto tiene sentido, pues se busca crear una aplicación web, de la cual se espera interactuar con archivos en formato `json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file  ProjectLab/packages/clf_model/clf_model/predict.py\n",
    "import pandas as pd \n",
    "import joblib\n",
    "\n",
    "from clf_model.config import config \n",
    "\n",
    "def predict(input_data):\n",
    "    '''Predice utilizando el modelo entrenado.''' \n",
    "    name =  config.LAST_MODEL_NAME + '_' +str(_version)\n",
    "    model = joblib.load(config.LAST_MODEL_PATH / name)\n",
    "    \n",
    "    data = pd.read_json(input_data, orient='index')\n",
    "    \n",
    "    if data.shape[1] == 1:\n",
    "\n",
    "        output = model.predict(pd.DataFrame(data).T)\n",
    "    else:\n",
    "        output = model.predict(data)\n",
    "\n",
    "\n",
    "    response = {\"predictions\": output}\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se escribe un test sobre la función de predicción, para ello nos ubicamos en la carpeta `ProjectLab/packages/clf_model/tests` y generamos el archivo `test_predict.py`. \n",
    "\n",
    "En este apartado cargamos el dataset `test.csv` y comprobamos que la respuesta de predicción es consistente con la respuesta esperada. En este caso, sabemos que a la primera fila de `test.csv` le corresponde la predicción `0` mientras que a la última fila le corresponde `1`.\n",
    "\n",
    "**Obs:** Se debe agregar la variable global `DATA_PATH_TEST = root +'data/test.csv'` en el modulo de configuraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file  ProjectLab/packages/clf_model/tests/test_predict.py\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from clf_model.predict import predict\n",
    "from clf_model.config import config \n",
    "\n",
    "def test_predict_tails():\n",
    "    \n",
    "    test_data = pd.read_csv(config.DATA_PATH_TEST)\n",
    "    \n",
    "    json_1 = test_data.iloc[0].to_json(orient='index')\n",
    "    json_2 = test_data.iloc[-1].to_json(orient='index')\n",
    "\n",
    "    subject_1 = predict(input_data=json_1)\n",
    "    subject_2 = predict(input_data=json_2)\n",
    "\n",
    "    \n",
    "    assert any((subject_1,subject_2)) is not None \n",
    "    print(type(subject_1.get('predictions')[0]))\n",
    "    \n",
    "    assert isinstance(subject_1.get('predictions')[0], np.int64)\n",
    "    assert isinstance(subject_2.get('predictions')[0], np.int64)\n",
    "    \n",
    "    assert subject_1.get('predictions')[0] == 0\n",
    "    assert subject_2.get('predictions')[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se modifica el texto de configuración para testeo con pytest, para ejecutar todos los tests de la carpeta `tests/` agregamos el comando `pytest tests`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/tox.ini \n",
    "[tox]\n",
    "envlist = clf_model\n",
    "skipsdist = True\n",
    "\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "deps =\n",
    "    -rrequirements.txt\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/train.py \n",
    "    pytest tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar tox, se ejecutará el test sobre los ouputs del primer y ultimo registro en el conjunto de test. Si el modelo es reproducible se deben pasar las pruebas programadas. Vale la pena observar que el test anterior puede ser modificado de manera que al entrenar un nuevo modelo se garantice que el tipo de output que este genera es consistente con nuestros datos. En tal caso, no sería necesario corroborar que las predicciones esperadas con precisamente `0` y `1`. \n",
    "\n",
    "Lo anterior muestra la importancia del diseño de tests, si estos son bien imeplementados permiten generar un sistema automático de confirmación antes de hacer cualquier cambio en nuestra aplicación / repositorio. Por otra parte, si se agregan pruebas mal diseñadas, pueden haber situaciones en las que se rechaze código que funciona bien. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicios**\n",
    "\n",
    "1. Es una buena práctica validar los datos de entrada antes de hacer predicciones. Este proceso de validación consiste en entregar los datos sobre los que se busca predecir a una función que se asegura que tales datos tengan el formato necesario para predecir sobre ellos. Genere el módulo `validation.py` en cual existe la función `validate_input` que recibe un `DataFrame` de pandas y revisa si este posee las columnas necesarias y que no tenga valores nulos. Agregue finalmente un paso de validación antes de predecir en la función `predict.py`.\n",
    "\n",
    "2. El principio de modularidad requiere separar los procesos según su naturaleza. Observe que en la sección de preprocesdores están mezclados los transformadores que en efecto preprocesan los datos junto con transformadores que efectúan ingenieria de características. Genere un módulo que permita separar estos dos procedimientos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versionamiento y Logging\n",
    "\n",
    "El versionamiento de una aplicación consiste en asignar un identificador único a ciertos estados de la apliación. En el contexto de ciencia de datos, el versionamiento permite asegurar reproducibilidad, que es el concepto clave al momento de desplegar una prueba de concepto. \n",
    "\n",
    "Por otra parte, el concepto de *Logging* hace referencia al registro de eventos. Esto es de suma importancia pues permite tener un control de la aplicación implementada. \n",
    "\n",
    "Para asociar una versión a nuestra aplicación generamos el archivo `VERSION` según la ruta:\n",
    "\n",
    "```\n",
    "user@ruta/a/clf_model/clf_model/VERSION\n",
    "```\n",
    "\n",
    "En este caso, el archivo no posee ninguna extensión y contiene el número de versión asociado al estado actual de la aplicación. Acá seguiremos el *formato de versiones semantico* que consiste en:\n",
    "\n",
    "```\n",
    "version_mayor.version_menor.parche\n",
    "```\n",
    "\n",
    "Se procede a generar dicho archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/VERSION \n",
    "0.1.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es indicarle a nuestra aplicación que versión posee, para ello se accede al archivo `__init__.py` asociado al paquete que estamos creando. Acá agregamos la ruta al archivo que hemos creado con la versión y asignamos su contenido a la veriable de entorno `__version__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/__init__.py \n",
    "from clf_model.config import config\n",
    "\n",
    "VERSION_PATH = config.PACKAGE_ROOT / 'VERSION'\n",
    "\n",
    "with open(VERSION_PATH,'r') as handler: \n",
    "    __version__ = handler.read().strip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación generamos un esquema de persistencia de modelos usando la versión del paquete actual. Esto se refiere a modificar el proceso de guardado de modelos entrenados, cada modelo entrenado tendrá asociada una versión. Queremos además una relación *uno a uno* entre modelos y versiones del paquete, por este motivo se deben borrar los modelos correspondientes a versiones anteriores. \n",
    "\n",
    "Primero se modifica el archivo `train.py` que guarda el modelo entrenado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/train.py\n",
    "import  warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from clf_model import pipeline\n",
    "from clf_model.config import config \n",
    "from clf_model import __version__ as _version \n",
    "\n",
    "def clean_old_models(files_to_keep)  :\n",
    "    '''Limpia los modelos generados en versiones anteriores.'''\n",
    "\n",
    "    for model_file in config.LAST_MODEL_PATH.iterdir():\n",
    "        if model_file.name not in [files_to_keep, \"__init__.py\"]:\n",
    "            model_file.unlink()\n",
    "\n",
    "def train(model_name = config.LAST_MODEL_NAME):\n",
    "    '''Entrena el modelo final.'''\n",
    "\n",
    "    # Lee los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    #Entrena el modelo\n",
    "    pipeline.train_pipe.fit(x_train, y_train)\n",
    "\n",
    "    name =  model_name+'_'+str(_version) \n",
    "    file_name = config.LAST_MODEL_PATH / name \n",
    "\n",
    "    #Guarda el modelo y limpia\n",
    "    clean_old_models(files_to_keep = file_name)\n",
    "    joblib.dump(pipeline.train_pipe, file_name) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego se modifican los archivos que dependen del nombre del modelo, en este caso `predict.py` y `prediction_report.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/predict.py\n",
    "import pandas as pd \n",
    "import joblib\n",
    "\n",
    "from clf_model.config import config \n",
    "from clf_model import __version__ as _version \n",
    "\n",
    "def predict(input_data):\n",
    "    '''Predice utilizando el modelo entrenado.''' \n",
    "    name =  config.LAST_MODEL_NAME + '_' +str(_version)\n",
    "    model = joblib.load(config.LAST_MODEL_PATH / name)\n",
    "    \n",
    "    data = pd.read_json(input_data, orient='index')\n",
    "    \n",
    "    if data.shape[1] == 1:\n",
    "\n",
    "        output = model.predict(pd.DataFrame(data).T)\n",
    "\n",
    "    else:\n",
    "        output = model.predict(data)\n",
    "\n",
    "\n",
    "    response = {\"predictions\": output}\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/prediction_report.py\n",
    "import pandas as pd \n",
    "\n",
    "import joblib\n",
    "\n",
    "from clf_model.config import config\n",
    "from clf_model import __version__ as _version \n",
    "\n",
    "def predict(X):\n",
    "    name = config.LAST_MODEL_NAME+'_'+str(_version)\n",
    "    model = joblib.load(config.LAST_MODEL_PATH / name)\n",
    "    return model.predict(X)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    \n",
    "    # Se obtienen los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "        \n",
    "    # Datos de entrenamiento\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    # Datos test\n",
    "    X = test_data.drop(config.TARGET, axis=1)\n",
    "    y = test_data[config.TARGET]\n",
    "    \n",
    "    # Resultados\n",
    "    c_train = classification_report(predict(x_train),y_train)\n",
    "    c_test = classification_report(predict(X),y)\n",
    "    \n",
    "    print('Score en Train:', c_train) \n",
    "    print('Score en Test:', c_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: Se deben ejecutar nuevamente los tests implementados para asegurar que todo funciona como es debido. Esto se hace de manea sencilla con el comando `tox` si todo esta configurado como indicado anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es generar un sistema de registro de eventos o *logging*. Para ello, se importa la librería `logging` en archivo `__init__.py` asociado al paquete con el que se trabaja. \n",
    "\n",
    "El módulo `logging` permite generar registros con los cuales se facilita la compresión del flujo inherente a una aplicación. Esté módulo es nativo de Python.\n",
    "\n",
    "Una vez importado el módulo, se requiere hacer uso de un \"logger\" para registrar mensajes de interés. Por defecto se tienen 5 niveles para indicar la importancia de los eventos a registrar. Estos corresponden a DEBUG, INFO, WARNING, ERROR y CRITICAL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Importe el módulo `logging` acceda a los niveles de importacia del módulo utilizando la notación `logging.nivel(msj)` (ej: `loggin.debug(msj)`) donde `msj` representa un `string` a imprimir en pantalla. ¿Existe alguna diferencia en la impresión por pantalla según el nivel de importancia?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar un *logger* utilizamos el método `.getLogger()` y le asociamos un nombre, en este caso, buscamos un logger con el nombre de nuestro paquete por lo que deberiamos agregar las siguientes lineas:\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "```\n",
    "\n",
    "Acá configuramos el nivel del logger como `DEBUG` pues utilizaremos esta herramienta en un entorno de desarrollo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adicionalmente, crearemos un archivo de configuraciones asociado al módulo de logging. En esté archivo indicaremos que información buscamos almacenar al registrar eventos, para ello nos basamos en la siguiente [lista](https://docs.python.org/3/library/logging.html#logrecord-attributes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/config/logging_config.py \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "FORMATTER = logging.Formatter(\n",
    "    \"%(asctime)s — %(name)s — %(levelname)s —\" \"%(funcName)s:%(lineno)d — %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscamos además mostrar los eventos en la terminal, para ello se hace uso de `handlers`, estos objetos permiten enviar registros a diferentes destinos por medio de mensajes (ej: HTTP, email, guardar en disco). Creamos un `handler` que permita imprimir en pantalla utilizando el módulo `sys`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/config/logging_config.py \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "FORMATTER = logging.Formatter(\n",
    "    \"%(asctime)s — %(name)s — %(levelname)s —\" \"%(funcName)s:%(lineno)d — %(message)s\"\n",
    ")\n",
    "\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    return console_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "entregaremos dicho `handler` a nuestro logger definido en `__init__.py`. Este pasa a ser finalmente: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/__init__.py\n",
    "import logging\n",
    "\n",
    "from clf_model.config import config\n",
    "from clf_model.config import logging_config\n",
    "\n",
    "VERSION_PATH = config.PACKAGE_ROOT / 'VERSION'\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging_config.get_console_handler())\n",
    "\n",
    "logger.propagate = False\n",
    "\n",
    "with open(VERSION_PATH, 'r') as version_file:\n",
    "    __version__ = version_file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La opción `logger.propagate = False` evita que los mensajes generados por el logger asociado a nuestro paquete sean inputs de loggers de otros paquetes generando registros sobre nuestra implementación. Para más información sobre el módulo de logging se puede acceder a la [documentación oficial](https://docs.python.org/3/library/logging.html).\n",
    "\n",
    "Con las configuraciones anteriores es posible utilizar loggers en los componentes de nuestro paquete.\n",
    "\n",
    "Se procede a modificar el archivo `train.py` para generar registros de sus ejecuciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/train.py\n",
    "import  warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from clf_model import pipeline\n",
    "from clf_model.config import config \n",
    "from clf_model import __version__ as _version \n",
    "\n",
    "import logging\n",
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "def clean_old_models(files_to_keep)  :\n",
    "    '''Limpia los modelos generados en versiones anteriores.'''\n",
    "\n",
    "    for model_file in config.LAST_MODEL_PATH.iterdir():\n",
    "        if model_file.name not in [files_to_keep, \"__init__.py\"]:\n",
    "            model_file.unlink()\n",
    "\n",
    "\n",
    "def train(model_name = config.LAST_MODEL_NAME):\n",
    "    '''Entrena el modelo final.'''\n",
    "\n",
    "    # Lee los datos\n",
    "    data = pd.read_csv(config.DATA_PATH_TRAIN)\n",
    "    test_data = data.sample(frac=0.1, random_state=5)\n",
    "\n",
    "    train_idx = data.index.difference(test_data.index)\n",
    "\n",
    "    y_train = data.loc[train_idx, config.TARGET]\n",
    "    x_train = data.drop(config.TARGET, axis=1).loc[train_idx]\n",
    "    \n",
    "    #Entrena el modelo\n",
    "    pipeline.train_pipe.fit(x_train, y_train)\n",
    "\n",
    "    name =  model_name+'_'+str(_version) \n",
    "    file_name = config.LAST_MODEL_PATH / name \n",
    "\n",
    "    #Guarda el modelo y limpia\n",
    "    _logger.info('Limpiando versiones anteriores')\n",
    "    clean_old_models(files_to_keep = file_name)\n",
    "\n",
    "    _logger.info(f\"Guardando modelo version: {_version}\")\n",
    "    joblib.dump(pipeline.train_pipe, file_name) \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera se modifica `predict.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/clf_model/predict.py\n",
    "import  warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pandas as pd \n",
    "import joblib\n",
    "\n",
    "from clf_model.config import config \n",
    "from clf_model import __version__ as _version \n",
    "\n",
    "import logging\n",
    "\n",
    "_logger = logging.getLogger(__name__)\n",
    "\n",
    "def predict(input_data):\n",
    "    '''Predice utilizando el modelo entrenado.''' \n",
    "    name =  config.LAST_MODEL_NAME + '_' +str(_version)\n",
    "    model = joblib.load(config.LAST_MODEL_PATH / name)\n",
    "    \n",
    "    data = pd.read_json(input_data, orient='index')\n",
    "    \n",
    "    if data.shape[1] == 1:\n",
    "\n",
    "        output = model.predict(pd.DataFrame(data).T)\n",
    "        _logger.info(\n",
    "            f\"Version del modelo: {_version} \"\n",
    "            f\"Inputs para predecir: {data} \"\n",
    "            f\"Predicciones: {output}\"\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        output = model.predict(data)\n",
    "        _logger.info(\n",
    "            f\"Version del modelo: {_version} \"\n",
    "            f\"Inputs para predecir: {data} \"\n",
    "            f\"Predicciones: {output}\"\n",
    "        )\n",
    "\n",
    "\n",
    "    response = {\"predictions\": output, \"version\":_version}\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente para que se muestren los mensajes de logging al momento de ejecutar tests con `tox` agregamos el parámetro `-s` a `tox.ini`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/tox.ini\n",
    "[tox]\n",
    "envlist = clf_model\n",
    "skipsdist = True\n",
    "\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "deps =\n",
    "    -rrequirements.txt\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/train.py \n",
    "    pytest -s tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "al ejecutar `tox` se observan los registros programados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**\n",
    "\n",
    "1. Modifique el archivo `train.py` para que muestre los logs configurados en pantalla. *Hint*: ponga atención a la variable `__name__`. \n",
    "2. Agregue loggers a los demás módulos del paquete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empaquetamiento \n",
    "\n",
    "Una vez generada la estructura de módulos, asegurada la reproducibilidad del modelo, generados los tests correspondientes, haber generado un versionamiento y un sistema de logs, se procede a empaquetar nuestra aplicación para ser distribuida.\n",
    "\n",
    "Para este proceso es necesario generar un archivo `setup.py`, también se requiere modificar los requerimientos agregado `setuptools` y `wheel`. \n",
    "\n",
    "`setuptools` permite construir y distribuir paquetes de python de manera sencilla. Por su parte `wheel` es la librería estándar de empaquetamiento de Python, `wheel` proporciona una extensión para `setuptools` para generar *wheels*, donde *wheel* es un tipo de paquete basado en `.zip` con un sistema de archivos siguiendo una estructura especial. \n",
    "\n",
    "Se agregan las nuevas dependecias, en este caso basta añadir las lineas:\n",
    "\n",
    "```\n",
    "setuptools >= 49.2.1, < 50.0.0 \n",
    "wheel >= 0.34.2, < 0.35.0\n",
    "```\n",
    "\n",
    "**Obs**: Esta parte depende de la versión actual y depende de cuando se generó este documento.\n",
    "\n",
    "Se procede a generar un archivo `setup.py` con las especificaciones que requiere la aplicación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/setup.py \n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import io\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from setuptools import find_packages, setup\n",
    "\n",
    "# metadatos\n",
    "NAME = 'clf_model'\n",
    "DESCRIPTION = 'Entrena y despliega un modelo de clasificacion.'\n",
    "URL = 'https://github.com/NicoCaro'\n",
    "EMAIL = 'ncaro@dim.uchile.cl'\n",
    "AUTHOR = 'Nico Caro'\n",
    "REQUIRES_PYTHON = '>=3.8.0'\n",
    "\n",
    "# Se cicla por los requerimientos\n",
    "def list_reqs(fname='requirements.txt'):\n",
    "    with open(fname) as fd:\n",
    "        return fd.read().splitlines()\n",
    "\n",
    "\n",
    "#ubicacion de este archivo\n",
    "here = os.path.abspath(os.path.dirname(__file__))\n",
    "\n",
    "'''\n",
    "Imorta un archivo README y lo usa como descriptor. \n",
    "Debe estar definido en un archivo MANIFEST.in\n",
    "'''\n",
    "try:\n",
    "    with io.open(os.path.join(here, 'README.md'), encoding='utf-8') as f:\n",
    "        long_description = '\\n' + f.read()\n",
    "except FileNotFoundError:\n",
    "    long_description = DESCRIPTION\n",
    "\n",
    "# Carga la version del paquete\n",
    "ROOT_DIR = Path(__file__).resolve().parent\n",
    "PACKAGE_DIR = ROOT_DIR / NAME\n",
    "about = {}\n",
    "with open(PACKAGE_DIR / 'VERSION') as f:\n",
    "    _version = f.read().strip()\n",
    "    about['__version__'] = _version\n",
    "\n",
    "\n",
    "#Inicializa el objeto que produce la instalcion\n",
    "# Obs: la lincencia se puede cambiar. En esta implementacion se utiliza MIT.\n",
    "setup(\n",
    "    name=NAME,\n",
    "    version=about['__version__'],\n",
    "    description=DESCRIPTION,\n",
    "    long_description=long_description,\n",
    "    long_description_content_type='text/markdown',\n",
    "    author=AUTHOR,\n",
    "    author_email=EMAIL,\n",
    "    python_requires=REQUIRES_PYTHON,\n",
    "    url=URL,\n",
    "    packages=find_packages(exclude=('tests',)),\n",
    "    package_data={'regression_model': ['VERSION']},\n",
    "    install_requires=list_reqs(),\n",
    "    extras_require={},\n",
    "    include_package_data=True,\n",
    "    license='MIT',\n",
    "    classifiers=[\n",
    "        # Trove classifiers\n",
    "        # Full list: https://pypi.python.org/pypi?%3Aaction=list_classifiers\n",
    "        'License :: OSI Approved :: MIT License',\n",
    "        'Programming Language :: Python',\n",
    "        'Programming Language :: Python :: 3',\n",
    "        'Programming Language :: Python :: 3.6',\n",
    "        'Programming Language :: Python :: 3.7',\n",
    "        'Programming Language :: Python :: 3.8',\n",
    "        'Programming Language :: Python :: Implementation :: CPython',\n",
    "        'Programming Language :: Python :: Implementation :: PyPy'\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es crear un archivo `MANIFEST.in`. En este tipo de archivos se especifica que se incluirá en nuestro paquete al ser distribuido. Para más información se puede acceder a la siguiente [fuente](https://packaging.python.org/guides/using-manifest-in/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/MANIFEST.in \n",
    "include *.txt\n",
    "include *.md\n",
    "include *.cfg\n",
    "include *.pkl\n",
    "recursive-include ./clf_model/*\n",
    "\n",
    "include clf_model/data/train.csv \n",
    "include clf_model/data/test.csv\n",
    "include clf_model/trained_models/*\n",
    "include clf_model/last_model/*\n",
    "include clf_model/VERSION\n",
    "\n",
    "include ./requirements.txt\n",
    "exclude *.log\n",
    "\n",
    "recursive-exclude * __pycache__\n",
    "recursive-exclude * *.py[co]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar el archivo `setup.py` en un entorno `tox` generamos un nuevo entorno denominado `instalcion_local`. Este nueo ambiente posee las mismas dependencias que `testenv`  pero ejecuta el comando de entrenamiento para generar el modelo de clasificación y luego instala el paquete utilizando `setup.py`. Esto se implementa de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_model/tox.ini\n",
    "[tox]\n",
    "envlist = clf_model\n",
    "skipsdist = True\n",
    "\n",
    "[testenv]\n",
    "install_command = pip install {opts} {packages}\n",
    "\n",
    "deps =\n",
    "    -rrequirements.txt\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/train.py \n",
    "    pytest -s tests \n",
    "\n",
    "[testenv:instalacion_local]\n",
    "deps =\n",
    "    {[testenv]deps}\n",
    "\n",
    "setenv =\n",
    "    PYTHONPATH=.\n",
    "\n",
    "commands =\n",
    "    python clf_model/train.py\n",
    "    python setup.py sdist bdist_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejectuar `tox` se ejecturará el ambiente `testenv` por defecto, para ejecutar la instalación local debemos utilizar la opción `-e` según la sintaxis:\n",
    "\n",
    "```\n",
    "user@ruta/a/clf_model$ tox -e instalacion_local\n",
    "```\n",
    "\n",
    "El comando anterior genera un nuevo entorno local en el cual instala nuestro modelo de clasificación. \n",
    "\n",
    "**Obs**: para instalar el modelo en nuestro computador, debemos acceder `packages/clf_model` y ejecutar `pip install .`. Al instalar el paquete se podrá importar en cualquier instancia del interprete de Python por medio de `import clf_model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: El estado de la aplicación hasta este punto se puede acceder en el archivo `app_freeze.zip`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de una REST  API \n",
    "\n",
    "Una vez empaquetado el modelo se puede utilizar para *servir* sus predicciones. Esto se hará utilizando una REST API, *REST* viene de *Representational State Trasnfer* y *API* (como ya lo sabiamos) de *Application Programming Interface*. Esto quiere decir, que se creará un sistema (servidor) que entregará (al cliente) una representación del estado de un recurso solicitado (predicción del modelo). \n",
    "\n",
    "Este tipo de soluciones permite realizar predicciones de manera inmediata a múltiples clientes, además de separar el desarrollo de modelos del *front-end* o capa frontal del cliente. También permite combinar múltiples modelos y escalar a más usuarios. \n",
    "\n",
    "A continuación se implementa una API minimal haciendo uso de flask. Para ello, se crea un nuevo paquete siguiendo la estructura:\n",
    "\n",
    "```\n",
    "|- ProjectLab/\n",
    "|--- packages/\n",
    "|----- clf_model/\n",
    "|----- clf_api/\n",
    "|------- api/\n",
    "|------- requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ProjectLab/packages/clf_api  \n",
    "%mkdir ProjectLab/packages/clf_api/api "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza por crear un archivo de requerimientos asociado a la API. Acá se necesita tanto flask como el paquete asociado al modelo `clf_model`, para instalar dicho paquete entregamos la ruta **local relativa**. Observe que el paquete debe haber sido previamente procesado utilizando *setup.py*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask \n",
    "ver = flask.__version__ \n",
    "\n",
    "print(f'Se requiere la versio de flask: {ver}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/requirements.txt \n",
    "flask >= 1.1.2, < 1.2.0 \n",
    "\n",
    "#modelo local \n",
    "-e '../clf_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso corresponde a dar estructura a nuestra aplicación (API). Esto se lleva a cabo en la carpeta `clp_api/api/`. Acá creamos un archivo `__init__.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/__init__.py  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego creamos un módulo asociado a la aplicación `app.py` y uno asociado a una *blueprint* de flask. \n",
    "\n",
    "El concepto *blueprint* hace referencia a *proyecto* o *plantilla*. En flask esta abstraccioń permite generar componentes de aplicaciones, agregando a la vez soporte para patrones comunes transversales a la aplicación. El manejo de plantillas se hace por medio de la clase `Blueprint` que permite construir y extender una aplicación. Más información en el siguiente [recurso](https://flask.palletsprojects.com/en/1.1.x/blueprints/).\n",
    "\n",
    "Creamos una blueprint sencilla en el script `controller.py`. Acá buscamos generar una primera prueba para lo que posteriormente se conformará como la ruta sobre la cual se harán predicciones. \n",
    "\n",
    "Se comienza importando los objetos necesarios para luego definir nuestra blueplrint (inicial) asociada al componente de predicción, este se denomina `prediction_app`, a esta le asociamos la ruta `/pred_test` y registramos la función correspondiente a aplicar cuando se reciban consultas tipo `GET`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/controller.py \n",
    "from flask import Blueprint, request\n",
    "\n",
    "# se define la blueprint, actua como una app pero no lo es!\n",
    "prediction_app = Blueprint('prediction_app', __name__)\n",
    "\n",
    "#se define la ruta\n",
    "@prediction_app.route('/pred_test', methods=['GET'])\n",
    "def pred_test():\n",
    "    if request.method == 'GET':\n",
    "        return 'test aprobado'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego hacemos uso de la plantilla generada para crear el esqueleto de la API en el script `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/app.py \n",
    "from flask import Flask\n",
    "\n",
    "def create_app(): \n",
    "    flask_app = Flask('clf_api') \n",
    "   \n",
    "    # Se importa la plantilla y se registra\n",
    "    from api.controller import prediction_app\n",
    "    flask_app.register_blueprint(prediction_app)\n",
    "\n",
    "    return flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente generamos el script `run.py` con el cual inicializaremos nuestra API. Este se ubica en `clf_api/` y tiene la siguiente estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/run.py \n",
    "from api.app import create_app\n",
    "\n",
    "application = create_app()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    application.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para probar la configuración hasta acá generada, ingresamos a `packages/clf_api/` y declaramos la variable de entorno `FLASK_APP = run.py`  (ver introducción). \n",
    "\n",
    "Finalmente para comprobar el funcionamiento de la aplicación ejecutamos `python run.py` y accedemos a la ruta `pred_test`. Si todo funciona como es debido, se debería tener el mensaje `test aprobado` en pantalla. \n",
    "\n",
    "Al igual que con el modelo anterior, la API requiere de módulos de configuraciones, tests y logging.\n",
    "\n",
    "Se procede a crear un módulo de configuración, en este se definen loggers para guardar registros en disco y mostrar en pantalla. \n",
    "\n",
    "Además se genera un sistema de clases con el cual se manejan opciones globales en función del ambiente en el que se ejecuta la API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/config.py  \n",
    "import logging\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import pathlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PACKAGE_ROOT = pathlib.Path(__file__).resolve().parent.parent\n",
    "\n",
    "\n",
    "FORMATTER = logging.Formatter(\n",
    "    \"%(asctime)s — %(name)s — %(levelname)s —\"\n",
    "    \"%(funcName)s:%(lineno)d — %(message)s\")\n",
    "\n",
    "LOG_DIR = PACKAGE_ROOT / 'logs'\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "LOG_FILE = LOG_DIR / 'clf_api.log'\n",
    "\n",
    "#Logger en consola\n",
    "def get_console_handler():\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(FORMATTER)\n",
    "    return console_handler\n",
    "\n",
    "#logger hacia archivos \n",
    "def get_file_handler():\n",
    "    file_handler = TimedRotatingFileHandler(\n",
    "        LOG_FILE, when='midnight')\n",
    "    file_handler.setFormatter(FORMATTER)\n",
    "    file_handler.setLevel(logging.WARNING)\n",
    "    return file_handler\n",
    "\n",
    "#permite seleccioanr un logger segun entorno\n",
    "def get_logger(logger_name):\n",
    "    \"\"\"Selecciona el logger segun un nombre\"\"\"\n",
    "\n",
    "    logger = logging.getLogger(logger_name)\n",
    "\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    logger.addHandler(get_console_handler())\n",
    "    logger.addHandler(get_file_handler())\n",
    "    logger.propagate = False\n",
    "\n",
    "    return logger\n",
    "\n",
    "# Clases de configuracion segun ambiente \n",
    "\n",
    "#General\n",
    "class Config:\n",
    "    DEBUG = False\n",
    "    TESTING = False\n",
    "    CSRF_ENABLED = True\n",
    "    SECRET_KEY = 'ClaveSecreta123'\n",
    "    SERVER_PORT = 5000\n",
    "\n",
    "#Produccion\n",
    "class ProductionConfig(Config):\n",
    "    DEBUG = False\n",
    "    SERVER_PORT = os.environ.get('PORT', 5000)\n",
    "\n",
    "#Desarrollo\n",
    "class DevelopmentConfig(Config):\n",
    "    DEVELOPMENT = True\n",
    "    DEBUG = True\n",
    "\n",
    "#Testing\n",
    "class TestingConfig(Config):\n",
    "    TESTING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conectamos el módulo de configuraciones con la aplicación ingresando a `app.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/app.py \n",
    "from flask import Flask\n",
    "\n",
    "#importa la configuracion\n",
    "from api.config import get_logger\n",
    "\n",
    "# se comporta igual que el logger del paquete clf_model.\n",
    "_logger = get_logger(logger_name=__name__)\n",
    "\n",
    "\n",
    "def create_app(config_object):\n",
    "    \n",
    "    flask_app = Flask('clf_api') \n",
    "    \n",
    "    #conecta con la configuracion\n",
    "    flask_app.config.from_object(config_object)\n",
    "\n",
    "    #Blueprints \n",
    "    from api.controller import prediction_app\n",
    "    flask_app.register_blueprint(prediction_app)\n",
    "    _logger.debug('Instancia de App creada')\n",
    "\n",
    "    return flask_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera modificamos el archivo de blueprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/controller.py \n",
    "from flask import Blueprint, request\n",
    "from api.config import get_logger\n",
    "\n",
    "\n",
    "_logger = get_logger(logger_name=__name__)\n",
    "\n",
    "# se define la blueprint, actua como una app pero no lo es!\n",
    "prediction_app = Blueprint('prediction_app', __name__)\n",
    "\n",
    "#se define la ruta\n",
    "@prediction_app.route('/pred_test', methods=['GET'])\n",
    "def pred_test():\n",
    "    if request.method == 'GET':\n",
    "        _logger.info('Consulta ok')\n",
    "        return 'test aprobado'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se necesita agregar un modulo de tests para desarrollar de manera robusta sobre la API, para ello se crea la carpeta `tests` que será manejada por `pytests` al igual que con el módulo `clf_model`. \n",
    "\n",
    "Se crea la estructura de carpetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mkdir ProjectLab/packages/clf_api/tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/tests/__init__.py \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá haremos uso de un archivo de configuraciones que servirá para declarar variables a nivel global en nuestros tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/tests/conftest.py\n",
    "import pytest\n",
    "\n",
    "from api.app import create_app\n",
    "from api.config import TestingConfig\n",
    "\n",
    "#crea una instacia test de nuestra aplicacion\n",
    "@pytest.fixture\n",
    "def app():\n",
    "    app = create_app(config_object=TestingConfig)\n",
    "\n",
    "    with app.app_context():\n",
    "        yield app\n",
    "\n",
    "#\n",
    "@pytest.fixture\n",
    "def flask_test_client(app):\n",
    "    with app.test_client() as test_client:\n",
    "        yield test_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el archivo`conftest.py` es reconocido por `pytest` de manera predeterminada (lo busca en cada directorio) acá se hace uso de `fixtures`. Las *fixtures* corresponden a funciones cuya utilidad es centralizar la entrega de un tipo de dato. Para comprender este concepto hay que visualizar cada test como un conjunto de operaciones *input*-*output* donde se aseguran las condiciones *input* para contrastar las salidas o *output* con ciertos patrones esperados a priori (sabemos que tipo de datos esperar como salida o incluso que resultado). Podemos definir tests que reciben como *input* una *fixture* y de manera centralizada definimos que resultado entrega dicha *fixture* a cada test que lo requiera. Esto mejora la mantenibilidad de los tests facilitando su manejo. Más información sobre *pytest* en esta [fuente](https://docs.pytest.org/en/stable/).\n",
    "\n",
    "A continuación se procede a generar un módulo de test para el script `controller.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/tests/test_controller.py \n",
    "#Se crea el este utilizando la fixture flask_test_client.\n",
    "def test_health_endpoint_returns_200(flask_test_client):\n",
    "    #Aplica la consulta\n",
    "    response = flask_test_client.get('/pred_test')\n",
    "\n",
    "    #Verifica una correcta respuesta\n",
    "    assert response.status_code == 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se confirma el funcionamiento del código implementado por medio de:\n",
    "\n",
    "```\n",
    "user@ruta/a/clf_api$ pytest tests\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obs**: no es necesario declarar previamente el valor de `flask_test_client` pues pytest lo carga al inicializar `conftest.py` antes de realizar cualquier test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se modifica el archivo `run.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/run.py\n",
    "from api.app import create_app\n",
    "from api.config import DevelopmentConfig\n",
    "\n",
    "# se agrega la configuracion de desarrollo\n",
    "application = create_app(\n",
    "    config_object=DevelopmentConfig)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    application.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción en la API\n",
    "\n",
    "Generada la estructra base de tests, configuraciones y loggers, se procede a conectar nuestra API con el modelo de clasificación mediante un *endpoint* de predicción. En este contexto, el término *endopoint* hace referencia a *canal de comunicación* mediante el cual un cliente entrega una solicitud y la API *sirve* con un resultado.\n",
    "\n",
    "La implementación se basa en el esquema de blueprints utilizado en el test anterior. Se procede a modificar por tanto el script `controller.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/controller.py\n",
    "from flask import Blueprint, request, jsonify\n",
    "from api.config import get_logger\n",
    "\n",
    "#Conectamos la API con el modelo de clasificacion\n",
    "from clf_model.predict import predict\n",
    "\n",
    "_logger = get_logger(logger_name=__name__)\n",
    "\n",
    "prediction_app = Blueprint('prediction_app', __name__)\n",
    "\n",
    "@prediction_app.route('/pred_test', methods=['GET'])\n",
    "def pred_test():\n",
    "    if request.method == 'GET':\n",
    "        _logger.info('Consulta ok')\n",
    "        return 'test aprobado'\n",
    "\n",
    "#Se define el endpoint de prediccion\n",
    "@prediction_app.route('/v1/predict/classify', methods=['POST'])\n",
    "def predict_classify():\n",
    "    if request.method == 'POST':\n",
    "        json_data = request.get_json()\n",
    "        _logger.info(f'Inputs: {json_data}')\n",
    "\n",
    "        result = predict(input_data=json_data)\n",
    "        _logger.info(f'Outputs: {result}')\n",
    "\n",
    "        predictions = [int(x) for x in result.get('predictions')]\n",
    "        version = result.get('version')\n",
    "        \n",
    "        print('VERSION:',version)\n",
    "        return jsonify({'predictions': predictions,\n",
    "                        'version': version})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá hay varios puntos que destacar. En primer lugar, la conexión API - modelo ocurre al importar el paquete `clf_model`. Esto garantiza modularidad pues toda la abstracción asociada al modelo de ciencia de datos queda apartado de API. En segundo lugar, se hace uso de la ruta `/v1/predict/classify` se utiliza `v1` como identificador de la API, (en vez de directamente `/predict/classify` que sería un identificador directo del modelo) esto permite nuevamente separar la API del modelo. Por último, la información es obtenida por medio de métodos `POST` en formato `json` y todo el procesamiento de la información ocurre en la función `predict`. \n",
    "\n",
    "El siguiente paso es generar un test asociado a esta nueva funcionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/tests/test_controller.py\n",
    "from clf_model.config import config as model_config\n",
    "from clf_model import __version__ as _version\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "def test_pred_endpoint_returns_200(flask_test_client):\n",
    "    response = flask_test_client.get('/pred_test')\n",
    "    assert response.status_code == 200\n",
    "\n",
    "def test_prediction_endpoint_returns_prediction(flask_test_client):\n",
    "    '''Carga los datos de clf_model y efectua un simil del test ahi defindo.'''\n",
    "    \n",
    "    test_data = pd.read_csv(model_config.DATA_PATH_TEST)\n",
    "    post_json = test_data.iloc[[0,-1],:].to_json(orient='index') \n",
    "\n",
    "    # Realiza la consulta\n",
    "    response = flask_test_client.post('/v1/predict/classify',\n",
    "                                      json=post_json)\n",
    "\n",
    "    # testea la respuesa\n",
    "    \n",
    "    # respuesta correcta\n",
    "    assert response.status_code == 200\n",
    "    response_json = json.loads(response.data)\n",
    "    \n",
    "    #recupera la prediccion\n",
    "    prediction = response_json['predictions']\n",
    "    response_version = response_json['version']\n",
    "    \n",
    "    # sanidad del modelo (respuestas conocidas)\n",
    "    assert prediction[0] == 0\n",
    "    assert prediction[1] == 1\n",
    "    \n",
    "    # recupara la version\n",
    "    assert response_version == _version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ejecutar `pytest` deberían aparecer ambos tests como superados (es posible que existan advertencias del tipo `UserWarning` estas aparecen al cargar modelos guardados con `pickle`).\n",
    "\n",
    "Con este hemos implementado el *endopoint* de predicción por lo que nuestro modelo puede comenzar a servir con predicciones. Hasta este punto ya podemos considerar la API construida como *funcional *.\n",
    "\n",
    "El siguiente paso será crear un nuevo *endpoint* asociado a la versiones, tanto de la API como del modelo de clasificación. Para ello, versionamos la api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/VERSION\n",
    "0.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/__init__.py\n",
    "from api.config import PACKAGE_ROOT\n",
    "\n",
    "with open(PACKAGE_ROOT / 'VERSION') as version_file:\n",
    "    __version__ = version_file.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego construimos un endpoint que recibe la versión tanto del modelo como de la API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/api/controller.py\n",
    "from flask import Blueprint, request, jsonify\n",
    "\n",
    "from clf_model.predict import predict\n",
    "from clf_model import __version__ as _version\n",
    "\n",
    "from api import __version__ as api_version\n",
    "from api.config import get_logger\n",
    "\n",
    "_logger = get_logger(logger_name=__name__)\n",
    "\n",
    "prediction_app = Blueprint('prediction_app', __name__)\n",
    "\n",
    "@prediction_app.route('/pred_test', methods=['GET'])\n",
    "def pred_test():\n",
    "    if request.method == 'GET':\n",
    "        _logger.info('Consulta ok')\n",
    "        return 'test aprobado'\n",
    "\n",
    "#Se define el endpoint de prediccion\n",
    "@prediction_app.route('/v1/predict/classify', methods=['POST'])\n",
    "def predict_classify():\n",
    "    if request.method == 'POST':\n",
    "        json_data = request.get_json()\n",
    "        _logger.info(f'Inputs: {json_data}')\n",
    "\n",
    "        result = predict(input_data=json_data)\n",
    "        _logger.info(f'Outputs: {result}')\n",
    "\n",
    "        predictions = [int(x) for x in result.get('predictions')]\n",
    "        version = result.get('version')\n",
    "        \n",
    "        print('VERSION:',version)\n",
    "        return jsonify({'predictions': predictions,\n",
    "                        'version': version})\n",
    "    \n",
    "@prediction_app.route('/version', methods=['GET'])\n",
    "def version():\n",
    "    if request.method == 'GET':\n",
    "        return jsonify({'model_version': _version,\n",
    "                        'api_version': api_version})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente construimos un test asociado a esta última funcionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file ProjectLab/packages/clf_api/tests/test_controller.py\n",
    "from clf_model.config import config as model_config\n",
    "from clf_model import __version__ as _version\n",
    "from api import __version__ as api_version\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "import math\n",
    "\n",
    "def test_pred_endpoint_returns_200(flask_test_client):\n",
    "    response = flask_test_client.get('/pred_test')\n",
    "    assert response.status_code == 200\n",
    "\n",
    "def test_prediction_endpoint_returns_prediction(flask_test_client):\n",
    "    '''Carga los datos de clf_model y efectua un simil del test ahi defindo.'''\n",
    "    \n",
    "    test_data = pd.read_csv(model_config.DATA_PATH_TEST)\n",
    "    post_json = test_data.iloc[[0,-1],:].to_json(orient='index') \n",
    "\n",
    "    response = flask_test_client.post('/v1/predict/classify',\n",
    "                                      json=post_json)\n",
    "\n",
    "    assert response.status_code == 200\n",
    "    response_json = json.loads(response.data)\n",
    "\n",
    "    prediction = response_json['predictions']\n",
    "    response_version = response_json['version']\n",
    "\n",
    "    assert prediction[0] == 0\n",
    "    assert prediction[1] == 1\n",
    "    assert response_version == _version\n",
    "\n",
    "\n",
    "def test_version_endpoint_returns_version(flask_test_client):\n",
    "     # Realiza la consulta\n",
    "    response = flask_test_client.get('/version')\n",
    "\n",
    "     # Testea\n",
    "    assert response.status_code == 200\n",
    "    response_json = json.loads(response.data)\n",
    "    assert response_json['model_version'] == _version\n",
    "    assert response_json['api_version'] == api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es una API que recibe un archivo `json` en un método post en la ruta `/v1/predict/classify`y retorna una predicción. Además, al acceder a la ruta `/version` entrega un archivo `json` con la versión tanto de la API como del modelo. \n",
    "\n",
    "Se puede acceder a la versión final de la API implementada por medio del archivo `packages_final.zip`.\n",
    "\n",
    "El siguente paso corresponde a validar los campos de predicción y en general el *esquema* de la API. Sin embargo, las operaciones de ingenieria de ML conforman un campo de estudio como tal y se escapan al alcance del curso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (entorno_virtual)",
   "language": "python",
   "name": "entorno_virtual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
